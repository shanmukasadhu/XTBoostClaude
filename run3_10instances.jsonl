{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-12907", "model_patch": "", "raw_model_patch": "diff --git a/astropy/modeling/tests/test_separable.py b/astropy/modeling/tests/test_separable.py\nindex 88711b0..e774751 100644\n--- a/astropy/modeling/tests/test_separable.py\n+++ b/astropy/modeling/tests/test_separable.py\n@@ -147,4 +147,6 @@ def test_custom_model_separable():\n         return x + y\n \n     assert not model_c().separable\n-    assert np.all(separability_matrix(model_c()) == [True, True])\n+    assert np.all(separability_matrix(model_c()) == [True, True])\n+\n+\n", "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\"\"\"\nTest separability of models.\n\n\"\"\"\n# pylint: disable=invalid-name\nimport pytest\nimport numpy as np\nfrom numpy.testing import assert_allclose\n\nfrom astropy.modeling import custom_model, models\nfrom astropy.modeling.models import Mapping\nfrom astropy.modeling.separable import (_coord_matrix, is_separable, _cdot,\n                                        _cstack, _arith_oper, separability_matrix)\nfrom astropy.modeling.core import ModelDefinitionError\n\n\nsh1 = models.Shift(1, name='shift1')\nsh2 = models.Shift(2, name='sh2')\nscl1 = models.Scale(1, name='scl1')\nscl2 = models.Scale(2, name='scl2')\nmap1 = Mapping((0, 1, 0, 1), name='map1')\nmap2 = Mapping((0, 0, 1), name='map2')\nmap3 = Mapping((0, 0), name='map3')\nrot = models.Rotation2D(2, name='rotation')\np2 = models.Polynomial2D(1, name='p2')\np22 = models.Polynomial2D(2, name='p22')\np1 = models.Polynomial1D(1, name='p1')\n\n\ncompound_models = {\n    'cm1': (map3 & sh1 | rot & sh1 | sh1 & sh2 & sh1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm2': (sh1 & sh2 | rot | map1 | p2 & p22,\n            (np.array([False, False]),\n             np.array([[True, True], [True, True]]))\n            ),\n    'cm3': (map2 | rot & scl1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm4': (sh1 & sh2 | map2 | rot & scl1,\n            (np.array([False, False, True]),\n             np.array([[True, False], [True, False], [False, True]]))\n            ),\n    'cm5': (map3 | sh1 & sh2 | scl1 & scl2,\n            (np.array([False, False]),\n             np.array([[True], [True]]))\n            ),\n    'cm7': (map2 | p2 & sh1,\n            (np.array([False, True]),\n             np.array([[True, False], [False, True]]))\n            )\n}\n\n\ndef test_coord_matrix():\n    c = _coord_matrix(p2, 'left', 2)\n    assert_allclose(np.array([[1, 1], [0, 0]]), c)\n    c = _coord_matrix(p2, 'right', 2)\n    assert_allclose(np.array([[0, 0], [1, 1]]), c)\n    c = _coord_matrix(p1, 'left', 2)\n    assert_allclose(np.array([[1], [0]]), c)\n    c = _coord_matrix(p1, 'left', 1)\n    assert_allclose(np.array([[1]]), c)\n    c = _coord_matrix(sh1, 'left', 2)\n    assert_allclose(np.array([[1], [0]]), c)\n    c = _coord_matrix(sh1, 'right', 2)\n    assert_allclose(np.array([[0], [1]]), c)\n    c = _coord_matrix(sh1, 'right', 3)\n    assert_allclose(np.array([[0], [0], [1]]), c)\n    c = _coord_matrix(map3, 'left', 2)\n    assert_allclose(np.array([[1], [1]]), c)\n    c = _coord_matrix(map3, 'left', 3)\n    assert_allclose(np.array([[1], [1], [0]]), c)\n\n\ndef test_cdot():\n    result = _cdot(sh1, scl1)\n    assert_allclose(result, np.array([[1]]))\n\n    result = _cdot(rot, p2)\n    assert_allclose(result, np.array([[2, 2]]))\n\n    result = _cdot(rot, rot)\n    assert_allclose(result, np.array([[2, 2], [2, 2]]))\n\n    result = _cdot(Mapping((0, 0)), rot)\n    assert_allclose(result, np.array([[2], [2]]))\n\n    with pytest.raises(ModelDefinitionError,\n                       match=r\"Models cannot be combined with the \\\"|\\\" operator; .*\"):\n        _cdot(sh1, map1)\n\n\ndef test_cstack():\n    result = _cstack(sh1, scl1)\n    assert_allclose(result, np.array([[1, 0], [0, 1]]))\n\n    result = _cstack(sh1, rot)\n    assert_allclose(result,\n                    np.array([[1, 0, 0],\n                              [0, 1, 1],\n                              [0, 1, 1]])\n                    )\n    result = _cstack(rot, sh1)\n    assert_allclose(result,\n                    np.array([[1, 1, 0],\n                              [1, 1, 0],\n                              [0, 0, 1]])\n                    )\n\n\ndef test_arith_oper():\n    # Models as inputs\n    result = _arith_oper(sh1, scl1)\n    assert_allclose(result, np.array([[1]]))\n    result = _arith_oper(rot, rot)\n    assert_allclose(result, np.array([[1, 1], [1, 1]]))\n\n    # ndarray\n    result = _arith_oper(np.array([[1, 2], [3, 4]]), np.array([[1, 2], [3, 4]]))\n    assert_allclose(result, np.array([[1, 1], [1, 1]]))\n\n    # Error\n    with pytest.raises(ModelDefinitionError, match=r\"Unsupported operands for arithmetic operator: .*\"):\n        _arith_oper(sh1, map1)\n\n\n@pytest.mark.parametrize(('compound_model', 'result'), compound_models.values())\ndef test_separable(compound_model, result):\n    assert_allclose(is_separable(compound_model), result[0])\n    assert_allclose(separability_matrix(compound_model), result[1])\n\n\ndef test_custom_model_separable():\n    @custom_model\n    def model_a(x):\n        return x\n\n    assert model_a().separable\n\n    @custom_model\n    def model_c(x, y):\n        return x + y\n\n    assert not model_c().separable\n    assert np.all(separability_matrix(model_c()) == [True, True])"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-13033", "model_patch": "", "raw_model_patch": "", "original_file_content": ""}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-13236", "model_patch": "", "raw_model_patch": "diff --git a/astropy/table/tests/test_mixin.py b/astropy/table/tests/test_mixin.py\nindex 48ae0c6..3a7c962 100644\n--- a/astropy/table/tests/test_mixin.py\n+++ b/astropy/table/tests/test_mixin.py\n@@ -877,4 +877,5 @@ def test_bad_info_class():\n     out = StringIO()\n     match = r\"failed to represent column 'tm' \\(MyArrayWrapper\\) as one or more Column subclasses\"\n     with pytest.raises(TypeError, match=match):\n-        represent_mixins_as_columns(t)\n+        represent_mixins_as_columns(t)\n+\n", "original_file_content": "# -*- coding: utf-8 -*-\n# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\n\nimport copy\nimport pickle\nfrom io import StringIO\n\nimport pytest\nimport numpy as np\n\nfrom astropy.table.serialize import represent_mixins_as_columns\nfrom astropy.utils.data_info import ParentDtypeInfo\nfrom astropy.table.table_helpers import ArrayWrapper\nfrom astropy.coordinates import EarthLocation, SkyCoord\nfrom astropy.table import Table, QTable, join, hstack, vstack, Column, NdarrayMixin\nfrom astropy.table import serialize\nfrom astropy import time\nfrom astropy import coordinates\nfrom astropy import units as u\nfrom astropy.table.column import BaseColumn\nfrom astropy.table import table_helpers\nfrom astropy.utils.exceptions import AstropyUserWarning\nfrom astropy.utils.metadata import MergeConflictWarning\nfrom astropy.coordinates.tests.test_representation import representation_equal\nfrom astropy.coordinates.tests.helper import skycoord_equal\n\nfrom .conftest import MIXIN_COLS\n\n\ndef test_attributes(mixin_cols):\n    \"\"\"\n    Required attributes for a column can be set.\n    \"\"\"\n    m = mixin_cols['m']\n    m.info.name = 'a'\n    assert m.info.name == 'a'\n\n    m.info.description = 'a'\n    assert m.info.description == 'a'\n\n    # Cannot set unit for these classes\n    if isinstance(m, (u.Quantity, coordinates.SkyCoord, time.Time, time.TimeDelta,\n                      coordinates.BaseRepresentationOrDifferential)):\n        with pytest.raises(AttributeError):\n            m.info.unit = u.m\n    else:\n        m.info.unit = u.m\n        assert m.info.unit is u.m\n\n    m.info.format = 'a'\n    assert m.info.format == 'a'\n\n    m.info.meta = {'a': 1}\n    assert m.info.meta == {'a': 1}\n\n    with pytest.raises(AttributeError):\n        m.info.bad_attr = 1\n\n    with pytest.raises(AttributeError):\n        m.info.bad_attr\n\n\ndef check_mixin_type(table, table_col, in_col):\n    # We check for QuantityInfo rather than just isinstance(col, u.Quantity)\n    # since we want to treat EarthLocation as a mixin, even though it is\n    # a Quantity subclass.\n    if ((isinstance(in_col.info, u.QuantityInfo) and type(table) is not QTable)\n            or isinstance(in_col, Column)):\n        assert type(table_col) is table.ColumnClass\n    else:\n        assert type(table_col) is type(in_col)\n\n    # Make sure in_col got copied and creating table did not touch it\n    assert in_col.info.name is None\n\n\ndef test_make_table(table_types, mixin_cols):\n    \"\"\"\n    Make a table with the columns in mixin_cols, which is an ordered dict of\n    three cols: 'a' and 'b' are table_types.Column type, and 'm' is a mixin.\n    \"\"\"\n    t = table_types.Table(mixin_cols)\n    check_mixin_type(t, t['m'], mixin_cols['m'])\n\n    cols = list(mixin_cols.values())\n    t = table_types.Table(cols, names=('i', 'a', 'b', 'm'))\n    check_mixin_type(t, t['m'], mixin_cols['m'])\n\n    t = table_types.Table(cols)\n    check_mixin_type(t, t['col3'], mixin_cols['m'])\n\n\ndef test_io_ascii_write():\n    \"\"\"\n    Test that table with mixin column can be written by io.ascii for\n    every pure Python writer.  No validation of the output is done,\n    this just confirms no exceptions.\n    \"\"\"\n    from astropy.io.ascii.connect import _get_connectors_table\n    t = QTable(MIXIN_COLS)\n    for fmt in _get_connectors_table():\n        if fmt['Write'] and '.fast_' not in fmt['Format']:\n            out = StringIO()\n            t.write(out, format=fmt['Format'])\n\n\ndef test_votable_quantity_write(tmpdir):\n    \"\"\"\n    Test that table with Quantity mixin column can be round-tripped by\n    io.votable.  Note that FITS and HDF5 mixin support are tested (much more\n    thoroughly) in their respective subpackage tests\n    (io/fits/tests/test_connect.py and io/misc/tests/test_hdf5.py).\n    \"\"\"\n    t = QTable()\n    t['a'] = u.Quantity([1, 2, 4], unit='nm')\n\n    filename = str(tmpdir.join('table-tmp'))\n    t.write(filename, format='votable', overwrite=True)\n    qt = QTable.read(filename, format='votable')\n    assert isinstance(qt['a'], u.Quantity)\n    assert qt['a'].unit == 'nm'\n\n\n@pytest.mark.remote_data\n@pytest.mark.parametrize('table_types', (Table, QTable))\ndef test_io_time_write_fits_standard(tmpdir, table_types):\n    \"\"\"\n    Test that table with Time mixin columns can be written by io.fits.\n    Validation of the output is done. Test that io.fits writes a table\n    containing Time mixin columns that can be partially round-tripped\n    (metadata scale, location).\n\n    Note that we postpone checking the \"local\" scale, since that cannot\n    be done with format 'cxcsec', as it requires an epoch.\n    \"\"\"\n    t = table_types([[1, 2], ['string', 'column']])\n    for scale in time.STANDARD_TIME_SCALES:\n        t['a' + scale] = time.Time([[1, 2], [3, 4]], format='cxcsec',\n                                   scale=scale, location=EarthLocation(\n            -2446354, 4237210, 4077985, unit='m'))\n        t['b' + scale] = time.Time(['1999-01-01T00:00:00.123456789',\n                                    '2010-01-01T00:00:00'], scale=scale)\n    t['c'] = [3., 4.]\n\n    filename = str(tmpdir.join('table-tmp'))\n\n    # Show that FITS format succeeds\n    with pytest.warns(\n            AstropyUserWarning,\n            match='Time Column \"btai\" has no specified location, '\n            'but global Time Position is present'):\n        t.write(filename, format='fits', overwrite=True)\n    with pytest.warns(\n            AstropyUserWarning,\n            match='Time column reference position \"TRPOSn\" is not specified'):\n        tm = table_types.read(filename, format='fits', astropy_native=True)\n\n    for scale in time.STANDARD_TIME_SCALES:\n        for ab in ('a', 'b'):\n            name = ab + scale\n\n            # Assert that the time columns are read as Time\n            assert isinstance(tm[name], time.Time)\n\n            # Assert that the scales round-trip\n            assert tm[name].scale == t[name].scale\n\n            # Assert that the format is jd\n            assert tm[name].format == 'jd'\n\n            # Assert that the location round-trips\n            assert tm[name].location == t[name].location\n\n            # Finally assert that the column data round-trips\n            assert (tm[name] == t[name]).all()\n\n    for name in ('col0', 'col1', 'c'):\n        # Assert that the non-time columns are read as Column\n        assert isinstance(tm[name], Column)\n\n        # Assert that the non-time columns' data round-trips\n        assert (tm[name] == t[name]).all()\n\n    # Test for conversion of time data to its value, as defined by its format\n    for scale in time.STANDARD_TIME_SCALES:\n        for ab in ('a', 'b'):\n            name = ab + scale\n            t[name].info.serialize_method['fits'] = 'formatted_value'\n\n    t.write(filename, format='fits', overwrite=True)\n    tm = table_types.read(filename, format='fits')\n\n    for scale in time.STANDARD_TIME_SCALES:\n        for ab in ('a', 'b'):\n            name = ab + scale\n\n            assert not isinstance(tm[name], time.Time)\n            assert (tm[name] == t[name].value).all()\n\n\n@pytest.mark.parametrize('table_types', (Table, QTable))\ndef test_io_time_write_fits_local(tmpdir, table_types):\n    \"\"\"\n    Test that table with a Time mixin with scale local can also be written\n    by io.fits. Like ``test_io_time_write_fits_standard`` above, but avoiding\n    ``cxcsec`` format, which requires an epoch and thus cannot be used for a\n    local time scale.\n    \"\"\"\n    t = table_types([[1, 2], ['string', 'column']])\n    t['a_local'] = time.Time([[50001, 50002], [50003, 50004]],\n                             format='mjd', scale='local',\n                             location=EarthLocation(-2446354, 4237210, 4077985,\n                                                    unit='m'))\n    t['b_local'] = time.Time(['1999-01-01T00:00:00.123456789',\n                              '2010-01-01T00:00:00'], scale='local')\n    t['c'] = [3., 4.]\n\n    filename = str(tmpdir.join('table-tmp'))\n\n    # Show that FITS format succeeds\n\n    with pytest.warns(AstropyUserWarning,\n                      match='Time Column \"b_local\" has no specified location'):\n        t.write(filename, format='fits', overwrite=True)\n\n    with pytest.warns(AstropyUserWarning,\n                      match='Time column reference position \"TRPOSn\" is not specified.'):\n        tm = table_types.read(filename, format='fits', astropy_native=True)\n\n    for ab in ('a', 'b'):\n        name = ab + '_local'\n\n        # Assert that the time columns are read as Time\n        assert isinstance(tm[name], time.Time)\n\n        # Assert that the scales round-trip\n        assert tm[name].scale == t[name].scale\n\n        # Assert that the format is jd\n        assert tm[name].format == 'jd'\n\n        # Assert that the location round-trips\n        assert tm[name].location == t[name].location\n\n        # Finally assert that the column data round-trips\n        assert (tm[name] == t[name]).all()\n\n    for name in ('col0', 'col1', 'c'):\n        # Assert that the non-time columns are read as Column\n        assert isinstance(tm[name], Column)\n\n        # Assert that the non-time columns' data round-trips\n        assert (tm[name] == t[name]).all()\n\n    # Test for conversion of time data to its value, as defined by its format.\n    for ab in ('a', 'b'):\n        name = ab + '_local'\n        t[name].info.serialize_method['fits'] = 'formatted_value'\n\n    t.write(filename, format='fits', overwrite=True)\n    tm = table_types.read(filename, format='fits')\n\n    for ab in ('a', 'b'):\n        name = ab + '_local'\n\n        assert not isinstance(tm[name], time.Time)\n        assert (tm[name] == t[name].value).all()\n\n\ndef test_votable_mixin_write_fail(mixin_cols):\n    \"\"\"\n    Test that table with mixin columns (excluding Quantity) cannot be written by\n    io.votable.\n    \"\"\"\n    t = QTable(mixin_cols)\n    # Only do this test if there are unsupported column types (i.e. anything besides\n    # BaseColumn and Quantity class instances).\n    unsupported_cols = t.columns.not_isinstance((BaseColumn, u.Quantity))\n\n    if not unsupported_cols:\n        pytest.skip(\"no unsupported column types\")\n\n    out = StringIO()\n    with pytest.raises(ValueError) as err:\n        t.write(out, format='votable')\n    assert 'cannot write table with mixin column(s)' in str(err.value)\n\n\ndef test_join(table_types):\n    \"\"\"\n    Join tables with mixin cols.  Use column \"i\" as proxy for what the\n    result should be for each mixin.\n    \"\"\"\n    t1 = table_types.Table()\n    t1['a'] = table_types.Column(['a', 'b', 'b', 'c'])\n    t1['i'] = table_types.Column([0, 1, 2, 3])\n    for name, col in MIXIN_COLS.items():\n        t1[name] = col\n\n    t2 = table_types.Table(t1)\n    t2['a'] = ['b', 'c', 'a', 'd']\n\n    for name, col in MIXIN_COLS.items():\n        t1[name].info.description = name\n        t2[name].info.description = name + '2'\n\n    for join_type in ('inner', 'left'):\n        t12 = join(t1, t2, keys='a', join_type=join_type)\n        idx1 = t12['i_1']\n        idx2 = t12['i_2']\n        for name, col in MIXIN_COLS.items():\n            name1 = name + '_1'\n            name2 = name + '_2'\n            assert_table_name_col_equal(t12, name1, col[idx1])\n            assert_table_name_col_equal(t12, name2, col[idx2])\n            assert t12[name1].info.description == name\n            assert t12[name2].info.description == name + '2'\n\n    for join_type in ('outer', 'right'):\n        with pytest.raises(NotImplementedError) as exc:\n            t12 = join(t1, t2, keys='a', join_type=join_type)\n        assert 'join requires masking column' in str(exc.value)\n\n    with pytest.raises(TypeError) as exc:\n        t12 = join(t1, t2, keys=['a', 'skycoord'])\n    assert 'one or more key columns are not sortable' in str(exc.value)\n\n    # Join does work for a mixin which is a subclass of np.ndarray\n    with pytest.warns(MergeConflictWarning,\n                      match=\"In merged column 'quantity' the 'description' \"\n                            \"attribute does not match\"):\n        t12 = join(t1, t2, keys=['quantity'])\n    assert np.all(t12['a_1'] == t1['a'])\n\n\ndef test_hstack(table_types):\n    \"\"\"\n    Hstack tables with mixin cols.  Use column \"i\" as proxy for what the\n    result should be for each mixin.\n    \"\"\"\n    t1 = table_types.Table()\n    t1['i'] = table_types.Column([0, 1, 2, 3])\n    for name, col in MIXIN_COLS.items():\n        t1[name] = col\n        t1[name].info.description = name\n        t1[name].info.meta = {'a': 1}\n\n    for join_type in ('inner', 'outer'):\n        for chop in (True, False):\n            t2 = table_types.Table(t1)\n            if chop:\n                t2 = t2[:-1]\n                if join_type == 'outer':\n                    with pytest.raises(NotImplementedError) as exc:\n                        t12 = hstack([t1, t2], join_type=join_type)\n                    assert 'hstack requires masking column' in str(exc.value)\n                    continue\n\n            t12 = hstack([t1, t2], join_type=join_type)\n            idx1 = t12['i_1']\n            idx2 = t12['i_2']\n            for name, col in MIXIN_COLS.items():\n                name1 = name + '_1'\n                name2 = name + '_2'\n                assert_table_name_col_equal(t12, name1, col[idx1])\n                assert_table_name_col_equal(t12, name2, col[idx2])\n                for attr in ('description', 'meta'):\n                    assert getattr(t1[name].info, attr) == getattr(t12[name1].info, attr)\n                    assert getattr(t2[name].info, attr) == getattr(t12[name2].info, attr)\n\n\ndef assert_table_name_col_equal(t, name, col):\n    \"\"\"\n    Assert all(t[name] == col), with special handling for known mixin cols.\n    \"\"\"\n    if isinstance(col, coordinates.SkyCoord):\n        assert np.all(t[name].ra == col.ra)\n        assert np.all(t[name].dec == col.dec)\n    elif isinstance(col, coordinates.BaseRepresentationOrDifferential):\n        assert np.all(representation_equal(t[name], col))\n    elif isinstance(col, u.Quantity):\n        if type(t) is QTable:\n            assert np.all(t[name] == col)\n    elif isinstance(col, table_helpers.ArrayWrapper):\n        assert np.all(t[name].data == col.data)\n    else:\n        assert np.all(t[name] == col)\n\n\ndef test_get_items(mixin_cols):\n    \"\"\"\n    Test that slicing / indexing table gives right values and col attrs inherit\n    \"\"\"\n    attrs = ('name', 'unit', 'dtype', 'format', 'description', 'meta')\n    m = mixin_cols['m']\n    m.info.name = 'm'\n    m.info.format = '{0}'\n    m.info.description = 'd'\n    m.info.meta = {'a': 1}\n    t = QTable([m])\n    for item in ([1, 3], np.array([0, 2]), slice(1, 3)):\n        t2 = t[item]\n        m2 = m[item]\n        assert_table_name_col_equal(t2, 'm', m[item])\n        for attr in attrs:\n            assert getattr(t2['m'].info, attr) == getattr(m.info, attr)\n            assert getattr(m2.info, attr) == getattr(m.info, attr)\n\n\ndef test_info_preserved_pickle_copy_init(mixin_cols):\n    \"\"\"\n    Test copy, pickle, and init from class roundtrip preserve info.  This\n    tests not only the mixin classes but a regular column as well.\n    \"\"\"\n    def pickle_roundtrip(c):\n        return pickle.loads(pickle.dumps(c))\n\n    def init_from_class(c):\n        return c.__class__(c)\n\n    attrs = ('name', 'unit', 'dtype', 'format', 'description', 'meta')\n    for colname in ('i', 'm'):\n        m = mixin_cols[colname]\n        m.info.name = colname\n        m.info.format = '{0}'\n        m.info.description = 'd'\n        m.info.meta = {'a': 1}\n        for func in (copy.copy, copy.deepcopy, pickle_roundtrip, init_from_class):\n            m2 = func(m)\n            for attr in attrs:\n                # non-native byteorder not preserved by last 2 func, _except_ for structured dtype\n                if (attr != 'dtype'\n                        or getattr(m.info.dtype, 'isnative', True)\n                        or m.info.dtype.name.startswith('void')\n                        or func in (copy.copy, copy.deepcopy)):\n                    original = getattr(m.info, attr)\n                else:\n                    # func does not preserve byteorder, check against (native) type.\n                    original = m.info.dtype.newbyteorder('=')\n                assert getattr(m2.info, attr) == original\n\n\ndef test_add_column(mixin_cols):\n    \"\"\"\n    Test that adding a column preserves values and attributes\n    \"\"\"\n    attrs = ('name', 'unit', 'dtype', 'format', 'description', 'meta')\n    m = mixin_cols['m']\n    assert m.info.name is None\n\n    # Make sure adding column in various ways doesn't touch\n    t = QTable([m], names=['a'])\n    assert m.info.name is None\n\n    t['new'] = m\n    assert m.info.name is None\n\n    m.info.name = 'm'\n    m.info.format = '{0}'\n    m.info.description = 'd'\n    m.info.meta = {'a': 1}\n    t = QTable([m])\n\n    # Add columns m2, m3, m4 by two different methods and test expected equality\n    t['m2'] = m\n    m.info.name = 'm3'\n    t.add_columns([m], copy=True)\n    m.info.name = 'm4'\n    t.add_columns([m], copy=False)\n    for name in ('m2', 'm3', 'm4'):\n        assert_table_name_col_equal(t, name, m)\n        for attr in attrs:\n            if attr != 'name':\n                assert getattr(t['m'].info, attr) == getattr(t[name].info, attr)\n    # Also check that one can set using a scalar.\n    s = m[0]\n    if type(s) is type(m) and 'info' in s.__dict__:\n        # We're not going to worry about testing classes for which scalars\n        # are a different class than the real array, or where info is not copied.\n        t['s'] = m[0]\n        assert_table_name_col_equal(t, 's', m[0])\n        for attr in attrs:\n            if attr != 'name':\n                assert getattr(t['m'].info, attr) == getattr(t['s'].info, attr)\n\n    # While we're add it, also check a length-1 table.\n    t = QTable([m[1:2]], names=['m'])\n    if type(s) is type(m) and 'info' in s.__dict__:\n        t['s'] = m[0]\n        assert_table_name_col_equal(t, 's', m[0])\n        for attr in attrs:\n            if attr != 'name':\n                assert getattr(t['m'].info, attr) == getattr(t['s'].info, attr)\n\n\ndef test_vstack():\n    \"\"\"\n    Vstack tables with mixin cols.\n    \"\"\"\n    t1 = QTable(MIXIN_COLS)\n    t2 = QTable(MIXIN_COLS)\n    with pytest.raises(NotImplementedError):\n        vstack([t1, t2])\n\n\ndef test_insert_row(mixin_cols):\n    \"\"\"\n    Test inserting a row, which works for Column, Quantity, Time and SkyCoord.\n    \"\"\"\n    t = QTable(mixin_cols)\n    t0 = t.copy()\n    t['m'].info.description = 'd'\n    idxs = [0, -1, 1, 2, 3]\n    if isinstance(t['m'], (u.Quantity, Column, time.Time, time.TimeDelta, coordinates.SkyCoord)):\n        t.insert_row(1, t[-1])\n\n        for name in t.colnames:\n            col = t[name]\n            if isinstance(col, coordinates.SkyCoord):\n                assert skycoord_equal(col, t0[name][idxs])\n            else:\n                assert np.all(col == t0[name][idxs])\n\n        assert t['m'].info.description == 'd'\n    else:\n        with pytest.raises(ValueError) as exc:\n            t.insert_row(1, t[-1])\n        assert \"Unable to insert row\" in str(exc.value)\n\n\ndef test_insert_row_bad_unit():\n    \"\"\"\n    Insert a row into a QTable with the wrong unit\n    \"\"\"\n    t = QTable([[1] * u.m])\n    with pytest.raises(ValueError) as exc:\n        t.insert_row(0, (2 * u.m / u.s,))\n    assert \"'m / s' (speed/velocity) and 'm' (length) are not convertible\" in str(exc.value)\n\n\ndef test_convert_np_array(mixin_cols):\n    \"\"\"\n    Test that converting to numpy array creates an object dtype and that\n    each instance in the array has the expected type.\n    \"\"\"\n    t = QTable(mixin_cols)\n    ta = t.as_array()\n    m = mixin_cols['m']\n    dtype_kind = m.dtype.kind if hasattr(m, 'dtype') else 'O'\n    assert ta['m'].dtype.kind == dtype_kind\n\n\ndef test_assignment_and_copy():\n    \"\"\"\n    Test that assignment of an int, slice, and fancy index works.\n    Along the way test that copying table works.\n    \"\"\"\n    for name in ('quantity', 'arraywrap'):\n        m = MIXIN_COLS[name]\n        t0 = QTable([m], names=['m'])\n        for i0, i1 in ((1, 2),\n                       (slice(0, 2), slice(1, 3)),\n                       (np.array([1, 2]), np.array([2, 3]))):\n            t = t0.copy()\n            t['m'][i0] = m[i1]\n            if name == 'arraywrap':\n                assert np.all(t['m'].data[i0] == m.data[i1])\n                assert np.all(t0['m'].data[i0] == m.data[i0])\n                assert np.all(t0['m'].data[i0] != t['m'].data[i0])\n            else:\n                assert np.all(t['m'][i0] == m[i1])\n                assert np.all(t0['m'][i0] == m[i0])\n                assert np.all(t0['m'][i0] != t['m'][i0])\n\n\ndef test_conversion_qtable_table():\n    \"\"\"\n    Test that a table round trips from QTable => Table => QTable\n    \"\"\"\n    qt = QTable(MIXIN_COLS)\n    names = qt.colnames\n    for name in names:\n        qt[name].info.description = name\n\n    t = Table(qt)\n    for name in names:\n        assert t[name].info.description == name\n        if name == 'quantity':\n            assert np.all(t['quantity'] == qt['quantity'].value)\n            assert np.all(t['quantity'].unit is qt['quantity'].unit)\n            assert isinstance(t['quantity'], t.ColumnClass)\n        else:\n            assert_table_name_col_equal(t, name, qt[name])\n\n    qt2 = QTable(qt)\n    for name in names:\n        assert qt2[name].info.description == name\n        assert_table_name_col_equal(qt2, name, qt[name])\n\n\ndef test_setitem_as_column_name():\n    \"\"\"\n    Test for mixin-related regression described in #3321.\n    \"\"\"\n    t = Table()\n    t['a'] = ['x', 'y']\n    t['b'] = 'b'  # Previously was failing with KeyError\n    assert np.all(t['a'] == ['x', 'y'])\n    assert np.all(t['b'] == ['b', 'b'])\n\n\ndef test_quantity_representation():\n    \"\"\"\n    Test that table representation of quantities does not have unit\n    \"\"\"\n    t = QTable([[1, 2] * u.m])\n    assert t.pformat() == ['col0',\n                           ' m  ',\n                           '----',\n                           ' 1.0',\n                           ' 2.0']\n\n\ndef test_representation_representation():\n    \"\"\"\n    Test that Representations are represented correctly.\n    \"\"\"\n    # With no unit we get \"None\" in the unit row\n    c = coordinates.CartesianRepresentation([0], [1], [0], unit=u.one)\n    t = Table([c])\n    assert t.pformat() == ['    col0    ',\n                           '------------',\n                           '(0., 1., 0.)']\n\n    c = coordinates.CartesianRepresentation([0], [1], [0], unit='m')\n    t = Table([c])\n    assert t.pformat() == ['    col0    ',\n                           '     m      ',\n                           '------------',\n                           '(0., 1., 0.)']\n\n    c = coordinates.SphericalRepresentation([10]*u.deg, [20]*u.deg, [1]*u.pc)\n    t = Table([c])\n    assert t.pformat() == ['     col0     ',\n                           ' deg, deg, pc ',\n                           '--------------',\n                           '(10., 20., 1.)']\n\n    c = coordinates.UnitSphericalRepresentation([10]*u.deg, [20]*u.deg)\n    t = Table([c])\n    assert t.pformat() == ['   col0   ',\n                           '   deg    ',\n                           '----------',\n                           '(10., 20.)']\n\n    c = coordinates.SphericalCosLatDifferential(\n        [10]*u.mas/u.yr, [2]*u.mas/u.yr, [10]*u.km/u.s)\n    t = Table([c])\n    assert t.pformat() == ['           col0           ',\n                           'mas / yr, mas / yr, km / s',\n                           '--------------------------',\n                           '            (10., 2., 10.)']\n\n\ndef test_skycoord_representation():\n    \"\"\"\n    Test that skycoord representation works, both in the way that the\n    values are output and in changing the frame representation.\n    \"\"\"\n    # With no unit we get \"None\" in the unit row\n    c = coordinates.SkyCoord([0], [1], [0], representation_type='cartesian')\n    t = Table([c])\n    assert t.pformat() == ['     col0     ',\n                           'None,None,None',\n                           '--------------',\n                           '   0.0,1.0,0.0']\n\n    # Test that info works with a dynamically changed representation\n    c = coordinates.SkyCoord([0], [1], [0], unit='m', representation_type='cartesian')\n    t = Table([c])\n    assert t.pformat() == ['    col0   ',\n                           '   m,m,m   ',\n                           '-----------',\n                           '0.0,1.0,0.0']\n\n    t['col0'].representation_type = 'unitspherical'\n    assert t.pformat() == ['  col0  ',\n                           'deg,deg ',\n                           '--------',\n                           '90.0,0.0']\n\n    t['col0'].representation_type = 'cylindrical'\n    assert t.pformat() == ['    col0    ',\n                           '  m,deg,m   ',\n                           '------------',\n                           '1.0,90.0,0.0']\n\n\ndef test_ndarray_mixin():\n    \"\"\"\n    Test directly adding a plain structured array into a table instead of the\n    view as an NdarrayMixin.  Once added as an NdarrayMixin then all the previous\n    tests apply.\n    \"\"\"\n    a = np.array([(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')],\n                 dtype='<i4,' + ('|U1'))\n    b = np.array([(10, 'aa'), (20, 'bb'), (30, 'cc'), (40, 'dd')],\n                 dtype=[('x', 'i4'), ('y', ('U2'))])\n    c = np.rec.fromrecords([(100., 'raa'), (200., 'rbb'), (300., 'rcc'), (400., 'rdd')],\n                           names=['rx', 'ry'])\n    d = np.arange(8, dtype='i8').reshape(4, 2).view(NdarrayMixin)\n\n    # Add one during initialization and the next as a new column.\n    t = Table([a], names=['a'])\n    t['b'] = b\n    t['c'] = c\n    t['d'] = d\n\n    assert isinstance(t['a'], NdarrayMixin)\n\n    assert t['a'][1][1] == a[1][1]\n    assert t['a'][2][0] == a[2][0]\n\n    assert t[1]['a'][1] == a[1][1]\n    assert t[2]['a'][0] == a[2][0]\n\n    assert isinstance(t['b'], NdarrayMixin)\n\n    assert t['b'][1]['x'] == b[1]['x']\n    assert t['b'][1]['y'] == b[1]['y']\n\n    assert t[1]['b']['x'] == b[1]['x']\n    assert t[1]['b']['y'] == b[1]['y']\n\n    assert isinstance(t['c'], NdarrayMixin)\n\n    assert t['c'][1]['rx'] == c[1]['rx']\n    assert t['c'][1]['ry'] == c[1]['ry']\n\n    assert t[1]['c']['rx'] == c[1]['rx']\n    assert t[1]['c']['ry'] == c[1]['ry']\n\n    assert isinstance(t['d'], NdarrayMixin)\n\n    assert t['d'][1][0] == d[1][0]\n    assert t['d'][1][1] == d[1][1]\n\n    assert t[1]['d'][0] == d[1][0]\n    assert t[1]['d'][1] == d[1][1]\n\n    assert t.pformat(show_dtype=True) == [\n        '  a [f0, f1]     b [x, y]      c [rx, ry]      d    ',\n        '(int32, str1) (int32, str2) (float64, str3) int64[2]',\n        '------------- ------------- --------------- --------',\n        \"     (1, 'a')    (10, 'aa')   (100., 'raa')   0 .. 1\",\n        \"     (2, 'b')    (20, 'bb')   (200., 'rbb')   2 .. 3\",\n        \"     (3, 'c')    (30, 'cc')   (300., 'rcc')   4 .. 5\",\n        \"     (4, 'd')    (40, 'dd')   (400., 'rdd')   6 .. 7\"]\n\n\ndef test_possible_string_format_functions():\n    \"\"\"\n    The QuantityInfo info class for Quantity implements a\n    possible_string_format_functions() method that overrides the\n    standard pprint._possible_string_format_functions() function.\n    Test this.\n    \"\"\"\n    t = QTable([[1, 2] * u.m])\n    t['col0'].info.format = '%.3f'\n    assert t.pformat() == [' col0',\n                           '  m  ',\n                           '-----',\n                           '1.000',\n                           '2.000']\n\n    t['col0'].info.format = 'hi {:.3f}'\n    assert t.pformat() == ['  col0  ',\n                           '   m    ',\n                           '--------',\n                           'hi 1.000',\n                           'hi 2.000']\n\n    t['col0'].info.format = '.4f'\n    assert t.pformat() == [' col0 ',\n                           '  m   ',\n                           '------',\n                           '1.0000',\n                           '2.0000']\n\n\ndef test_rename_mixin_columns(mixin_cols):\n    \"\"\"\n    Rename a mixin column.\n    \"\"\"\n    t = QTable(mixin_cols)\n    tc = t.copy()\n    t.rename_column('m', 'mm')\n    assert t.colnames == ['i', 'a', 'b', 'mm']\n    if isinstance(t['mm'], table_helpers.ArrayWrapper):\n        assert np.all(t['mm'].data == tc['m'].data)\n    elif isinstance(t['mm'], coordinates.SkyCoord):\n        assert np.all(t['mm'].ra == tc['m'].ra)\n        assert np.all(t['mm'].dec == tc['m'].dec)\n    elif isinstance(t['mm'], coordinates.BaseRepresentationOrDifferential):\n        assert np.all(representation_equal(t['mm'], tc['m']))\n    else:\n        assert np.all(t['mm'] == tc['m'])\n\n\ndef test_represent_mixins_as_columns_unit_fix():\n    \"\"\"\n    If the unit is invalid for a column that gets serialized this would\n    cause an exception.  Fixed in #7481.\n    \"\"\"\n    t = Table({'a': [1, 2]}, masked=True)\n    t['a'].unit = 'not a valid unit'\n    t['a'].mask[1] = True\n    serialize.represent_mixins_as_columns(t)\n\n\ndef test_primary_data_column_gets_description():\n    \"\"\"\n    If the mixin defines a primary data column, that should get the\n    description, format, etc., so no __info__ should be needed.\n    \"\"\"\n    t = QTable({'a': [1, 2] * u.m})\n    t['a'].info.description = 'parrot'\n    t['a'].info.format = '7.2f'\n    tser = serialize.represent_mixins_as_columns(t)\n    assert '__info__' not in tser.meta['__serialized_columns__']['a']\n    assert tser['a'].format == '7.2f'\n    assert tser['a'].description == 'parrot'\n\n\ndef test_skycoord_with_velocity():\n    # Regression test for gh-6447\n    sc = SkyCoord([1], [2], unit='deg', galcen_v_sun=None)\n    t = Table([sc])\n    s = StringIO()\n    t.write(s, format='ascii.ecsv', overwrite=True)\n    s.seek(0)\n    t2 = Table.read(s.read(), format='ascii.ecsv')\n    assert skycoord_equal(t2['col0'], sc)\n\n\n@pytest.mark.parametrize('table_cls', [Table, QTable])\ndef test_ensure_input_info_is_unchanged(table_cls):\n    \"\"\"If a mixin input to a table has no info, it should stay that way.\n\n    This since having 'info' slows down slicing, etc.\n    See gh-11066.\n    \"\"\"\n    q = [1, 2] * u.m\n    assert 'info' not in q.__dict__\n    t = table_cls([q], names=['q'])\n    assert 'info' not in q.__dict__\n    t = table_cls([q])\n    assert 'info' not in q.__dict__\n    t = table_cls({'q': q})\n    assert 'info' not in q.__dict__\n    t['q2'] = q\n    assert 'info' not in q.__dict__\n    sc = SkyCoord([1, 2], [2, 3], unit='deg')\n    t['sc'] = sc\n    assert 'info' not in sc.__dict__\n\n\ndef test_bad_info_class():\n    \"\"\"Make a mixin column class that does not trigger the machinery to generate\n    a pure column representation\"\"\"\n    class MyArrayWrapper(ArrayWrapper):\n        info = ParentDtypeInfo()\n\n    t = Table()\n    t['tm'] = MyArrayWrapper([0, 1, 2])\n    out = StringIO()\n    match = r\"failed to represent column 'tm' \\(MyArrayWrapper\\) as one or more Column subclasses\"\n    with pytest.raises(TypeError, match=match):\n        represent_mixins_as_columns(t)"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-13398", "model_patch": "diff --git a/astropy/coordinates/tests/test_intermediate_transformations.py b/astropy/coordinates/tests/test_intermediate_transformations.py\nindex 7bcc900..9217658 100644\n--- a/astropy/coordinates/tests/test_intermediate_transformations.py\n+++ b/astropy/coordinates/tests/test_intermediate_transformations.py\n@@ -29,6 +29,7 @@ from astropy.coordinates.builtin_frames.intermediate_rotation_transforms import\n from astropy.coordinates.builtin_frames.utils import get_jd12\n from astropy.coordinates import solar_system_ephemeris\n from astropy.units import allclose\n+import numpy as np\n \n CI = os.environ.get('CI', False) == \"true\"\n \n", "raw_model_patch": "diff --git a/astropy/coordinates/tests/test_intermediate_transformations.py b/astropy/coordinates/tests/test_intermediate_transformations.py\nindex 7bcc900..9217658 100644\n--- a/astropy/coordinates/tests/test_intermediate_transformations.py\n+++ b/astropy/coordinates/tests/test_intermediate_transformations.py\n@@ -29,6 +29,7 @@ from astropy.coordinates.builtin_frames.intermediate_rotation_transforms import\n from astropy.coordinates.builtin_frames.utils import get_jd12\n from astropy.coordinates import solar_system_ephemeris\n from astropy.units import allclose\n+import numpy as np\n \n CI = os.environ.get('CI', False) == \"true\"\n \n", "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\"\"\"Accuracy tests for GCRS coordinate transformations, primarily to/from AltAz.\n\n\"\"\"\nimport os\nimport warnings\nfrom importlib import metadata\n\nimport pytest\nimport numpy as np\nimport erfa\n\nfrom astropy import units as u\nfrom astropy.tests.helper import assert_quantity_allclose as assert_allclose\nfrom astropy.time import Time\nfrom astropy.coordinates import (\n    EarthLocation, get_sun, ICRS, GCRS, CIRS, ITRS, AltAz, HADec,\n    PrecessedGeocentric, CartesianRepresentation, SkyCoord,\n    CartesianDifferential, SphericalRepresentation, UnitSphericalRepresentation,\n    HCRS, HeliocentricMeanEcliptic, TEME, TETE)\nfrom astropy.coordinates.solar_system import _apparent_position_in_true_coordinates, get_body\nfrom astropy.utils import iers\nfrom astropy.utils.exceptions import AstropyWarning, AstropyDeprecationWarning\nfrom astropy.utils.compat.optional_deps import HAS_JPLEPHEM\n\nfrom astropy.coordinates.angle_utilities import golden_spiral_grid\nfrom astropy.coordinates.builtin_frames.intermediate_rotation_transforms import (\n    get_location_gcrs, tete_to_itrs_mat, gcrs_to_cirs_mat, cirs_to_itrs_mat)\nfrom astropy.coordinates.builtin_frames.utils import get_jd12\nfrom astropy.coordinates import solar_system_ephemeris\nfrom astropy.units import allclose\n\nCI = os.environ.get('CI', False) == \"true\"\n\n\ndef test_icrs_cirs():\n    \"\"\"\n    Check a few cases of ICRS<->CIRS for consistency.\n\n    Also includes the CIRS<->CIRS transforms at different times, as those go\n    through ICRS\n    \"\"\"\n    usph = golden_spiral_grid(200)\n    dist = np.linspace(0., 1, len(usph)) * u.pc\n    inod = ICRS(usph)\n    iwd = ICRS(ra=usph.lon, dec=usph.lat, distance=dist)\n\n    cframe1 = CIRS()\n    cirsnod = inod.transform_to(cframe1)  # uses the default time\n    # first do a round-tripping test\n    inod2 = cirsnod.transform_to(ICRS())\n    assert_allclose(inod.ra, inod2.ra)\n    assert_allclose(inod.dec, inod2.dec)\n\n    # now check that a different time yields different answers\n    cframe2 = CIRS(obstime=Time('J2005'))\n    cirsnod2 = inod.transform_to(cframe2)\n    assert not allclose(cirsnod.ra, cirsnod2.ra, rtol=1e-8)\n    assert not allclose(cirsnod.dec, cirsnod2.dec, rtol=1e-8)\n\n    # parallax effects should be included, so with and w/o distance should be different\n    cirswd = iwd.transform_to(cframe1)\n    assert not allclose(cirswd.ra, cirsnod.ra, rtol=1e-8)\n    assert not allclose(cirswd.dec, cirsnod.dec, rtol=1e-8)\n    # and the distance should transform at least somehow\n    assert not allclose(cirswd.distance, iwd.distance, rtol=1e-8)\n\n    # now check that the cirs self-transform works as expected\n    cirsnod3 = cirsnod.transform_to(cframe1)  # should be a no-op\n    assert_allclose(cirsnod.ra, cirsnod3.ra)\n    assert_allclose(cirsnod.dec, cirsnod3.dec)\n\n    cirsnod4 = cirsnod.transform_to(cframe2)  # should be different\n    assert not allclose(cirsnod4.ra, cirsnod.ra, rtol=1e-8)\n    assert not allclose(cirsnod4.dec, cirsnod.dec, rtol=1e-8)\n\n    cirsnod5 = cirsnod4.transform_to(cframe1)  # should be back to the same\n    assert_allclose(cirsnod.ra, cirsnod5.ra)\n    assert_allclose(cirsnod.dec, cirsnod5.dec)\n\n\nusph = golden_spiral_grid(200)\ndist = np.linspace(0.5, 1, len(usph)) * u.pc\nicrs_coords = [ICRS(usph), ICRS(usph.lon, usph.lat, distance=dist)]\ngcrs_frames = [GCRS(), GCRS(obstime=Time('J2005'))]\n\n\n@pytest.mark.parametrize('icoo', icrs_coords)\ndef test_icrs_gcrs(icoo):\n    \"\"\"\n    Check ICRS<->GCRS for consistency\n    \"\"\"\n    gcrscoo = icoo.transform_to(gcrs_frames[0])  # uses the default time\n    # first do a round-tripping test\n    icoo2 = gcrscoo.transform_to(ICRS())\n    assert_allclose(icoo.distance, icoo2.distance)\n    assert_allclose(icoo.ra, icoo2.ra)\n    assert_allclose(icoo.dec, icoo2.dec)\n    assert isinstance(icoo2.data, icoo.data.__class__)\n\n    # now check that a different time yields different answers\n    gcrscoo2 = icoo.transform_to(gcrs_frames[1])\n    assert not allclose(gcrscoo.ra, gcrscoo2.ra, rtol=1e-8, atol=1e-10*u.deg)\n    assert not allclose(gcrscoo.dec, gcrscoo2.dec, rtol=1e-8, atol=1e-10*u.deg)\n\n    # now check that the cirs self-transform works as expected\n    gcrscoo3 = gcrscoo.transform_to(gcrs_frames[0])  # should be a no-op\n    assert_allclose(gcrscoo.ra, gcrscoo3.ra)\n    assert_allclose(gcrscoo.dec, gcrscoo3.dec)\n\n    gcrscoo4 = gcrscoo.transform_to(gcrs_frames[1])  # should be different\n    assert not allclose(gcrscoo4.ra, gcrscoo.ra, rtol=1e-8, atol=1e-10*u.deg)\n    assert not allclose(gcrscoo4.dec, gcrscoo.dec, rtol=1e-8, atol=1e-10*u.deg)\n\n    gcrscoo5 = gcrscoo4.transform_to(gcrs_frames[0])  # should be back to the same\n    assert_allclose(gcrscoo.ra, gcrscoo5.ra, rtol=1e-8, atol=1e-10*u.deg)\n    assert_allclose(gcrscoo.dec, gcrscoo5.dec, rtol=1e-8, atol=1e-10*u.deg)\n\n    # also make sure that a GCRS with a different geoloc/geovel gets a different answer\n    # roughly a moon-like frame\n    gframe3 = GCRS(obsgeoloc=[385000., 0, 0]*u.km, obsgeovel=[1, 0, 0]*u.km/u.s)\n    gcrscoo6 = icoo.transform_to(gframe3)  # should be different\n    assert not allclose(gcrscoo.ra, gcrscoo6.ra, rtol=1e-8, atol=1e-10*u.deg)\n    assert not allclose(gcrscoo.dec, gcrscoo6.dec, rtol=1e-8, atol=1e-10*u.deg)\n    icooviag3 = gcrscoo6.transform_to(ICRS())  # and now back to the original\n    assert_allclose(icoo.ra, icooviag3.ra)\n    assert_allclose(icoo.dec, icooviag3.dec)\n\n\n@pytest.mark.parametrize('gframe', gcrs_frames)\ndef test_icrs_gcrs_dist_diff(gframe):\n    \"\"\"\n    Check that with and without distance give different ICRS<->GCRS answers\n    \"\"\"\n    gcrsnod = icrs_coords[0].transform_to(gframe)\n    gcrswd = icrs_coords[1].transform_to(gframe)\n\n    # parallax effects should be included, so with and w/o distance should be different\n    assert not allclose(gcrswd.ra, gcrsnod.ra, rtol=1e-8, atol=1e-10*u.deg)\n    assert not allclose(gcrswd.dec, gcrsnod.dec, rtol=1e-8, atol=1e-10*u.deg)\n    # and the distance should transform at least somehow\n    assert not allclose(gcrswd.distance, icrs_coords[1].distance, rtol=1e-8,\n                        atol=1e-10*u.pc)\n\n\ndef test_cirs_to_altaz():\n    \"\"\"\n    Check the basic CIRS<->AltAz transforms.  More thorough checks implicitly\n    happen in `test_iau_fullstack`\n    \"\"\"\n    from astropy.coordinates import EarthLocation\n\n    usph = golden_spiral_grid(200)\n    dist = np.linspace(0.5, 1, len(usph)) * u.pc\n    cirs = CIRS(usph, obstime='J2000')\n    crepr = SphericalRepresentation(lon=usph.lon, lat=usph.lat, distance=dist)\n    cirscart = CIRS(crepr, obstime=cirs.obstime, representation_type=CartesianRepresentation)\n\n    loc = EarthLocation(lat=0*u.deg, lon=0*u.deg, height=0*u.m)\n    altazframe = AltAz(location=loc, obstime=Time('J2005'))\n\n    cirs2 = cirs.transform_to(altazframe).transform_to(cirs)\n    cirs3 = cirscart.transform_to(altazframe).transform_to(cirs)\n\n    # check round-tripping\n    assert_allclose(cirs.ra, cirs2.ra)\n    assert_allclose(cirs.dec, cirs2.dec)\n    assert_allclose(cirs.ra, cirs3.ra)\n    assert_allclose(cirs.dec, cirs3.dec)\n\n\ndef test_cirs_to_hadec():\n    \"\"\"\n    Check the basic CIRS<->HADec transforms.\n    \"\"\"\n    from astropy.coordinates import EarthLocation\n\n    usph = golden_spiral_grid(200)\n    dist = np.linspace(0.5, 1, len(usph)) * u.pc\n    cirs = CIRS(usph, obstime='J2000')\n    crepr = SphericalRepresentation(lon=usph.lon, lat=usph.lat, distance=dist)\n    cirscart = CIRS(crepr, obstime=cirs.obstime, representation_type=CartesianRepresentation)\n\n    loc = EarthLocation(lat=0*u.deg, lon=0*u.deg, height=0*u.m)\n    hadecframe = HADec(location=loc, obstime=Time('J2005'))\n\n    cirs2 = cirs.transform_to(hadecframe).transform_to(cirs)\n    cirs3 = cirscart.transform_to(hadecframe).transform_to(cirs)\n\n    # check round-tripping\n    assert_allclose(cirs.ra, cirs2.ra)\n    assert_allclose(cirs.dec, cirs2.dec)\n    assert_allclose(cirs.ra, cirs3.ra)\n    assert_allclose(cirs.dec, cirs3.dec)\n\n\ndef test_gcrs_itrs():\n    \"\"\"\n    Check basic GCRS<->ITRS transforms for round-tripping.\n    \"\"\"\n    usph = golden_spiral_grid(200)\n    gcrs = GCRS(usph, obstime='J2000')\n    gcrs6 = GCRS(usph, obstime='J2006')\n\n    gcrs2 = gcrs.transform_to(ITRS()).transform_to(gcrs)\n    gcrs6_2 = gcrs6.transform_to(ITRS()).transform_to(gcrs)\n\n    assert_allclose(gcrs.ra, gcrs2.ra)\n    assert_allclose(gcrs.dec, gcrs2.dec)\n    # these should be different:\n    assert not allclose(gcrs.ra, gcrs6_2.ra, rtol=1e-8)\n    assert not allclose(gcrs.dec, gcrs6_2.dec, rtol=1e-8)\n\n    # also try with the cartesian representation\n    gcrsc = gcrs.realize_frame(gcrs.data)\n    gcrsc.representation_type = CartesianRepresentation\n    gcrsc2 = gcrsc.transform_to(ITRS()).transform_to(gcrsc)\n    assert_allclose(gcrsc.spherical.lon, gcrsc2.ra)\n    assert_allclose(gcrsc.spherical.lat, gcrsc2.dec)\n\n\ndef test_cirs_itrs():\n    \"\"\"\n    Check basic CIRS<->ITRS transforms for round-tripping.\n    \"\"\"\n    usph = golden_spiral_grid(200)\n    cirs = CIRS(usph, obstime='J2000')\n    cirs6 = CIRS(usph, obstime='J2006')\n\n    cirs2 = cirs.transform_to(ITRS()).transform_to(cirs)\n    cirs6_2 = cirs6.transform_to(ITRS()).transform_to(cirs)  # different obstime\n\n    # just check round-tripping\n    assert_allclose(cirs.ra, cirs2.ra)\n    assert_allclose(cirs.dec, cirs2.dec)\n    assert not allclose(cirs.ra, cirs6_2.ra)\n    assert not allclose(cirs.dec, cirs6_2.dec)\n\n\ndef test_gcrs_cirs():\n    \"\"\"\n    Check GCRS<->CIRS transforms for round-tripping.  More complicated than the\n    above two because it's multi-hop\n    \"\"\"\n    usph = golden_spiral_grid(200)\n    gcrs = GCRS(usph, obstime='J2000')\n    gcrs6 = GCRS(usph, obstime='J2006')\n\n    gcrs2 = gcrs.transform_to(CIRS()).transform_to(gcrs)\n    gcrs6_2 = gcrs6.transform_to(CIRS()).transform_to(gcrs)\n\n    assert_allclose(gcrs.ra, gcrs2.ra)\n    assert_allclose(gcrs.dec, gcrs2.dec)\n    # these should be different:\n    assert not allclose(gcrs.ra, gcrs6_2.ra, rtol=1e-8)\n    assert not allclose(gcrs.dec, gcrs6_2.dec, rtol=1e-8)\n\n    # now try explicit intermediate pathways and ensure they're all consistent\n    gcrs3 = gcrs.transform_to(ITRS()).transform_to(CIRS()).transform_to(ITRS()).transform_to(gcrs)\n    assert_allclose(gcrs.ra, gcrs3.ra)\n    assert_allclose(gcrs.dec, gcrs3.dec)\n\n    gcrs4 = gcrs.transform_to(ICRS()).transform_to(CIRS()).transform_to(ICRS()).transform_to(gcrs)\n    assert_allclose(gcrs.ra, gcrs4.ra)\n    assert_allclose(gcrs.dec, gcrs4.dec)\n\n\ndef test_gcrs_altaz():\n    \"\"\"\n    Check GCRS<->AltAz transforms for round-tripping.  Has multiple paths\n    \"\"\"\n    from astropy.coordinates import EarthLocation\n\n    usph = golden_spiral_grid(128)\n    gcrs = GCRS(usph, obstime='J2000')[None]  # broadcast with times below\n\n    # check array times sure N-d arrays work\n    times = Time(np.linspace(2456293.25, 2456657.25, 51) * u.day,\n                 format='jd')[:, None]\n\n    loc = EarthLocation(lon=10 * u.deg, lat=80. * u.deg)\n    aaframe = AltAz(obstime=times, location=loc)\n\n    aa1 = gcrs.transform_to(aaframe)\n    aa2 = gcrs.transform_to(ICRS()).transform_to(CIRS()).transform_to(aaframe)\n    aa3 = gcrs.transform_to(ITRS()).transform_to(CIRS()).transform_to(aaframe)\n\n    # make sure they're all consistent\n    assert_allclose(aa1.alt, aa2.alt)\n    assert_allclose(aa1.az, aa2.az)\n    assert_allclose(aa1.alt, aa3.alt)\n    assert_allclose(aa1.az, aa3.az)\n\n\ndef test_gcrs_hadec():\n    \"\"\"\n    Check GCRS<->HADec transforms for round-tripping.  Has multiple paths\n    \"\"\"\n    from astropy.coordinates import EarthLocation\n\n    usph = golden_spiral_grid(128)\n    gcrs = GCRS(usph, obstime='J2000')  # broadcast with times below\n\n    # check array times sure N-d arrays work\n    times = Time(np.linspace(2456293.25, 2456657.25, 51) * u.day,\n                 format='jd')[:, np.newaxis]\n\n    loc = EarthLocation(lon=10 * u.deg, lat=80. * u.deg)\n    hdframe = HADec(obstime=times, location=loc)\n\n    hd1 = gcrs.transform_to(hdframe)\n    hd2 = gcrs.transform_to(ICRS()).transform_to(CIRS()).transform_to(hdframe)\n    hd3 = gcrs.transform_to(ITRS()).transform_to(CIRS()).transform_to(hdframe)\n\n    # make sure they're all consistent\n    assert_allclose(hd1.dec, hd2.dec)\n    assert_allclose(hd1.ha, hd2.ha)\n    assert_allclose(hd1.dec, hd3.dec)\n    assert_allclose(hd1.ha, hd3.ha)\n\n\ndef test_precessed_geocentric():\n    assert PrecessedGeocentric().equinox.jd == Time('J2000').jd\n\n    gcrs_coo = GCRS(180*u.deg, 2*u.deg, distance=10000*u.km)\n    pgeo_coo = gcrs_coo.transform_to(PrecessedGeocentric())\n    assert np.abs(gcrs_coo.ra - pgeo_coo.ra) > 10*u.marcsec\n    assert np.abs(gcrs_coo.dec - pgeo_coo.dec) > 10*u.marcsec\n    assert_allclose(gcrs_coo.distance, pgeo_coo.distance)\n\n    gcrs_roundtrip = pgeo_coo.transform_to(GCRS())\n    assert_allclose(gcrs_coo.ra, gcrs_roundtrip.ra)\n    assert_allclose(gcrs_coo.dec, gcrs_roundtrip.dec)\n    assert_allclose(gcrs_coo.distance, gcrs_roundtrip.distance)\n\n    pgeo_coo2 = gcrs_coo.transform_to(PrecessedGeocentric(equinox='B1850'))\n    assert np.abs(gcrs_coo.ra - pgeo_coo2.ra) > 1.5*u.deg\n    assert np.abs(gcrs_coo.dec - pgeo_coo2.dec) > 0.5*u.deg\n    assert_allclose(gcrs_coo.distance, pgeo_coo2.distance)\n\n    gcrs2_roundtrip = pgeo_coo2.transform_to(GCRS())\n    assert_allclose(gcrs_coo.ra, gcrs2_roundtrip.ra)\n    assert_allclose(gcrs_coo.dec, gcrs2_roundtrip.dec)\n    assert_allclose(gcrs_coo.distance, gcrs2_roundtrip.distance)\n\n\ndef test_precessed_geocentric_different_obstime():\n    # Create two PrecessedGeocentric frames with different obstime\n    precessedgeo1 = PrecessedGeocentric(obstime='2021-09-07')\n    precessedgeo2 = PrecessedGeocentric(obstime='2021-06-07')\n\n    # GCRS->PrecessedGeocentric should give different results for the two frames\n    gcrs_coord = GCRS(10*u.deg, 20*u.deg, 3*u.AU, obstime=precessedgeo1.obstime)\n    pg_coord1 = gcrs_coord.transform_to(precessedgeo1)\n    pg_coord2 = gcrs_coord.transform_to(precessedgeo2)\n    assert not pg_coord1.is_equivalent_frame(pg_coord2)\n    assert not allclose(pg_coord1.cartesian.xyz, pg_coord2.cartesian.xyz)\n\n    # Looping back to GCRS should return the original coordinate\n    loopback1 = pg_coord1.transform_to(gcrs_coord)\n    loopback2 = pg_coord2.transform_to(gcrs_coord)\n    assert loopback1.is_equivalent_frame(gcrs_coord)\n    assert loopback2.is_equivalent_frame(gcrs_coord)\n    assert_allclose(loopback1.cartesian.xyz, gcrs_coord.cartesian.xyz)\n    assert_allclose(loopback2.cartesian.xyz, gcrs_coord.cartesian.xyz)\n\n\n# shared by parametrized tests below.  Some use the whole AltAz, others use just obstime\ntotest_frames = [AltAz(location=EarthLocation(-90*u.deg, 65*u.deg),\n                       obstime=Time('J2000')),  # J2000 is often a default so this might work when others don't\n                 AltAz(location=EarthLocation(120*u.deg, -35*u.deg),\n                       obstime=Time('J2000')),\n                 AltAz(location=EarthLocation(-90*u.deg, 65*u.deg),\n                       obstime=Time('2014-01-01 00:00:00')),\n                 AltAz(location=EarthLocation(-90*u.deg, 65*u.deg),\n                       obstime=Time('2014-08-01 08:00:00')),\n                 AltAz(location=EarthLocation(120*u.deg, -35*u.deg),\n                       obstime=Time('2014-01-01 00:00:00'))\n                 ]\nMOONDIST = 385000*u.km  # approximate moon semi-major orbit axis of moon\nMOONDIST_CART = CartesianRepresentation(3**-0.5*MOONDIST, 3**-0.5*MOONDIST, 3**-0.5*MOONDIST)\nEARTHECC = 0.017 + 0.005  # roughly earth orbital eccentricity, but with an added tolerance\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_gcrs_altaz_sunish(testframe):\n    \"\"\"\n    Sanity-check that the sun is at a reasonable distance from any altaz\n    \"\"\"\n    sun = get_sun(testframe.obstime)\n\n    assert sun.frame.name == 'gcrs'\n\n    # the .to(u.au) is not necessary, it just makes the asserts on failure more readable\n    assert (EARTHECC - 1)*u.au < sun.distance.to(u.au) < (EARTHECC + 1)*u.au\n\n    sunaa = sun.transform_to(testframe)\n    assert (EARTHECC - 1)*u.au < sunaa.distance.to(u.au) < (EARTHECC + 1)*u.au\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_gcrs_altaz_moonish(testframe):\n    \"\"\"\n    Sanity-check that an object resembling the moon goes to the right place with\n    a GCRS->AltAz transformation\n    \"\"\"\n    moon = GCRS(MOONDIST_CART, obstime=testframe.obstime)\n\n    moonaa = moon.transform_to(testframe)\n\n    # now check that the distance change is similar to earth radius\n    assert 1000*u.km < np.abs(moonaa.distance - moon.distance).to(u.au) < 7000*u.km\n\n    # now check that it round-trips\n    moon2 = moonaa.transform_to(moon)\n    assert_allclose(moon.cartesian.xyz, moon2.cartesian.xyz)\n\n    # also should add checks that the alt/az are different for different earth locations\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_gcrs_altaz_bothroutes(testframe):\n    \"\"\"\n    Repeat of both the moonish and sunish tests above to make sure the two\n    routes through the coordinate graph are consistent with each other\n    \"\"\"\n    sun = get_sun(testframe.obstime)\n    sunaa_viaicrs = sun.transform_to(ICRS()).transform_to(testframe)\n    sunaa_viaitrs = sun.transform_to(ITRS(obstime=testframe.obstime)).transform_to(testframe)\n\n    moon = GCRS(MOONDIST_CART, obstime=testframe.obstime)\n    moonaa_viaicrs = moon.transform_to(ICRS()).transform_to(testframe)\n    moonaa_viaitrs = moon.transform_to(ITRS(obstime=testframe.obstime)).transform_to(testframe)\n\n    assert_allclose(sunaa_viaicrs.cartesian.xyz, sunaa_viaitrs.cartesian.xyz)\n    assert_allclose(moonaa_viaicrs.cartesian.xyz, moonaa_viaitrs.cartesian.xyz)\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_cirs_altaz_moonish(testframe):\n    \"\"\"\n    Sanity-check that an object resembling the moon goes to the right place with\n    a CIRS<->AltAz transformation\n    \"\"\"\n    moon = CIRS(MOONDIST_CART, obstime=testframe.obstime)\n\n    moonaa = moon.transform_to(testframe)\n    assert 1000*u.km < np.abs(moonaa.distance - moon.distance).to(u.km) < 7000*u.km\n\n    # now check that it round-trips\n    moon2 = moonaa.transform_to(moon)\n    assert_allclose(moon.cartesian.xyz, moon2.cartesian.xyz)\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_cirs_altaz_nodist(testframe):\n    \"\"\"\n    Check that a UnitSphericalRepresentation coordinate round-trips for the\n    CIRS<->AltAz transformation.\n    \"\"\"\n    coo0 = CIRS(UnitSphericalRepresentation(10*u.deg, 20*u.deg), obstime=testframe.obstime)\n\n    # check that it round-trips\n    coo1 = coo0.transform_to(testframe).transform_to(coo0)\n    assert_allclose(coo0.cartesian.xyz, coo1.cartesian.xyz)\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_cirs_icrs_moonish(testframe):\n    \"\"\"\n    check that something like the moon goes to about the right distance from the\n    ICRS origin when starting from CIRS\n    \"\"\"\n    moonish = CIRS(MOONDIST_CART, obstime=testframe.obstime)\n    moonicrs = moonish.transform_to(ICRS())\n\n    assert 0.97*u.au < moonicrs.distance < 1.03*u.au\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_gcrs_icrs_moonish(testframe):\n    \"\"\"\n    check that something like the moon goes to about the right distance from the\n    ICRS origin when starting from GCRS\n    \"\"\"\n    moonish = GCRS(MOONDIST_CART, obstime=testframe.obstime)\n    moonicrs = moonish.transform_to(ICRS())\n\n    assert 0.97*u.au < moonicrs.distance < 1.03*u.au\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_icrs_gcrscirs_sunish(testframe):\n    \"\"\"\n    check that the ICRS barycenter goes to about the right distance from various\n    ~geocentric frames (other than testframe)\n    \"\"\"\n    # slight offset to avoid divide-by-zero errors\n    icrs = ICRS(0*u.deg, 0*u.deg, distance=10*u.km)\n\n    gcrs = icrs.transform_to(GCRS(obstime=testframe.obstime))\n    assert (EARTHECC - 1)*u.au < gcrs.distance.to(u.au) < (EARTHECC + 1)*u.au\n\n    cirs = icrs.transform_to(CIRS(obstime=testframe.obstime))\n    assert (EARTHECC - 1)*u.au < cirs.distance.to(u.au) < (EARTHECC + 1)*u.au\n\n    itrs = icrs.transform_to(ITRS(obstime=testframe.obstime))\n    assert (EARTHECC - 1)*u.au < itrs.spherical.distance.to(u.au) < (EARTHECC + 1)*u.au\n\n\n@pytest.mark.parametrize('testframe', totest_frames)\ndef test_icrs_altaz_moonish(testframe):\n    \"\"\"\n    Check that something expressed in *ICRS* as being moon-like goes to the\n    right AltAz distance\n    \"\"\"\n    # we use epv00 instead of get_sun because get_sun includes aberration\n    earth_pv_helio, earth_pv_bary = erfa.epv00(*get_jd12(testframe.obstime, 'tdb'))\n    earth_icrs_xyz = earth_pv_bary[0]*u.au\n    moonoffset = [0, 0, MOONDIST.value]*MOONDIST.unit\n    moonish_icrs = ICRS(CartesianRepresentation(earth_icrs_xyz + moonoffset))\n    moonaa = moonish_icrs.transform_to(testframe)\n\n    # now check that the distance change is similar to earth radius\n    assert 1000*u.km < np.abs(moonaa.distance - MOONDIST).to(u.au) < 7000*u.km\n\n\ndef test_gcrs_self_transform_closeby():\n    \"\"\"\n    Tests GCRS self transform for objects which are nearby and thus\n    have reasonable parallax.\n\n    Moon positions were originally created using JPL DE432s ephemeris.\n\n    The two lunar positions (one geocentric, one at a defined location)\n    are created via a transformation from ICRS to two different GCRS frames.\n\n    We test that the GCRS-GCRS self transform can correctly map one GCRS\n    frame onto the other.\n    \"\"\"\n    t = Time(\"2014-12-25T07:00\")\n    moon_geocentric = SkyCoord(GCRS(318.10579159*u.deg,\n                                    -11.65281165*u.deg,\n                                    365042.64880308*u.km, obstime=t))\n\n    # this is the location of the Moon as seen from La Palma\n    obsgeoloc = [-5592982.59658935, -63054.1948592, 3059763.90102216]*u.m\n    obsgeovel = [4.59798494, -407.84677071, 0.]*u.m/u.s\n    moon_lapalma = SkyCoord(GCRS(318.7048445*u.deg,\n                                 -11.98761996*u.deg,\n                                 369722.8231031*u.km,\n                                 obstime=t,\n                                 obsgeoloc=obsgeoloc,\n                                 obsgeovel=obsgeovel))\n\n    transformed = moon_geocentric.transform_to(moon_lapalma.frame)\n    delta = transformed.separation_3d(moon_lapalma)\n    assert_allclose(delta, 0.0*u.m, atol=1*u.m)\n\n\ndef test_teme_itrf():\n    \"\"\"\n    Test case transform from TEME to ITRF.\n\n    Test case derives from example on appendix C of Vallado, Crawford, Hujsak & Kelso (2006).\n    See https://celestrak.com/publications/AIAA/2006-6753/AIAA-2006-6753-Rev2.pdf\n    \"\"\"\n    v_itrf = CartesianDifferential(-3.225636520, -2.872451450, 5.531924446,\n                                   unit=u.km/u.s)\n    p_itrf = CartesianRepresentation(-1033.479383, 7901.2952740, 6380.35659580,\n                                     unit=u.km, differentials={'s': v_itrf})\n    t = Time(\"2004-04-06T07:51:28.386\")\n\n    teme = ITRS(p_itrf, obstime=t).transform_to(TEME(obstime=t))\n    v_teme = CartesianDifferential(-4.746131487, 0.785818041, 5.531931288,\n                                   unit=u.km/u.s)\n    p_teme = CartesianRepresentation(5094.18016210, 6127.64465050, 6380.34453270,\n                                     unit=u.km, differentials={'s': v_teme})\n\n    assert_allclose(teme.cartesian.without_differentials().xyz,\n                    p_teme.without_differentials().xyz, atol=30*u.cm)\n\n    assert_allclose(teme.cartesian.differentials['s'].d_xyz,\n                    p_teme.differentials['s'].d_xyz, atol=1.0*u.cm/u.s)\n\n    # test round trip\n    itrf = teme.transform_to(ITRS(obstime=t))\n    assert_allclose(\n        itrf.cartesian.without_differentials().xyz,\n        p_itrf.without_differentials().xyz,\n        atol=100*u.cm\n    )\n    assert_allclose(\n        itrf.cartesian.differentials['s'].d_xyz,\n        p_itrf.differentials['s'].d_xyz,\n        atol=1*u.cm/u.s\n    )\n\n\ndef test_precessedgeocentric_loopback():\n    from_coo = PrecessedGeocentric(1*u.deg, 2*u.deg, 3*u.AU,\n                                   obstime='2001-01-01', equinox='2001-01-01')\n\n    # Change just the obstime\n    to_frame = PrecessedGeocentric(obstime='2001-06-30', equinox='2001-01-01')\n\n    explicit_coo = from_coo.transform_to(ICRS()).transform_to(to_frame)\n    implicit_coo = from_coo.transform_to(to_frame)\n\n    # Confirm that the explicit transformation changes the coordinate\n    assert not allclose(explicit_coo.ra, from_coo.ra, rtol=1e-10)\n    assert not allclose(explicit_coo.dec, from_coo.dec, rtol=1e-10)\n    assert not allclose(explicit_coo.distance, from_coo.distance, rtol=1e-10)\n\n    # Confirm that the loopback matches the explicit transformation\n    assert_allclose(explicit_coo.ra, implicit_coo.ra, rtol=1e-10)\n    assert_allclose(explicit_coo.dec, implicit_coo.dec, rtol=1e-10)\n    assert_allclose(explicit_coo.distance, implicit_coo.distance, rtol=1e-10)\n\n    # Change just the equinox\n    to_frame = PrecessedGeocentric(obstime='2001-01-01', equinox='2001-06-30')\n\n    explicit_coo = from_coo.transform_to(ICRS()).transform_to(to_frame)\n    implicit_coo = from_coo.transform_to(to_frame)\n\n    # Confirm that the explicit transformation changes the direction but not the distance\n    assert not allclose(explicit_coo.ra, from_coo.ra, rtol=1e-10)\n    assert not allclose(explicit_coo.dec, from_coo.dec, rtol=1e-10)\n    assert allclose(explicit_coo.distance, from_coo.distance, rtol=1e-10)\n\n    # Confirm that the loopback matches the explicit transformation\n    assert_allclose(explicit_coo.ra, implicit_coo.ra, rtol=1e-10)\n    assert_allclose(explicit_coo.dec, implicit_coo.dec, rtol=1e-10)\n    assert_allclose(explicit_coo.distance, implicit_coo.distance, rtol=1e-10)\n\n\ndef test_teme_loopback():\n    from_coo = TEME(1*u.AU, 2*u.AU, 3*u.AU, obstime='2001-01-01')\n    to_frame = TEME(obstime='2001-06-30')\n\n    explicit_coo = from_coo.transform_to(ICRS()).transform_to(to_frame)\n    implicit_coo = from_coo.transform_to(to_frame)\n\n    # Confirm that the explicit transformation changes the coordinate\n    assert not allclose(explicit_coo.cartesian.xyz, from_coo.cartesian.xyz, rtol=1e-10)\n\n    # Confirm that the loopback matches the explicit transformation\n    assert_allclose(explicit_coo.cartesian.xyz, implicit_coo.cartesian.xyz, rtol=1e-10)\n\n\n@pytest.mark.remote_data\ndef test_earth_orientation_table(monkeypatch):\n    \"\"\"Check that we can set the IERS table used as Earth Reference.\n\n    Use the here and now to be sure we get a difference.\n    \"\"\"\n    monkeypatch.setattr('astropy.utils.iers.conf.auto_download', True)\n    t = Time.now()\n    location = EarthLocation(lat=0*u.deg, lon=0*u.deg)\n    altaz = AltAz(location=location, obstime=t)\n    sc = SkyCoord(1*u.deg, 2*u.deg)\n    # Default: uses IERS_Auto, which will give a prediction.\n    # Note: tests run with warnings turned into errors, so it is\n    # meaningful if this passes.\n    if CI:\n        with warnings.catch_warnings():\n            # Server occasionally blocks IERS download in CI.\n            warnings.filterwarnings('ignore', message=r'.*using local IERS-B.*')\n            # This also captures unclosed socket warning that is ignored in setup.cfg\n            warnings.filterwarnings('ignore', message=r'.*unclosed.*')\n            altaz_auto = sc.transform_to(altaz)\n    else:\n        altaz_auto = sc.transform_to(altaz)  # No warnings\n\n    with iers.earth_orientation_table.set(iers.IERS_B.open()):\n        with pytest.warns(AstropyWarning, match='after IERS data'):\n            altaz_b = sc.transform_to(altaz)\n\n    sep_b_auto = altaz_b.separation(altaz_auto)\n    assert_allclose(sep_b_auto, 0.0*u.deg, atol=1*u.arcsec)\n    assert sep_b_auto > 10*u.microarcsecond\n\n    # Check we returned to regular IERS system.\n    altaz_auto2 = sc.transform_to(altaz)\n    assert altaz_auto2.separation(altaz_auto) == 0.\n\n\n@pytest.mark.remote_data\n@pytest.mark.skipif(not HAS_JPLEPHEM, reason='requires jplephem')\ndef test_ephemerides():\n    \"\"\"\n    We test that using different ephemerides gives very similar results\n    for transformations\n    \"\"\"\n    t = Time(\"2014-12-25T07:00\")\n    moon = SkyCoord(GCRS(318.10579159*u.deg,\n                         -11.65281165*u.deg,\n                         365042.64880308*u.km, obstime=t))\n\n    icrs_frame = ICRS()\n    hcrs_frame = HCRS(obstime=t)\n    ecl_frame = HeliocentricMeanEcliptic(equinox=t)\n    cirs_frame = CIRS(obstime=t)\n\n    moon_icrs_builtin = moon.transform_to(icrs_frame)\n    moon_hcrs_builtin = moon.transform_to(hcrs_frame)\n    moon_helioecl_builtin = moon.transform_to(ecl_frame)\n    moon_cirs_builtin = moon.transform_to(cirs_frame)\n\n    with solar_system_ephemeris.set('jpl'):\n        moon_icrs_jpl = moon.transform_to(icrs_frame)\n        moon_hcrs_jpl = moon.transform_to(hcrs_frame)\n        moon_helioecl_jpl = moon.transform_to(ecl_frame)\n        moon_cirs_jpl = moon.transform_to(cirs_frame)\n\n    # most transformations should differ by an amount which is\n    # non-zero but of order milliarcsecs\n    sep_icrs = moon_icrs_builtin.separation(moon_icrs_jpl)\n    sep_hcrs = moon_hcrs_builtin.separation(moon_hcrs_jpl)\n    sep_helioecl = moon_helioecl_builtin.separation(moon_helioecl_jpl)\n    sep_cirs = moon_cirs_builtin.separation(moon_cirs_jpl)\n\n    assert_allclose([sep_icrs, sep_hcrs, sep_helioecl], 0.0*u.deg, atol=10*u.mas)\n    assert all(sep > 10*u.microarcsecond for sep in (sep_icrs, sep_hcrs, sep_helioecl))\n\n    # CIRS should be the same\n    assert_allclose(sep_cirs, 0.0*u.deg, atol=1*u.microarcsecond)\n\n\ndef test_tete_transforms():\n    \"\"\"\n    We test the TETE transforms for proper behaviour here.\n\n    The TETE transforms are tested for accuracy against JPL Horizons in\n    test_solar_system.py. Here we are looking to check for consistency and\n    errors in the self transform.\n    \"\"\"\n    loc = EarthLocation.from_geodetic(\"-22\u00b057'35.1\", \"-67\u00b047'14.1\", 5186*u.m)\n    time = Time('2020-04-06T00:00')\n    p, v = loc.get_gcrs_posvel(time)\n\n    gcrs_frame = GCRS(obstime=time, obsgeoloc=p, obsgeovel=v)\n    moon = SkyCoord(169.24113968*u.deg, 10.86086666*u.deg, 358549.25381755*u.km, frame=gcrs_frame)\n\n    tete_frame = TETE(obstime=time, location=loc)\n    # need to set obsgeoloc/vel explicitly or skycoord behaviour over-writes\n    tete_geo = TETE(obstime=time, location=EarthLocation(*([0, 0, 0]*u.km)))\n\n    # test self-transform by comparing to GCRS-TETE-ITRS-TETE route\n    tete_coo1 = moon.transform_to(tete_frame)\n    tete_coo2 = moon.transform_to(tete_geo)\n    assert_allclose(tete_coo1.separation_3d(tete_coo2), 0*u.mm, atol=1*u.mm)\n\n    # test TETE-ITRS transform by comparing GCRS-CIRS-ITRS to GCRS-TETE-ITRS\n    itrs1 = moon.transform_to(CIRS()).transform_to(ITRS())\n    itrs2 = moon.transform_to(TETE()).transform_to(ITRS())\n    assert_allclose(itrs1.separation_3d(itrs2), 0*u.mm, atol=1*u.mm)\n\n    # test round trip GCRS->TETE->GCRS\n    new_moon = moon.transform_to(TETE()).transform_to(moon)\n    assert_allclose(new_moon.separation_3d(moon), 0*u.mm, atol=1*u.mm)\n\n    # test round trip via ITRS\n    tete_rt = tete_coo1.transform_to(ITRS(obstime=time)).transform_to(tete_coo1)\n    assert_allclose(tete_rt.separation_3d(tete_coo1), 0*u.mm, atol=1*u.mm)\n\n    # ensure deprecated routine remains consistent\n    # make sure test raises warning!\n    with pytest.warns(AstropyDeprecationWarning, match='The use of'):\n        tete_alt = _apparent_position_in_true_coordinates(moon)\n    assert_allclose(tete_coo1.separation_3d(tete_alt), 0*u.mm, atol=100*u.mm)\n\n\ndef test_straight_overhead():\n    \"\"\"\n    With a precise CIRS<->AltAz transformation this should give Alt=90 exactly\n\n    If the CIRS self-transform breaks it won't, due to improper treatment of aberration\n    \"\"\"\n    t = Time('J2010')\n    obj = EarthLocation(-1*u.deg, 52*u.deg, height=10.*u.km)\n    home = EarthLocation(-1*u.deg, 52*u.deg, height=0.*u.km)\n\n    # An object that appears straight overhead - FOR A GEOCENTRIC OBSERVER.\n    # Note, this won't be overhead for a topocentric observer because of\n    # aberration.\n    cirs_geo = obj.get_itrs(t).transform_to(CIRS(obstime=t))\n\n    # now get the Geocentric CIRS position of observatory\n    obsrepr = home.get_itrs(t).transform_to(CIRS(obstime=t)).cartesian\n\n    # topocentric CIRS position of a straight overhead object\n    cirs_repr = cirs_geo.cartesian - obsrepr\n\n    # create a CIRS object that appears straight overhead for a TOPOCENTRIC OBSERVER\n    topocentric_cirs_frame = CIRS(obstime=t, location=home)\n    cirs_topo = topocentric_cirs_frame.realize_frame(cirs_repr)\n\n    # Check AltAz (though Azimuth can be anything so is not tested).\n    aa = cirs_topo.transform_to(AltAz(obstime=t, location=home))\n    assert_allclose(aa.alt, 90*u.deg, atol=1*u.uas, rtol=0)\n\n    # Check HADec.\n    hd = cirs_topo.transform_to(HADec(obstime=t, location=home))\n    assert_allclose(hd.ha, 0*u.hourangle, atol=1*u.uas, rtol=0)\n    assert_allclose(hd.dec, 52*u.deg, atol=1*u.uas, rtol=0)\n\n\ndef jplephem_ge(minversion):\n    \"\"\"Check if jplephem is installed and has version >= minversion.\"\"\"\n    # This is a separate routine since somehow with pyinstaller the stanza\n    # not HAS_JPLEPHEM or metadata.version('jplephem') < '2.15'\n    # leads to a module not found error.\n    try:\n        return HAS_JPLEPHEM and metadata.version('jplephem') >= minversion\n    except Exception:\n        return False\n\n\n@pytest.mark.remote_data\n@pytest.mark.skipif(not jplephem_ge('2.15'), reason='requires jplephem >= 2.15')\ndef test_aa_hd_high_precision():\n    \"\"\"These tests are provided by @mkbrewer - see issue #10356.\n\n    The code that produces them agrees very well (<0.5 mas) with SkyField once Polar motion\n    is turned off, but SkyField does not include polar motion, so a comparison to Skyfield\n    or JPL Horizons will be ~1\" off.\n\n    The absence of polar motion within Skyfield and the disagreement between Skyfield and Horizons\n    make high precision comparisons to those codes difficult.\n\n    Updated 2020-11-29, after the comparison between codes became even better,\n    down to 100 nas.\n\n    NOTE: the agreement reflects consistency in approach between two codes,\n    not necessarily absolute precision.  If this test starts failing, the\n    tolerance can and should be weakened *if* it is clear that the change is\n    due to an improvement (e.g., a new IAU precession model).\n\n    \"\"\"\n    lat = -22.959748*u.deg\n    lon = -67.787260*u.deg\n    elev = 5186*u.m\n    loc = EarthLocation.from_geodetic(lon, lat, elev)\n    # Note: at this level of precision for the comparison, we have to include\n    # the location in the time, as it influences the transformation to TDB.\n    t = Time('2017-04-06T00:00:00.0', location=loc)\n    with solar_system_ephemeris.set('de430'):\n        moon = get_body('moon', t, loc)\n        moon_aa = moon.transform_to(AltAz(obstime=t, location=loc))\n        moon_hd = moon.transform_to(HADec(obstime=t, location=loc))\n\n    # Numbers from\n    # https://github.com/astropy/astropy/pull/11073#issuecomment-735486271\n    # updated in https://github.com/astropy/astropy/issues/11683\n    TARGET_AZ, TARGET_EL = 15.032673509956*u.deg, 50.303110133923*u.deg\n    TARGET_DISTANCE = 376252883.247239*u.m\n    assert_allclose(moon_aa.az, TARGET_AZ, atol=0.1*u.uas, rtol=0)\n    assert_allclose(moon_aa.alt, TARGET_EL, atol=0.1*u.uas, rtol=0)\n    assert_allclose(moon_aa.distance, TARGET_DISTANCE, atol=0.1*u.mm, rtol=0)\n    ha, dec = erfa.ae2hd(moon_aa.az.to_value(u.radian), moon_aa.alt.to_value(u.radian),\n                         lat.to_value(u.radian))\n    ha = u.Quantity(ha, u.radian, copy=False)\n    dec = u.Quantity(dec, u.radian, copy=False)\n    assert_allclose(moon_hd.ha, ha, atol=0.1*u.uas, rtol=0)\n    assert_allclose(moon_hd.dec, dec, atol=0.1*u.uas, rtol=0)\n\n\ndef test_aa_high_precision_nodata():\n    \"\"\"\n    These tests are designed to ensure high precision alt-az transforms.\n\n    They are a slight fudge since the target values come from astropy itself. They are generated\n    with a version of the code that passes the tests above, but for the internal solar system\n    ephemerides to avoid the use of remote data.\n    \"\"\"\n    # Last updated when switching to erfa 2.0.0 and its moon98 function.\n    TARGET_AZ, TARGET_EL = 15.03231495*u.deg, 50.3027193*u.deg\n    lat = -22.959748*u.deg\n    lon = -67.787260*u.deg\n    elev = 5186*u.m\n    loc = EarthLocation.from_geodetic(lon, lat, elev)\n    t = Time('2017-04-06T00:00:00.0')\n\n    moon = get_body('moon', t, loc)\n    moon_aa = moon.transform_to(AltAz(obstime=t, location=loc))\n    assert_allclose(moon_aa.az - TARGET_AZ, 0*u.mas, atol=0.5*u.mas)\n    assert_allclose(moon_aa.alt - TARGET_EL, 0*u.mas, atol=0.5*u.mas)\n\n\nclass TestGetLocationGCRS:\n    # TETE and CIRS use get_location_gcrs to get obsgeoloc and obsgeovel\n    # with knowledge of some of the matrices. Check that this is consistent\n    # with a direct transformation.\n    def setup_class(cls):\n        cls.loc = loc = EarthLocation.from_geodetic(\n            np.linspace(0, 360, 6)*u.deg, np.linspace(-90, 90, 6)*u.deg, 100*u.m)\n        cls.obstime = obstime = Time(np.linspace(2000, 2010, 6), format='jyear')\n        # Get comparison via a full transformation.  We do not use any methods\n        # of EarthLocation, since those depend on the fast transform.\n        loc_itrs = ITRS(loc.x, loc.y, loc.z, obstime=obstime)\n        zeros = np.broadcast_to(0. * (u.km / u.s), (3,) + loc_itrs.shape, subok=True)\n        loc_itrs.data.differentials['s'] = CartesianDifferential(zeros)\n        loc_gcrs_cart = loc_itrs.transform_to(GCRS(obstime=obstime)).cartesian\n        cls.obsgeoloc = loc_gcrs_cart.without_differentials()\n        cls.obsgeovel = loc_gcrs_cart.differentials['s'].to_cartesian()\n\n    def check_obsgeo(self, obsgeoloc, obsgeovel):\n        assert_allclose(obsgeoloc.xyz, self.obsgeoloc.xyz, atol=.1*u.um, rtol=0.)\n        assert_allclose(obsgeovel.xyz, self.obsgeovel.xyz, atol=.1*u.mm/u.s, rtol=0.)\n\n    def test_get_gcrs_posvel(self):\n        # Really just a sanity check\n        self.check_obsgeo(*self.loc.get_gcrs_posvel(self.obstime))\n\n    def test_tete_quick(self):\n        # Following copied from intermediate_rotation_transforms.gcrs_to_tete\n        rbpn = erfa.pnm06a(*get_jd12(self.obstime, 'tt'))\n        loc_gcrs_frame = get_location_gcrs(self.loc, self.obstime,\n                                           tete_to_itrs_mat(self.obstime, rbpn=rbpn),\n                                           rbpn)\n        self.check_obsgeo(loc_gcrs_frame.obsgeoloc, loc_gcrs_frame.obsgeovel)\n\n    def test_cirs_quick(self):\n        cirs_frame = CIRS(location=self.loc, obstime=self.obstime)\n        # Following copied from intermediate_rotation_transforms.gcrs_to_cirs\n        pmat = gcrs_to_cirs_mat(cirs_frame.obstime)\n        loc_gcrs_frame = get_location_gcrs(self.loc, self.obstime,\n                                           cirs_to_itrs_mat(cirs_frame.obstime), pmat)\n        self.check_obsgeo(loc_gcrs_frame.obsgeoloc, loc_gcrs_frame.obsgeovel)"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-13453", "model_patch": "diff --git a/astropy/io/ascii/tests/test_html.py b/astropy/io/ascii/tests/test_html.py\nindex 3a91233..bc99173 100644\n--- a/astropy/io/ascii/tests/test_html.py\n+++ b/astropy/io/ascii/tests/test_html.py\n@@ -426,6 +426,210 @@ def test_multicolumn_write():\n     assert out == expected.strip()\n \n \n+def test_write_table_formatted_columns():\n+    \"\"\"\n+    Test to make sure that the HTML writer writes out using the\n+    supplied formatting.\n+    \"\"\"\n+\n+    col1 = [1, 2]\n+    col2 = [1.234567e-11, -9.876543e11]\n+    formats = {\"C1\": \"04d\", \"C2\": \".2e\"}\n+    table = Table([col1, col2], names=formats.keys())\n+\n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>C1</th>\n+     <th>C2</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>0001</td>\n+    <td>1.23e-11</td>\n+   </tr>\n+   <tr>\n+    <td>0002</td>\n+    <td>-9.88e+11</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    with StringIO() as sp:\n+        table.write(sp, format=\"html\", formats=formats)\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n+def test_write_table_formatted_columns_lambda():\n+    \"\"\"\n+    Test HTML writer with lambda function formatting (from the original issue).\n+    \"\"\"\n+    from astropy.table import Table\n+    from io import StringIO\n+\n+    # generate table\n+    t = Table([(1.23875234858e-24, 3.2348748432e-15), (2, 4)], names=('a', 'b'))\n+    \n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>a</th>\n+     <th>b</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>1.24e-24</td>\n+    <td>2</td>\n+   </tr>\n+   <tr>\n+    <td>3.23e-15</td>\n+    <td>4</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    \n+    with StringIO() as sp:\n+        t.write(sp, format=\"html\", formats={\"a\": lambda x: f\"{x:.2e}\"})\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n+def test_write_table_formatted_columns_mixed_types():\n+    \"\"\"\n+    Test HTML writer with different column types and formatting.\n+    \"\"\"\n+    from astropy.table import Table\n+    from io import StringIO\n+    \n+    # Test with mixed data types\n+    col1 = [1, 2, 3]  # integers\n+    col2 = [1.23456, 2.34567, 3.45678]  # floats\n+    col3 = ['hello', 'world', 'test']  # strings\n+    \n+    table = Table([col1, col2, col3], names=('int_col', 'float_col', 'str_col'))\n+    \n+    formats = {\n+        'int_col': '03d',  # zero-padded integers\n+        'float_col': '.1f',  # one decimal place\n+        'str_col': lambda x: x.upper()  # uppercase strings\n+    }\n+    \n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>int_col</th>\n+     <th>float_col</th>\n+     <th>str_col</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>001</td>\n+    <td>1.2</td>\n+    <td>HELLO</td>\n+   </tr>\n+   <tr>\n+    <td>002</td>\n+    <td>2.3</td>\n+    <td>WORLD</td>\n+   </tr>\n+   <tr>\n+    <td>003</td>\n+    <td>3.5</td>\n+    <td>TEST</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    \n+    with StringIO() as sp:\n+        table.write(sp, format=\"html\", formats=formats)\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n+def test_write_table_partial_formatting():\n+    \"\"\"\n+    Test HTML writer when only some columns have formatting specified.\n+    \"\"\"\n+    from astropy.table import Table\n+    from io import StringIO\n+    \n+    col1 = [1, 2, 3]\n+    col2 = [1.23456, 2.34567, 3.45678]\n+    col3 = [10, 20, 30]\n+    \n+    table = Table([col1, col2, col3], names=('A', 'B', 'C'))\n+    \n+    # Only format column B\n+    formats = {'B': '.2f'}\n+    \n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>A</th>\n+     <th>B</th>\n+     <th>C</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>1</td>\n+    <td>1.23</td>\n+    <td>10</td>\n+   </tr>\n+   <tr>\n+    <td>2</td>\n+    <td>2.35</td>\n+    <td>20</td>\n+   </tr>\n+   <tr>\n+    <td>3</td>\n+    <td>3.46</td>\n+    <td>30</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    \n+    with StringIO() as sp:\n+        table.write(sp, format=\"html\", formats=formats)\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n @pytest.mark.skipif('not HAS_BLEACH')\n def test_multicolumn_write_escape():\n     \"\"\"\n", "raw_model_patch": "diff --git a/astropy/io/ascii/tests/test_html.py b/astropy/io/ascii/tests/test_html.py\nindex 3a91233..bc99173 100644\n--- a/astropy/io/ascii/tests/test_html.py\n+++ b/astropy/io/ascii/tests/test_html.py\n@@ -426,6 +426,210 @@ def test_multicolumn_write():\n     assert out == expected.strip()\n \n \n+def test_write_table_formatted_columns():\n+    \"\"\"\n+    Test to make sure that the HTML writer writes out using the\n+    supplied formatting.\n+    \"\"\"\n+\n+    col1 = [1, 2]\n+    col2 = [1.234567e-11, -9.876543e11]\n+    formats = {\"C1\": \"04d\", \"C2\": \".2e\"}\n+    table = Table([col1, col2], names=formats.keys())\n+\n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>C1</th>\n+     <th>C2</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>0001</td>\n+    <td>1.23e-11</td>\n+   </tr>\n+   <tr>\n+    <td>0002</td>\n+    <td>-9.88e+11</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    with StringIO() as sp:\n+        table.write(sp, format=\"html\", formats=formats)\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n+def test_write_table_formatted_columns_lambda():\n+    \"\"\"\n+    Test HTML writer with lambda function formatting (from the original issue).\n+    \"\"\"\n+    from astropy.table import Table\n+    from io import StringIO\n+\n+    # generate table\n+    t = Table([(1.23875234858e-24, 3.2348748432e-15), (2, 4)], names=('a', 'b'))\n+    \n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>a</th>\n+     <th>b</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>1.24e-24</td>\n+    <td>2</td>\n+   </tr>\n+   <tr>\n+    <td>3.23e-15</td>\n+    <td>4</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    \n+    with StringIO() as sp:\n+        t.write(sp, format=\"html\", formats={\"a\": lambda x: f\"{x:.2e}\"})\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n+def test_write_table_formatted_columns_mixed_types():\n+    \"\"\"\n+    Test HTML writer with different column types and formatting.\n+    \"\"\"\n+    from astropy.table import Table\n+    from io import StringIO\n+    \n+    # Test with mixed data types\n+    col1 = [1, 2, 3]  # integers\n+    col2 = [1.23456, 2.34567, 3.45678]  # floats\n+    col3 = ['hello', 'world', 'test']  # strings\n+    \n+    table = Table([col1, col2, col3], names=('int_col', 'float_col', 'str_col'))\n+    \n+    formats = {\n+        'int_col': '03d',  # zero-padded integers\n+        'float_col': '.1f',  # one decimal place\n+        'str_col': lambda x: x.upper()  # uppercase strings\n+    }\n+    \n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>int_col</th>\n+     <th>float_col</th>\n+     <th>str_col</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>001</td>\n+    <td>1.2</td>\n+    <td>HELLO</td>\n+   </tr>\n+   <tr>\n+    <td>002</td>\n+    <td>2.3</td>\n+    <td>WORLD</td>\n+   </tr>\n+   <tr>\n+    <td>003</td>\n+    <td>3.5</td>\n+    <td>TEST</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    \n+    with StringIO() as sp:\n+        table.write(sp, format=\"html\", formats=formats)\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n+def test_write_table_partial_formatting():\n+    \"\"\"\n+    Test HTML writer when only some columns have formatting specified.\n+    \"\"\"\n+    from astropy.table import Table\n+    from io import StringIO\n+    \n+    col1 = [1, 2, 3]\n+    col2 = [1.23456, 2.34567, 3.45678]\n+    col3 = [10, 20, 30]\n+    \n+    table = Table([col1, col2, col3], names=('A', 'B', 'C'))\n+    \n+    # Only format column B\n+    formats = {'B': '.2f'}\n+    \n+    expected = \"\"\"\\\n+<html>\n+ <head>\n+  <meta charset=\"utf-8\"/>\n+  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n+ </head>\n+ <body>\n+  <table>\n+   <thead>\n+    <tr>\n+     <th>A</th>\n+     <th>B</th>\n+     <th>C</th>\n+    </tr>\n+   </thead>\n+   <tr>\n+    <td>1</td>\n+    <td>1.23</td>\n+    <td>10</td>\n+   </tr>\n+   <tr>\n+    <td>2</td>\n+    <td>2.35</td>\n+    <td>20</td>\n+   </tr>\n+   <tr>\n+    <td>3</td>\n+    <td>3.46</td>\n+    <td>30</td>\n+   </tr>\n+  </table>\n+ </body>\n+</html>\n+    \"\"\"\n+    \n+    with StringIO() as sp:\n+        table.write(sp, format=\"html\", formats=formats)\n+        out = sp.getvalue().strip()\n+    assert out == expected.strip()\n+\n+\n @pytest.mark.skipif('not HAS_BLEACH')\n def test_multicolumn_write_escape():\n     \"\"\"\n", "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\n\"\"\"\nThis module tests some of the methods related to the ``HTML``\nreader/writer and aims to document its functionality.\n\nRequires `BeautifulSoup <http://www.crummy.com/software/BeautifulSoup/>`_\nto be installed.\n\"\"\"\n\nfrom io import StringIO\n\nfrom astropy.io.ascii import html\nfrom astropy.io.ascii import core\nfrom astropy.table import Table\n\nimport pytest\nimport numpy as np\n\nfrom .common import setup_function, teardown_function  # noqa\nfrom astropy.io import ascii\n\nfrom astropy.utils.compat.optional_deps import HAS_BLEACH, HAS_BS4  # noqa\n\nif HAS_BS4:\n    from bs4 import BeautifulSoup, FeatureNotFound\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_soupstring():\n    \"\"\"\n    Test to make sure the class SoupString behaves properly.\n    \"\"\"\n\n    soup = BeautifulSoup('<html><head></head><body><p>foo</p></body></html>',\n                         'html.parser')\n    soup_str = html.SoupString(soup)\n    assert isinstance(soup_str, str)\n    assert isinstance(soup_str, html.SoupString)\n    assert soup_str == '<html><head></head><body><p>foo</p></body></html>'\n    assert soup_str.soup is soup\n\n\ndef test_listwriter():\n    \"\"\"\n    Test to make sure the class ListWriter behaves properly.\n    \"\"\"\n\n    lst = []\n    writer = html.ListWriter(lst)\n\n    for i in range(5):\n        writer.write(i)\n    for ch in 'abcde':\n        writer.write(ch)\n\n    assert lst == [0, 1, 2, 3, 4, 'a', 'b', 'c', 'd', 'e']\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_identify_table():\n    \"\"\"\n    Test to make sure that identify_table() returns whether the\n    given BeautifulSoup tag is the correct table to process.\n    \"\"\"\n\n    # Should return False on non-<table> tags and None\n    soup = BeautifulSoup('<html><body></body></html>', 'html.parser')\n    assert html.identify_table(soup, {}, 0) is False\n    assert html.identify_table(None, {}, 0) is False\n\n    soup = BeautifulSoup('<table id=\"foo\"><tr><th>A</th></tr><tr>'\n                         '<td>B</td></tr></table>', 'html.parser').table\n    assert html.identify_table(soup, {}, 2) is False\n    assert html.identify_table(soup, {}, 1) is True  # Default index of 1\n\n    # Same tests, but with explicit parameter\n    assert html.identify_table(soup, {'table_id': 2}, 1) is False\n    assert html.identify_table(soup, {'table_id': 1}, 1) is True\n\n    # Test identification by string ID\n    assert html.identify_table(soup, {'table_id': 'bar'}, 1) is False\n    assert html.identify_table(soup, {'table_id': 'foo'}, 1) is True\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_missing_data():\n    \"\"\"\n    Test reading a table with missing data\n    \"\"\"\n    # First with default where blank => '0'\n    table_in = ['<table>',\n                '<tr><th>A</th></tr>',\n                '<tr><td></td></tr>',\n                '<tr><td>1</td></tr>',\n                '</table>']\n    dat = Table.read(table_in, format='ascii.html')\n    assert dat.masked is False\n    assert np.all(dat['A'].mask == [True, False])\n    assert dat['A'].dtype.kind == 'i'\n\n    # Now with a specific value '...' => missing\n    table_in = ['<table>',\n                '<tr><th>A</th></tr>',\n                '<tr><td>...</td></tr>',\n                '<tr><td>1</td></tr>',\n                '</table>']\n    dat = Table.read(table_in, format='ascii.html', fill_values=[('...', '0')])\n    assert dat.masked is False\n    assert np.all(dat['A'].mask == [True, False])\n    assert dat['A'].dtype.kind == 'i'\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_rename_cols():\n    \"\"\"\n    Test reading a table and renaming cols\n    \"\"\"\n    table_in = ['<table>',\n                '<tr><th>A</th> <th>B</th></tr>',\n                '<tr><td>1</td><td>2</td></tr>',\n                '</table>']\n\n    # Swap column names\n    dat = Table.read(table_in, format='ascii.html', names=['B', 'A'])\n    assert dat.colnames == ['B', 'A']\n    assert len(dat) == 1\n\n    # Swap column names and only include A (the renamed version)\n    dat = Table.read(table_in, format='ascii.html', names=['B', 'A'], include_names=['A'])\n    assert dat.colnames == ['A']\n    assert len(dat) == 1\n    assert np.all(dat['A'] == 2)\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_no_names():\n    \"\"\"\n    Test reading a table with no column header\n    \"\"\"\n    table_in = ['<table>',\n                '<tr><td>1</td></tr>',\n                '<tr><td>2</td></tr>',\n                '</table>']\n    dat = Table.read(table_in, format='ascii.html')\n    assert dat.colnames == ['col1']\n    assert len(dat) == 2\n\n    dat = Table.read(table_in, format='ascii.html', names=['a'])\n    assert dat.colnames == ['a']\n    assert len(dat) == 2\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_identify_table_fail():\n    \"\"\"\n    Raise an exception with an informative error message if table_id\n    is not found.\n    \"\"\"\n    table_in = ['<table id=\"foo\"><tr><th>A</th></tr>',\n                '<tr><td>B</td></tr></table>']\n\n    with pytest.raises(core.InconsistentTableError) as err:\n        Table.read(table_in, format='ascii.html', htmldict={'table_id': 'bad_id'},\n                   guess=False)\n    assert err.match(\"ERROR: HTML table id 'bad_id' not found$\")\n\n    with pytest.raises(core.InconsistentTableError) as err:\n        Table.read(table_in, format='ascii.html', htmldict={'table_id': 3},\n                   guess=False)\n    assert err.match(\"ERROR: HTML table number 3 not found$\")\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_backend_parsers():\n    \"\"\"\n    Make sure the user can specify which back-end parser to use\n    and that an error is raised if the parser is invalid.\n    \"\"\"\n    for parser in ('lxml', 'xml', 'html.parser', 'html5lib'):\n        try:\n            Table.read('data/html2.html', format='ascii.html',\n                       htmldict={'parser': parser}, guess=False)\n        except FeatureNotFound:\n            if parser == 'html.parser':\n                raise\n            # otherwise ignore if the dependency isn't present\n\n    # reading should fail if the parser is invalid\n    with pytest.raises(FeatureNotFound):\n        Table.read('data/html2.html', format='ascii.html',\n                   htmldict={'parser': 'foo'}, guess=False)\n\n\n@pytest.mark.skipif('HAS_BS4')\ndef test_htmlinputter_no_bs4():\n    \"\"\"\n    This should return an OptionalTableImportError if BeautifulSoup\n    is not installed.\n    \"\"\"\n\n    inputter = html.HTMLInputter()\n    with pytest.raises(core.OptionalTableImportError):\n        inputter.process_lines([])\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_htmlinputter():\n    \"\"\"\n    Test to ensure that HTMLInputter correctly converts input\n    into a list of SoupStrings representing table elements.\n    \"\"\"\n\n    f = 'data/html.html'\n    with open(f) as fd:\n        table = fd.read()\n\n    inputter = html.HTMLInputter()\n    inputter.html = {}\n\n    # In absence of table_id, defaults to the first table\n    expected = ['<tr><th>Column 1</th><th>Column 2</th><th>Column 3</th></tr>',\n                '<tr><td>1</td><td>a</td><td>1.05</td></tr>',\n                '<tr><td>2</td><td>b</td><td>2.75</td></tr>',\n                '<tr><td>3</td><td>c</td><td>-1.25</td></tr>']\n    assert [str(x) for x in inputter.get_lines(table)] == expected\n\n    # Should raise an InconsistentTableError if the table is not found\n    inputter.html = {'table_id': 4}\n    with pytest.raises(core.InconsistentTableError):\n        inputter.get_lines(table)\n\n    # Identification by string ID\n    inputter.html['table_id'] = 'second'\n    expected = ['<tr><th>Column A</th><th>Column B</th><th>Column C</th></tr>',\n                '<tr><td>4</td><td>d</td><td>10.5</td></tr>',\n                '<tr><td>5</td><td>e</td><td>27.5</td></tr>',\n                '<tr><td>6</td><td>f</td><td>-12.5</td></tr>']\n    assert [str(x) for x in inputter.get_lines(table)] == expected\n\n    # Identification by integer index\n    inputter.html['table_id'] = 3\n    expected = ['<tr><th>C1</th><th>C2</th><th>C3</th></tr>',\n                '<tr><td>7</td><td>g</td><td>105.0</td></tr>',\n                '<tr><td>8</td><td>h</td><td>275.0</td></tr>',\n                '<tr><td>9</td><td>i</td><td>-125.0</td></tr>']\n    assert [str(x) for x in inputter.get_lines(table)] == expected\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_htmlsplitter():\n    \"\"\"\n    Test to make sure that HTMLSplitter correctly inputs lines\n    of type SoupString to return a generator that gives all\n    header and data elements.\n    \"\"\"\n\n    splitter = html.HTMLSplitter()\n\n    lines = [html.SoupString(BeautifulSoup('<table><tr><th>Col 1</th><th>Col 2</th></tr></table>',\n                                           'html.parser').tr),\n             html.SoupString(BeautifulSoup('<table><tr><td>Data 1</td><td>Data 2</td></tr></table>',\n                                           'html.parser').tr)]\n    expected_data = [['Col 1', 'Col 2'], ['Data 1', 'Data 2']]\n    assert list(splitter(lines)) == expected_data\n\n    # Make sure the presence of a non-SoupString triggers a TypeError\n    lines.append('<tr><td>Data 3</td><td>Data 4</td></tr>')\n    with pytest.raises(TypeError):\n        list(splitter(lines))\n\n    # Make sure that passing an empty list triggers an error\n    with pytest.raises(core.InconsistentTableError):\n        list(splitter([]))\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_htmlheader_start():\n    \"\"\"\n    Test to ensure that the start_line method of HTMLHeader\n    returns the first line of header data. Uses t/html.html\n    for sample input.\n    \"\"\"\n\n    f = 'data/html.html'\n    with open(f) as fd:\n        table = fd.read()\n\n    inputter = html.HTMLInputter()\n    inputter.html = {}\n    header = html.HTMLHeader()\n\n    lines = inputter.get_lines(table)\n    assert str(lines[header.start_line(lines)]) == \\\n        '<tr><th>Column 1</th><th>Column 2</th><th>Column 3</th></tr>'\n    inputter.html['table_id'] = 'second'\n    lines = inputter.get_lines(table)\n    assert str(lines[header.start_line(lines)]) == \\\n        '<tr><th>Column A</th><th>Column B</th><th>Column C</th></tr>'\n    inputter.html['table_id'] = 3\n    lines = inputter.get_lines(table)\n    assert str(lines[header.start_line(lines)]) == \\\n        '<tr><th>C1</th><th>C2</th><th>C3</th></tr>'\n\n    # start_line should return None if no valid header is found\n    lines = [html.SoupString(BeautifulSoup('<table><tr><td>Data</td></tr></table>',\n                                           'html.parser').tr),\n             html.SoupString(BeautifulSoup('<p>Text</p>', 'html.parser').p)]\n    assert header.start_line(lines) is None\n\n    # Should raise an error if a non-SoupString is present\n    lines.append('<tr><th>Header</th></tr>')\n    with pytest.raises(TypeError):\n        header.start_line(lines)\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_htmldata():\n    \"\"\"\n    Test to ensure that the start_line and end_lines methods\n    of HTMLData returns the first line of table data. Uses\n    t/html.html for sample input.\n    \"\"\"\n\n    f = 'data/html.html'\n    with open(f) as fd:\n        table = fd.read()\n\n    inputter = html.HTMLInputter()\n    inputter.html = {}\n    data = html.HTMLData()\n\n    lines = inputter.get_lines(table)\n    assert str(lines[data.start_line(lines)]) == \\\n        '<tr><td>1</td><td>a</td><td>1.05</td></tr>'\n    # end_line returns the index of the last data element + 1\n    assert str(lines[data.end_line(lines) - 1]) == \\\n        '<tr><td>3</td><td>c</td><td>-1.25</td></tr>'\n\n    inputter.html['table_id'] = 'second'\n    lines = inputter.get_lines(table)\n    assert str(lines[data.start_line(lines)]) == \\\n        '<tr><td>4</td><td>d</td><td>10.5</td></tr>'\n    assert str(lines[data.end_line(lines) - 1]) == \\\n        '<tr><td>6</td><td>f</td><td>-12.5</td></tr>'\n\n    inputter.html['table_id'] = 3\n    lines = inputter.get_lines(table)\n    assert str(lines[data.start_line(lines)]) == \\\n        '<tr><td>7</td><td>g</td><td>105.0</td></tr>'\n    assert str(lines[data.end_line(lines) - 1]) == \\\n        '<tr><td>9</td><td>i</td><td>-125.0</td></tr>'\n\n    # start_line should raise an error if no table data exists\n    lines = [html.SoupString(BeautifulSoup('<div></div>', 'html.parser').div),\n             html.SoupString(BeautifulSoup('<p>Text</p>', 'html.parser').p)]\n    with pytest.raises(core.InconsistentTableError):\n        data.start_line(lines)\n\n    # end_line should return None if no table data exists\n    assert data.end_line(lines) is None\n\n    # Should raise an error if a non-SoupString is present\n    lines.append('<tr><td>Data</td></tr>')\n    with pytest.raises(TypeError):\n        data.start_line(lines)\n    with pytest.raises(TypeError):\n        data.end_line(lines)\n\n\ndef test_multicolumn_write():\n    \"\"\"\n    Test to make sure that the HTML writer writes multidimensional\n    columns (those with iterable elements) using the colspan\n    attribute of <th>.\n    \"\"\"\n\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('a', 'a', 'a'), ('b', 'b', 'b'), ('c', 'c', 'c')]\n    table = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    expected = \"\"\"\\\n<html>\n <head>\n  <meta charset=\"utf-8\"/>\n  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n </head>\n <body>\n  <table>\n   <thead>\n    <tr>\n     <th>C1</th>\n     <th colspan=\"2\">C2</th>\n     <th colspan=\"3\">C3</th>\n    </tr>\n   </thead>\n   <tr>\n    <td>1</td>\n    <td>1.0</td>\n    <td>1.0</td>\n    <td>a</td>\n    <td>a</td>\n    <td>a</td>\n   </tr>\n   <tr>\n    <td>2</td>\n    <td>2.0</td>\n    <td>2.0</td>\n    <td>b</td>\n    <td>b</td>\n    <td>b</td>\n   </tr>\n   <tr>\n    <td>3</td>\n    <td>3.0</td>\n    <td>3.0</td>\n    <td>c</td>\n    <td>c</td>\n    <td>c</td>\n   </tr>\n  </table>\n </body>\n</html>\n    \"\"\"\n    out = html.HTML().write(table)[0].strip()\n    assert out == expected.strip()\n\n\n@pytest.mark.skipif('not HAS_BLEACH')\ndef test_multicolumn_write_escape():\n    \"\"\"\n    Test to make sure that the HTML writer writes multidimensional\n    columns (those with iterable elements) using the colspan\n    attribute of <th>.\n    \"\"\"\n\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('<a></a>', '<a></a>', 'a'), ('<b></b>', 'b', 'b'), ('c', 'c', 'c')]\n    table = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    expected = \"\"\"\\\n<html>\n <head>\n  <meta charset=\"utf-8\"/>\n  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n </head>\n <body>\n  <table>\n   <thead>\n    <tr>\n     <th>C1</th>\n     <th colspan=\"2\">C2</th>\n     <th colspan=\"3\">C3</th>\n    </tr>\n   </thead>\n   <tr>\n    <td>1</td>\n    <td>1.0</td>\n    <td>1.0</td>\n    <td><a></a></td>\n    <td><a></a></td>\n    <td>a</td>\n   </tr>\n   <tr>\n    <td>2</td>\n    <td>2.0</td>\n    <td>2.0</td>\n    <td><b></b></td>\n    <td>b</td>\n    <td>b</td>\n   </tr>\n   <tr>\n    <td>3</td>\n    <td>3.0</td>\n    <td>3.0</td>\n    <td>c</td>\n    <td>c</td>\n    <td>c</td>\n   </tr>\n  </table>\n </body>\n</html>\n    \"\"\"\n    out = html.HTML(htmldict={'raw_html_cols': 'C3'}).write(table)[0].strip()\n    assert out == expected.strip()\n\n\ndef test_write_no_multicols():\n    \"\"\"\n    Test to make sure that the HTML writer will not use\n    multi-dimensional columns if the multicol parameter\n    is False.\n    \"\"\"\n\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('a', 'a', 'a'), ('b', 'b', 'b'), ('c', 'c', 'c')]\n    table = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    expected = \"\"\"\\\n<html>\n <head>\n  <meta charset=\"utf-8\"/>\n  <meta content=\"text/html;charset=UTF-8\" http-equiv=\"Content-type\"/>\n </head>\n <body>\n  <table>\n   <thead>\n    <tr>\n     <th>C1</th>\n     <th>C2</th>\n     <th>C3</th>\n    </tr>\n   </thead>\n   <tr>\n    <td>1</td>\n    <td>1.0 .. 1.0</td>\n    <td>a .. a</td>\n   </tr>\n   <tr>\n    <td>2</td>\n    <td>2.0 .. 2.0</td>\n    <td>b .. b</td>\n   </tr>\n   <tr>\n    <td>3</td>\n    <td>3.0 .. 3.0</td>\n    <td>c .. c</td>\n   </tr>\n  </table>\n </body>\n</html>\n    \"\"\"\n    assert html.HTML({'multicol': False}).write(table)[0].strip() == \\\n        expected.strip()\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_multicolumn_read():\n    \"\"\"\n    Test to make sure that the HTML reader inputs multidimensional\n    columns (those with iterable elements) using the colspan\n    attribute of <th>.\n\n    Ensure that any string element within a multidimensional column\n    casts all elements to string prior to type conversion operations.\n    \"\"\"\n\n    table = Table.read('data/html2.html', format='ascii.html')\n    str_type = np.dtype((str, 21))\n    expected = Table(np.array([(['1', '2.5000000000000000001'], 3),\n                               (['1a', '1'], 3.5)],\n                              dtype=[('A', str_type, (2,)), ('B', '<f8')]))\n    assert np.all(table == expected)\n\n\n@pytest.mark.skipif('not HAS_BLEACH')\ndef test_raw_html_write():\n    \"\"\"\n    Test that columns can contain raw HTML which is not escaped.\n    \"\"\"\n    t = Table([['<em>x</em>'], ['<em>y</em>']], names=['a', 'b'])\n\n    # One column contains raw HTML (string input)\n    out = StringIO()\n    t.write(out, format='ascii.html', htmldict={'raw_html_cols': 'a'})\n    expected = \"\"\"\\\n   <tr>\n    <td><em>x</em></td>\n    <td>&lt;em&gt;y&lt;/em&gt;</td>\n   </tr>\"\"\"\n    assert expected in out.getvalue()\n\n    # One column contains raw HTML (list input)\n    out = StringIO()\n    t.write(out, format='ascii.html', htmldict={'raw_html_cols': ['a']})\n    assert expected in out.getvalue()\n\n    # Two columns contains raw HTML (list input)\n    out = StringIO()\n    t.write(out, format='ascii.html', htmldict={'raw_html_cols': ['a', 'b']})\n    expected = \"\"\"\\\n   <tr>\n    <td><em>x</em></td>\n    <td><em>y</em></td>\n   </tr>\"\"\"\n    assert expected in out.getvalue()\n\n\n@pytest.mark.skipif('not HAS_BLEACH')\ndef test_raw_html_write_clean():\n    \"\"\"\n    Test that columns can contain raw HTML which is not escaped.\n    \"\"\"\n    import bleach  # noqa\n\n    t = Table([['<script>x</script>'], ['<p>y</p>'], ['<em>y</em>']], names=['a', 'b', 'c'])\n\n    # Confirm that <script> and <p> get escaped but not <em>\n    out = StringIO()\n    t.write(out, format='ascii.html', htmldict={'raw_html_cols': t.colnames})\n    expected = \"\"\"\\\n   <tr>\n    <td>&lt;script&gt;x&lt;/script&gt;</td>\n    <td>&lt;p&gt;y&lt;/p&gt;</td>\n    <td><em>y</em></td>\n   </tr>\"\"\"\n    assert expected in out.getvalue()\n\n    # Confirm that we can whitelist <p>\n    out = StringIO()\n    t.write(out, format='ascii.html',\n            htmldict={'raw_html_cols': t.colnames,\n                      'raw_html_clean_kwargs': {'tags': bleach.ALLOWED_TAGS + ['p']}})\n    expected = \"\"\"\\\n   <tr>\n    <td>&lt;script&gt;x&lt;/script&gt;</td>\n    <td><p>y</p></td>\n    <td><em>y</em></td>\n   </tr>\"\"\"\n    assert expected in out.getvalue()\n\n\ndef test_write_table_html_fill_values():\n    \"\"\"\n    Test that passing fill_values should replace any matching row\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1], [2]], names=('a', 'b'))\n    ascii.write(t, buffer_output, fill_values=('1', 'Hello world'),\n                format='html')\n\n    t_expected = Table([['Hello world'], [2]], names=('a', 'b'))\n    buffer_expected = StringIO()\n    ascii.write(t_expected, buffer_expected, format='html')\n\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n\n\ndef test_write_table_html_fill_values_optional_columns():\n    \"\"\"\n    Test that passing optional column in fill_values should only replace\n    matching columns\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1], [1]], names=('a', 'b'))\n    ascii.write(t, buffer_output, fill_values=('1', 'Hello world', 'b'),\n                format='html')\n\n    t_expected = Table([[1], ['Hello world']], names=('a', 'b'))\n    buffer_expected = StringIO()\n    ascii.write(t_expected, buffer_expected, format='html')\n\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n\n\ndef test_write_table_html_fill_values_masked():\n    \"\"\"\n    Test that passing masked values in fill_values should only replace\n    masked columns or values\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1], [1]], names=('a', 'b'), masked=True, dtype=('i4', 'i8'))\n    t['a'] = np.ma.masked\n    ascii.write(t, buffer_output, fill_values=(ascii.masked, 'TEST'),\n                format='html')\n\n    t_expected = Table([['TEST'], [1]], names=('a', 'b'))\n    buffer_expected = StringIO()\n    ascii.write(t_expected, buffer_expected, format='html')\n\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n\n\ndef test_multicolumn_table_html_fill_values():\n    \"\"\"\n    Test to make sure that the HTML writer writes multidimensional\n    columns with correctly replaced fill_values.\n    \"\"\"\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('a', 'a', 'a'), ('b', 'b', 'b'), ('c', 'c', 'c')]\n\n    buffer_output = StringIO()\n    t = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    ascii.write(t, buffer_output, fill_values=('a', 'z'),\n                format='html')\n\n    col1 = [1, 2, 3]\n    col2 = [(1.0, 1.0), (2.0, 2.0), (3.0, 3.0)]\n    col3 = [('z', 'z', 'z'), ('b', 'b', 'b'), ('c', 'c', 'c')]\n\n    buffer_expected = StringIO()\n    t_expected = Table([col1, col2, col3], names=('C1', 'C2', 'C3'))\n    ascii.write(t_expected, buffer_expected, format='html')\n\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n\n\ndef test_multi_column_write_table_html_fill_values_masked():\n    \"\"\"\n    Test that passing masked values in fill_values should only replace\n    masked columns or values for multidimensional tables\n    \"\"\"\n    buffer_output = StringIO()\n    t = Table([[1, 2, 3, 4], ['--', 'a', '--', 'b']], names=('a', 'b'), masked=True)\n    t['a'][0:2] = np.ma.masked\n    t['b'][0:2] = np.ma.masked\n    ascii.write(t, buffer_output, fill_values=[(ascii.masked, 'MASKED')],\n                format='html')\n\n    t_expected = Table([['MASKED', 'MASKED', 3, 4], [\n                       'MASKED', 'MASKED', '--', 'b']], names=('a', 'b'))\n    buffer_expected = StringIO()\n    ascii.write(t_expected, buffer_expected, format='html')\n    print(buffer_expected.getvalue())\n\n    assert buffer_output.getvalue() == buffer_expected.getvalue()\n\n\n@pytest.mark.skipif('not HAS_BS4')\ndef test_read_html_unicode():\n    \"\"\"\n    Test reading an HTML table with unicode values\n    \"\"\"\n    table_in = ['<table>',\n                '<tr><td>&#x0394;</td></tr>',\n                '<tr><td>\u0394</td></tr>',\n                '</table>']\n    dat = Table.read(table_in, format='ascii.html')\n    assert np.all(dat['col1'] == ['\u0394', '\u0394'])"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-13579", "model_patch": "diff --git a/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py b/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py\nindex 5004b6a..3ae3fd6 100644\n--- a/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py\n+++ b/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py\n@@ -244,6 +244,147 @@ World Dim    0    1    2\n         2  yes   no  yes\n \"\"\"\n \n+COUPLED_WCS_HEADER = {\n+    'WCSAXES': 3,\n+    'CRPIX1': (100 + 1)/2,\n+    'CRPIX2': (25 + 1)/2,\n+    'CRPIX3': 1.0,\n+    'PC1_1': 0.0,\n+    'PC1_2': -1.0,\n+    'PC1_3': 0.0,\n+    'PC2_1': 1.0,\n+    'PC2_2': 0.0,\n+    'PC2_3': -1.0,\n+    'CDELT1': 5,\n+    'CDELT2': 5,\n+    'CDELT3': 0.055,\n+    'CUNIT1': 'arcsec',\n+    'CUNIT2': 'arcsec',\n+    'CUNIT3': 'Angstrom',\n+    'CTYPE1': 'HPLN-TAN',\n+    'CTYPE2': 'HPLT-TAN',\n+    'CTYPE3': 'WAVE',\n+    'CRVAL1': 0.0,\n+    'CRVAL2': 0.0,\n+    'CRVAL3': 1.05,\n+}\n+\n+\n+def test_coupled_world_slicing():\n+    \"\"\"Test the original issue case from the bug report.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    sl = SlicedLowLevelWCS(fits_wcs, 0)\n+    world = fits_wcs.pixel_to_world_values(0, 0, 0)\n+    out_pix = sl.world_to_pixel_values(world[0], world[1])\n+\n+    assert np.allclose(out_pix[0], 0)\n+\n+\n+def test_sliced_wcs_world_to_pixel_consistency():\n+    \"\"\"Test that SlicedLowLevelWCS world_to_pixel is consistent with full WCS.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Create a SkyCoord at the reference position\n+    pt = SkyCoord(Tx=0*u.arcsec, Ty=0*u.arcsec, \n+                  frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+    \n+    # Get world_to_pixel result from full WCS\n+    full_result = fits_wcs.world_to_pixel(pt, 1.05*u.angstrom)\n+    \n+    # Create sliced WCS for first wavelength slice\n+    ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+    hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+    \n+    # Get world_to_pixel result from sliced WCS\n+    sliced_result = hl_sliced_wcs.world_to_pixel(pt)\n+    \n+    # The first two components should match between full and sliced WCS\n+    assert np.allclose(sliced_result[0], full_result[0]), \\\n+        f\"X pixel mismatch: sliced={sliced_result[0]}, full={full_result[0]}\"\n+    assert np.allclose(sliced_result[1], full_result[1]), \\\n+        f\"Y pixel mismatch: sliced={sliced_result[1]}, full={full_result[1]}\"\n+\n+\n+def test_sliced_wcs_pixel_to_world_consistency():\n+    \"\"\"Test that pixel_to_world remains consistent (this should already work).\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Create a SkyCoord at the reference position\n+    pt = SkyCoord(Tx=0*u.arcsec, Ty=0*u.arcsec, \n+                  frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+    \n+    # Get pixel coordinates from full WCS\n+    px, py, pz = fits_wcs.world_to_pixel(pt, 1.05*u.angstrom)\n+    \n+    # Test pixel_to_world on full WCS\n+    full_world = fits_wcs.pixel_to_world(px, py, pz)\n+    \n+    # Test pixel_to_world on sliced WCS\n+    ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+    hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+    sliced_world = hl_sliced_wcs.pixel_to_world(px, py)\n+    \n+    # The spatial coordinates should match\n+    assert np.allclose(full_world[0].Tx.value, sliced_world.Tx.value)\n+    assert np.allclose(full_world[0].Ty.value, sliced_world.Ty.value)\n+\n+\n+def test_sliced_wcs_different_slice_positions():\n+    \"\"\"Test world_to_pixel consistency for different slice positions.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Test different slice positions\n+    for slice_idx in [0, 1]:\n+        ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, slice_idx)\n+        hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+        \n+        # Test at reference position\n+        pt = SkyCoord(Tx=0*u.arcsec, Ty=0*u.arcsec, \n+                      frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+        \n+        # Get expected result from full WCS\n+        wavelength = 1.05 + slice_idx * 0.055  # Based on CRVAL3 and CDELT3\n+        full_result = fits_wcs.world_to_pixel(pt, wavelength*u.angstrom)\n+        \n+        # Get result from sliced WCS\n+        sliced_result = hl_sliced_wcs.world_to_pixel(pt)\n+        \n+        # Check consistency\n+        assert np.allclose(sliced_result[0], full_result[0]), \\\n+            f\"Slice {slice_idx}: X pixel mismatch: sliced={sliced_result[0]}, full={full_result[0]}\"\n+        assert np.allclose(sliced_result[1], full_result[1]), \\\n+            f\"Slice {slice_idx}: Y pixel mismatch: sliced={sliced_result[1]}, full={full_result[1]}\"\n+\n+\n+def test_sliced_wcs_off_center_coordinates():\n+    \"\"\"Test world_to_pixel consistency for off-center coordinates.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Test various off-center positions\n+    test_positions = [\n+        (10*u.arcsec, 5*u.arcsec),\n+        (-15*u.arcsec, 10*u.arcsec),\n+        (25*u.arcsec, -20*u.arcsec)\n+    ]\n+    \n+    for tx, ty in test_positions:\n+        pt = SkyCoord(Tx=tx, Ty=ty, \n+                      frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+        \n+        # Get result from full WCS\n+        full_result = fits_wcs.world_to_pixel(pt, 1.05*u.angstrom)\n+        \n+        # Get result from sliced WCS\n+        ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+        hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+        sliced_result = hl_sliced_wcs.world_to_pixel(pt)\n+        \n+        # Check consistency\n+        assert np.allclose(sliced_result[0], full_result[0]), \\\n+            f\"Position ({tx}, {ty}): X pixel mismatch: sliced={sliced_result[0]}, full={full_result[0]}\"\n+        assert np.allclose(sliced_result[1], full_result[1]), \\\n+            f\"Position ({tx}, {ty}): Y pixel mismatch: sliced={sliced_result[1]}, full={full_result[1]}\"\n+\n \n def test_spectral_range():\n \n", "raw_model_patch": "diff --git a/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py b/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py\nindex 5004b6a..3ae3fd6 100644\n--- a/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py\n+++ b/astropy/wcs/wcsapi/wrappers/tests/test_sliced_wcs.py\n@@ -244,6 +244,147 @@ World Dim    0    1    2\n         2  yes   no  yes\n \"\"\"\n \n+COUPLED_WCS_HEADER = {\n+    'WCSAXES': 3,\n+    'CRPIX1': (100 + 1)/2,\n+    'CRPIX2': (25 + 1)/2,\n+    'CRPIX3': 1.0,\n+    'PC1_1': 0.0,\n+    'PC1_2': -1.0,\n+    'PC1_3': 0.0,\n+    'PC2_1': 1.0,\n+    'PC2_2': 0.0,\n+    'PC2_3': -1.0,\n+    'CDELT1': 5,\n+    'CDELT2': 5,\n+    'CDELT3': 0.055,\n+    'CUNIT1': 'arcsec',\n+    'CUNIT2': 'arcsec',\n+    'CUNIT3': 'Angstrom',\n+    'CTYPE1': 'HPLN-TAN',\n+    'CTYPE2': 'HPLT-TAN',\n+    'CTYPE3': 'WAVE',\n+    'CRVAL1': 0.0,\n+    'CRVAL2': 0.0,\n+    'CRVAL3': 1.05,\n+}\n+\n+\n+def test_coupled_world_slicing():\n+    \"\"\"Test the original issue case from the bug report.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    sl = SlicedLowLevelWCS(fits_wcs, 0)\n+    world = fits_wcs.pixel_to_world_values(0, 0, 0)\n+    out_pix = sl.world_to_pixel_values(world[0], world[1])\n+\n+    assert np.allclose(out_pix[0], 0)\n+\n+\n+def test_sliced_wcs_world_to_pixel_consistency():\n+    \"\"\"Test that SlicedLowLevelWCS world_to_pixel is consistent with full WCS.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Create a SkyCoord at the reference position\n+    pt = SkyCoord(Tx=0*u.arcsec, Ty=0*u.arcsec, \n+                  frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+    \n+    # Get world_to_pixel result from full WCS\n+    full_result = fits_wcs.world_to_pixel(pt, 1.05*u.angstrom)\n+    \n+    # Create sliced WCS for first wavelength slice\n+    ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+    hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+    \n+    # Get world_to_pixel result from sliced WCS\n+    sliced_result = hl_sliced_wcs.world_to_pixel(pt)\n+    \n+    # The first two components should match between full and sliced WCS\n+    assert np.allclose(sliced_result[0], full_result[0]), \\\n+        f\"X pixel mismatch: sliced={sliced_result[0]}, full={full_result[0]}\"\n+    assert np.allclose(sliced_result[1], full_result[1]), \\\n+        f\"Y pixel mismatch: sliced={sliced_result[1]}, full={full_result[1]}\"\n+\n+\n+def test_sliced_wcs_pixel_to_world_consistency():\n+    \"\"\"Test that pixel_to_world remains consistent (this should already work).\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Create a SkyCoord at the reference position\n+    pt = SkyCoord(Tx=0*u.arcsec, Ty=0*u.arcsec, \n+                  frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+    \n+    # Get pixel coordinates from full WCS\n+    px, py, pz = fits_wcs.world_to_pixel(pt, 1.05*u.angstrom)\n+    \n+    # Test pixel_to_world on full WCS\n+    full_world = fits_wcs.pixel_to_world(px, py, pz)\n+    \n+    # Test pixel_to_world on sliced WCS\n+    ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+    hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+    sliced_world = hl_sliced_wcs.pixel_to_world(px, py)\n+    \n+    # The spatial coordinates should match\n+    assert np.allclose(full_world[0].Tx.value, sliced_world.Tx.value)\n+    assert np.allclose(full_world[0].Ty.value, sliced_world.Ty.value)\n+\n+\n+def test_sliced_wcs_different_slice_positions():\n+    \"\"\"Test world_to_pixel consistency for different slice positions.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Test different slice positions\n+    for slice_idx in [0, 1]:\n+        ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, slice_idx)\n+        hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+        \n+        # Test at reference position\n+        pt = SkyCoord(Tx=0*u.arcsec, Ty=0*u.arcsec, \n+                      frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+        \n+        # Get expected result from full WCS\n+        wavelength = 1.05 + slice_idx * 0.055  # Based on CRVAL3 and CDELT3\n+        full_result = fits_wcs.world_to_pixel(pt, wavelength*u.angstrom)\n+        \n+        # Get result from sliced WCS\n+        sliced_result = hl_sliced_wcs.world_to_pixel(pt)\n+        \n+        # Check consistency\n+        assert np.allclose(sliced_result[0], full_result[0]), \\\n+            f\"Slice {slice_idx}: X pixel mismatch: sliced={sliced_result[0]}, full={full_result[0]}\"\n+        assert np.allclose(sliced_result[1], full_result[1]), \\\n+            f\"Slice {slice_idx}: Y pixel mismatch: sliced={sliced_result[1]}, full={full_result[1]}\"\n+\n+\n+def test_sliced_wcs_off_center_coordinates():\n+    \"\"\"Test world_to_pixel consistency for off-center coordinates.\"\"\"\n+    fits_wcs = WCS(header=COUPLED_WCS_HEADER)\n+    \n+    # Test various off-center positions\n+    test_positions = [\n+        (10*u.arcsec, 5*u.arcsec),\n+        (-15*u.arcsec, 10*u.arcsec),\n+        (25*u.arcsec, -20*u.arcsec)\n+    ]\n+    \n+    for tx, ty in test_positions:\n+        pt = SkyCoord(Tx=tx, Ty=ty, \n+                      frame=astropy.wcs.utils.wcs_to_celestial_frame(fits_wcs))\n+        \n+        # Get result from full WCS\n+        full_result = fits_wcs.world_to_pixel(pt, 1.05*u.angstrom)\n+        \n+        # Get result from sliced WCS\n+        ll_sliced_wcs = SlicedLowLevelWCS(fits_wcs, 0)\n+        hl_sliced_wcs = HighLevelWCSWrapper(ll_sliced_wcs)\n+        sliced_result = hl_sliced_wcs.world_to_pixel(pt)\n+        \n+        # Check consistency\n+        assert np.allclose(sliced_result[0], full_result[0]), \\\n+            f\"Position ({tx}, {ty}): X pixel mismatch: sliced={sliced_result[0]}, full={full_result[0]}\"\n+        assert np.allclose(sliced_result[1], full_result[1]), \\\n+            f\"Position ({tx}, {ty}): Y pixel mismatch: sliced={sliced_result[1]}, full={full_result[1]}\"\n+\n \n def test_spectral_range():\n \n", "original_file_content": "import warnings\n\nimport pytest\n\nimport numpy as np\nfrom numpy.testing import assert_equal, assert_allclose\nfrom astropy.wcs.wcs import WCS, FITSFixedWarning\nfrom astropy.time import Time\nfrom astropy.wcs import WCS\nfrom astropy.io.fits import Header\nfrom astropy.io.fits.verify import VerifyWarning\nfrom astropy.coordinates import SkyCoord, Galactic, ICRS\nfrom astropy.units import Quantity\nfrom astropy.wcs.wcsapi.wrappers.sliced_wcs import SlicedLowLevelWCS, sanitize_slices, combine_slices\nfrom astropy.wcs.wcsapi.utils import wcs_info_str\nimport astropy.units as u\n\nfrom astropy.coordinates.spectral_coordinate import SpectralCoord\n\n# To test the slicing we start off from standard FITS WCS\n# objects since those implement the low-level API. We create\n# a WCS for a spectral cube with axes in non-standard order\n# and with correlated celestial axes and an uncorrelated\n# spectral axis.\n\nHEADER_SPECTRAL_CUBE = \"\"\"\nNAXIS   = 3\nNAXIS1  = 10\nNAXIS2  = 20\nNAXIS3  = 30\nCTYPE1  = GLAT-CAR\nCTYPE2  = FREQ\nCTYPE3  = GLON-CAR\nCNAME1  = Latitude\nCNAME2  = Frequency\nCNAME3  = Longitude\nCRVAL1  = 10\nCRVAL2  = 20\nCRVAL3  = 25\nCRPIX1  = 30\nCRPIX2  = 40\nCRPIX3  = 45\nCDELT1  = -0.1\nCDELT2  =  0.5\nCDELT3  =  0.1\nCUNIT1  = deg\nCUNIT2  = Hz\nCUNIT3  = deg\n\"\"\"\n\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore', VerifyWarning)\n    WCS_SPECTRAL_CUBE = WCS(Header.fromstring(HEADER_SPECTRAL_CUBE, sep='\\n'))\nWCS_SPECTRAL_CUBE.pixel_bounds = [(-1, 11), (-2, 18), (5, 15)]\n\n\ndef test_invalid_slices():\n    with pytest.raises(IndexError):\n        SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [None, None, [False, False, False]])\n\n    with pytest.raises(IndexError):\n        SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [None, None, slice(None, None, 2)])\n\n    with pytest.raises(IndexError):\n        SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [None, None, 1000.100])\n\n\n@pytest.mark.parametrize(\"item, ndim, expected\", (\n    ([Ellipsis, 10], 4, [slice(None)] * 3 + [10]),\n    ([10, slice(20, 30)], 5, [10, slice(20, 30)] + [slice(None)] * 3),\n    ([10, Ellipsis, 8], 10, [10] + [slice(None)] * 8 + [8])\n))\ndef test_sanitize_slice(item, ndim, expected):\n    new_item = sanitize_slices(item, ndim)\n    # FIXME: do we still need the first two since the third assert\n    # should cover it all?\n    assert len(new_item) == ndim\n    assert all(isinstance(i, (slice, int)) for i in new_item)\n    assert new_item == expected\n\n\nEXPECTED_ELLIPSIS_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 3 pixel and 3 world dimensions\n\nArray shape (Numpy order): (30, 20, 10)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None              10  (-1, 11)\n        1  None              20  (-2, 18)\n        2  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  Latitude   pos.galactic.lat  deg\n        1  Frequency  em.freq           Hz\n        2  Longitude  pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n             Pixel Dim\nWorld Dim    0    1    2\n        0  yes   no  yes\n        1   no  yes   no\n        2  yes   no  yes\n\"\"\"\n\n\ndef test_ellipsis():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, Ellipsis)\n\n    assert wcs.pixel_n_dim == 3\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape == (30, 20, 10)\n    assert wcs.pixel_shape == (10, 20, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'em.freq', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n    assert wcs.pixel_axis_names == ['', '', '']\n    assert wcs.world_axis_names == ['Latitude', 'Frequency', 'Longitude']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, False, True], [False, True, False], [True, False, True]])\n\n    assert len(wcs.world_axis_object_components) == 3\n    assert wcs.world_axis_object_components[0] == ('celestial', 1, 'spherical.lat.degree')\n    assert wcs.world_axis_object_components[1][:2] == ('spectral', 0)\n    assert wcs.world_axis_object_components[2] == ('celestial', 0, 'spherical.lon.degree')\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert wcs.world_axis_object_classes['spectral'][0] is Quantity\n    assert wcs.world_axis_object_classes['spectral'][1] == ()\n    assert wcs.world_axis_object_classes['spectral'][2] == {}\n\n    assert_allclose(wcs.pixel_to_world_values(29, 39, 44), (10, 20, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 39, 29), (10, 20, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(10, 20, 25), (29., 39., 44.))\n    assert_equal(wcs.world_to_array_index_values(10, 20, 25), (44, 39, 29))\n\n    assert_equal(wcs.pixel_bounds, [(-1, 11), (-2, 18), (5, 15)])\n\n    assert str(wcs) == EXPECTED_ELLIPSIS_REPR.strip()\n    assert EXPECTED_ELLIPSIS_REPR.strip() in repr(wcs)\n\n\ndef test_pixel_to_world_broadcasting():\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, Ellipsis)\n\n    assert_allclose(wcs.pixel_to_world_values((29, 29), 39, 44), ((10, 10), (20, 20), (25, 25)))\n\n\ndef test_world_to_pixel_broadcasting():\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, Ellipsis)\n\n    assert_allclose(wcs.world_to_pixel_values((10, 10), 20, 25), ((29., 29.), (39., 39.), (44., 44.)))\n\n\nEXPECTED_SPECTRAL_SLICE_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 2 pixel and 2 world dimensions\n\nArray shape (Numpy order): (30, 10)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None              10  (-1, 11)\n        1  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  Latitude   pos.galactic.lat  deg\n        1  Longitude  pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n           Pixel Dim\nWorld Dim    0    1\n        0  yes  yes\n        1  yes  yes\n\"\"\"\n\n\ndef test_spectral_slice():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [slice(None), 10])\n\n    assert wcs.pixel_n_dim == 2\n    assert wcs.world_n_dim == 2\n    assert wcs.array_shape == (30, 10)\n    assert wcs.pixel_shape == (10, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'deg']\n    assert wcs.pixel_axis_names == ['', '']\n    assert wcs.world_axis_names == ['Latitude', 'Longitude']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, True], [True, True]])\n\n    assert wcs.world_axis_object_components == [('celestial', 1, 'spherical.lat.degree'),\n                                                ('celestial', 0, 'spherical.lon.degree')]\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert_allclose(wcs.pixel_to_world_values(29, 44), (10, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 29), (10, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(10, 25), (29., 44.))\n    assert_equal(wcs.world_to_array_index_values(10, 25), (44, 29))\n\n    assert_equal(wcs.pixel_bounds, [(-1, 11), (5, 15)])\n\n    assert str(wcs) == EXPECTED_SPECTRAL_SLICE_REPR.strip()\n    assert EXPECTED_SPECTRAL_SLICE_REPR.strip() in repr(wcs)\n\n\nEXPECTED_SPECTRAL_RANGE_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 3 pixel and 3 world dimensions\n\nArray shape (Numpy order): (30, 6, 10)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None              10  (-1, 11)\n        1  None               6  (-6, 14)\n        2  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  Latitude   pos.galactic.lat  deg\n        1  Frequency  em.freq           Hz\n        2  Longitude  pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n             Pixel Dim\nWorld Dim    0    1    2\n        0  yes   no  yes\n        1   no  yes   no\n        2  yes   no  yes\n\"\"\"\n\n\ndef test_spectral_range():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [slice(None), slice(4, 10)])\n\n    assert wcs.pixel_n_dim == 3\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape == (30, 6, 10)\n    assert wcs.pixel_shape == (10, 6, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'em.freq', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n    assert wcs.pixel_axis_names == ['', '', '']\n    assert wcs.world_axis_names == ['Latitude', 'Frequency', 'Longitude']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, False, True], [False, True, False], [True, False, True]])\n\n    assert len(wcs.world_axis_object_components) == 3\n    assert wcs.world_axis_object_components[0] == ('celestial', 1, 'spherical.lat.degree')\n    assert wcs.world_axis_object_components[1][:2] == ('spectral', 0)\n    assert wcs.world_axis_object_components[2] == ('celestial', 0, 'spherical.lon.degree')\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert wcs.world_axis_object_classes['spectral'][0] is Quantity\n    assert wcs.world_axis_object_classes['spectral'][1] == ()\n    assert wcs.world_axis_object_classes['spectral'][2] == {}\n\n    assert_allclose(wcs.pixel_to_world_values(29, 35, 44), (10, 20, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 35, 29), (10, 20, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(10, 20, 25), (29., 35., 44.))\n    assert_equal(wcs.world_to_array_index_values(10, 20, 25), (44, 35, 29))\n\n    assert_equal(wcs.pixel_bounds, [(-1, 11), (-6, 14), (5, 15)])\n\n    assert str(wcs) == EXPECTED_SPECTRAL_RANGE_REPR.strip()\n    assert EXPECTED_SPECTRAL_RANGE_REPR.strip() in repr(wcs)\n\n\nEXPECTED_CELESTIAL_SLICE_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 2 pixel and 3 world dimensions\n\nArray shape (Numpy order): (30, 20)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None              20  (-2, 18)\n        1  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  Latitude   pos.galactic.lat  deg\n        1  Frequency  em.freq           Hz\n        2  Longitude  pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n           Pixel Dim\nWorld Dim    0    1\n        0   no  yes\n        1  yes   no\n        2   no  yes\n\"\"\"\n\n\ndef test_celestial_slice():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [Ellipsis, 5])\n\n    assert wcs.pixel_n_dim == 2\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape == (30, 20)\n    assert wcs.pixel_shape == (20, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'em.freq', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n    assert wcs.pixel_axis_names == ['', '']\n    assert wcs.world_axis_names == ['Latitude', 'Frequency', 'Longitude']\n\n    assert_equal(wcs.axis_correlation_matrix, [[False, True], [True, False], [False, True]])\n\n    assert len(wcs.world_axis_object_components) == 3\n    assert wcs.world_axis_object_components[0] == ('celestial', 1, 'spherical.lat.degree')\n    assert wcs.world_axis_object_components[1][:2] == ('spectral', 0)\n    assert wcs.world_axis_object_components[2] == ('celestial', 0, 'spherical.lon.degree')\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert wcs.world_axis_object_classes['spectral'][0] is Quantity\n    assert wcs.world_axis_object_classes['spectral'][1] == ()\n    assert wcs.world_axis_object_classes['spectral'][2] == {}\n\n    assert_allclose(wcs.pixel_to_world_values(39, 44), (12.4, 20, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 39), (12.4, 20, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(12.4, 20, 25), (39., 44.))\n    assert_equal(wcs.world_to_array_index_values(12.4, 20, 25), (44, 39))\n\n    assert_equal(wcs.pixel_bounds, [(-2, 18), (5, 15)])\n\n    assert str(wcs) == EXPECTED_CELESTIAL_SLICE_REPR.strip()\n    assert EXPECTED_CELESTIAL_SLICE_REPR.strip() in repr(wcs)\n\n\nEXPECTED_CELESTIAL_RANGE_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 3 pixel and 3 world dimensions\n\nArray shape (Numpy order): (30, 20, 5)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None               5  (-6, 6)\n        1  None              20  (-2, 18)\n        2  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  Latitude   pos.galactic.lat  deg\n        1  Frequency  em.freq           Hz\n        2  Longitude  pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n             Pixel Dim\nWorld Dim    0    1    2\n        0  yes   no  yes\n        1   no  yes   no\n        2  yes   no  yes\n\"\"\"\n\n\ndef test_celestial_range():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, [Ellipsis, slice(5, 10)])\n\n    assert wcs.pixel_n_dim == 3\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape == (30, 20, 5)\n    assert wcs.pixel_shape == (5, 20, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'em.freq', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n    assert wcs.pixel_axis_names == ['', '', '']\n    assert wcs.world_axis_names == ['Latitude', 'Frequency', 'Longitude']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, False, True], [False, True, False], [True, False, True]])\n\n    assert len(wcs.world_axis_object_components) == 3\n    assert wcs.world_axis_object_components[0] == ('celestial', 1, 'spherical.lat.degree')\n    assert wcs.world_axis_object_components[1][:2] == ('spectral', 0)\n    assert wcs.world_axis_object_components[2] == ('celestial', 0, 'spherical.lon.degree')\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert wcs.world_axis_object_classes['spectral'][0] is Quantity\n    assert wcs.world_axis_object_classes['spectral'][1] == ()\n    assert wcs.world_axis_object_classes['spectral'][2] == {}\n\n    assert_allclose(wcs.pixel_to_world_values(24, 39, 44), (10, 20, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 39, 24), (10, 20, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(10, 20, 25), (24., 39., 44.))\n    assert_equal(wcs.world_to_array_index_values(10, 20, 25), (44, 39, 24))\n\n    assert_equal(wcs.pixel_bounds, [(-6, 6), (-2, 18), (5, 15)])\n\n    assert str(wcs) == EXPECTED_CELESTIAL_RANGE_REPR.strip()\n    assert EXPECTED_CELESTIAL_RANGE_REPR.strip() in repr(wcs)\n\n\n# Now try with a 90 degree rotation\n\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore', VerifyWarning)\n    WCS_SPECTRAL_CUBE_ROT = WCS(Header.fromstring(\n        HEADER_SPECTRAL_CUBE, sep='\\n'))\nWCS_SPECTRAL_CUBE_ROT.wcs.pc = [[0, 0, 1], [0, 1, 0], [1, 0, 0]]\nWCS_SPECTRAL_CUBE_ROT.wcs.crval[0] = 0\nWCS_SPECTRAL_CUBE_ROT.pixel_bounds = [(-1, 11), (-2, 18), (5, 15)]\n\nEXPECTED_CELESTIAL_RANGE_ROT_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 3 pixel and 3 world dimensions\n\nArray shape (Numpy order): (30, 20, 5)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None               5  (-6, 6)\n        1  None              20  (-2, 18)\n        2  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  Latitude   pos.galactic.lat  deg\n        1  Frequency  em.freq           Hz\n        2  Longitude  pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n             Pixel Dim\nWorld Dim    0    1    2\n        0  yes   no  yes\n        1   no  yes   no\n        2  yes   no  yes\n\"\"\"\n\n\ndef test_celestial_range_rot():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE_ROT, [Ellipsis, slice(5, 10)])\n\n    assert wcs.pixel_n_dim == 3\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape == (30, 20, 5)\n    assert wcs.pixel_shape == (5, 20, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'em.freq', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n    assert wcs.pixel_axis_names == ['', '', '']\n    assert wcs.world_axis_names == ['Latitude', 'Frequency', 'Longitude']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, False, True], [False, True, False], [True, False, True]])\n\n    assert len(wcs.world_axis_object_components) == 3\n    assert wcs.world_axis_object_components[0] == ('celestial', 1, 'spherical.lat.degree')\n    assert wcs.world_axis_object_components[1][:2] == ('spectral', 0)\n    assert wcs.world_axis_object_components[2] == ('celestial', 0, 'spherical.lon.degree')\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert wcs.world_axis_object_classes['spectral'][0] is Quantity\n    assert wcs.world_axis_object_classes['spectral'][1] == ()\n    assert wcs.world_axis_object_classes['spectral'][2] == {}\n\n    assert_allclose(wcs.pixel_to_world_values(14, 29, 34), (1, 15, 24))\n    assert_allclose(wcs.array_index_to_world_values(34, 29, 14), (1, 15, 24))\n\n    assert_allclose(wcs.world_to_pixel_values(1, 15, 24), (14., 29., 34.))\n    assert_equal(wcs.world_to_array_index_values(1, 15, 24), (34, 29, 14))\n\n    assert_equal(wcs.pixel_bounds, [(-6, 6), (-2, 18), (5, 15)])\n\n    assert str(wcs) == EXPECTED_CELESTIAL_RANGE_ROT_REPR.strip()\n    assert EXPECTED_CELESTIAL_RANGE_ROT_REPR.strip() in repr(wcs)\n\n\nHEADER_NO_SHAPE_CUBE = \"\"\"\nNAXIS   = 3\nCTYPE1  = GLAT-CAR\nCTYPE2  = FREQ\nCTYPE3  = GLON-CAR\nCRVAL1  = 10\nCRVAL2  = 20\nCRVAL3  = 25\nCRPIX1  = 30\nCRPIX2  = 40\nCRPIX3  = 45\nCDELT1  = -0.1\nCDELT2  =  0.5\nCDELT3  =  0.1\nCUNIT1  = deg\nCUNIT2  = Hz\nCUNIT3  = deg\n\"\"\"\n\nwith warnings.catch_warnings():\n    warnings.simplefilter('ignore', VerifyWarning)\n    WCS_NO_SHAPE_CUBE = WCS(Header.fromstring(HEADER_NO_SHAPE_CUBE, sep='\\n'))\n\nEXPECTED_NO_SHAPE_REPR = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 3 pixel and 3 world dimensions\n\nArray shape (Numpy order): None\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None            None  None\n        1  None            None  None\n        2  None            None  None\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  None       pos.galactic.lat  deg\n        1  None       em.freq           Hz\n        2  None       pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n             Pixel Dim\nWorld Dim    0    1    2\n        0  yes   no  yes\n        1   no  yes   no\n        2  yes   no  yes\n\"\"\"\n\n\ndef test_no_array_shape():\n\n    wcs = SlicedLowLevelWCS(WCS_NO_SHAPE_CUBE, Ellipsis)\n\n    assert wcs.pixel_n_dim == 3\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape is None\n    assert wcs.pixel_shape is None\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', 'em.freq', 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, False, True], [False, True, False], [True, False, True]])\n\n    assert len(wcs.world_axis_object_components) == 3\n    assert wcs.world_axis_object_components[0] == ('celestial', 1, 'spherical.lat.degree')\n    assert wcs.world_axis_object_components[1][:2] == ('spectral', 0)\n    assert wcs.world_axis_object_components[2] == ('celestial', 0, 'spherical.lon.degree')\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert wcs.world_axis_object_classes['spectral'][0] is Quantity\n    assert wcs.world_axis_object_classes['spectral'][1] == ()\n    assert wcs.world_axis_object_classes['spectral'][2] == {}\n\n    assert_allclose(wcs.pixel_to_world_values(29, 39, 44), (10, 20, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 39, 29), (10, 20, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(10, 20, 25), (29., 39., 44.))\n    assert_equal(wcs.world_to_array_index_values(10, 20, 25), (44, 39, 29))\n\n    assert str(wcs) == EXPECTED_NO_SHAPE_REPR.strip()\n    assert EXPECTED_NO_SHAPE_REPR.strip() in repr(wcs)\n\n\n# Testing the WCS object having some physical types as None/Unknown\nHEADER_SPECTRAL_CUBE_NONE_TYPES = {\n        'CTYPE1': 'GLAT-CAR',\n        'CUNIT1': 'deg',\n        'CDELT1': -0.1,\n        'CRPIX1': 30,\n        'CRVAL1': 10,\n        'NAXIS1': 10,\n        'CTYPE2': '',\n        'CUNIT2': 'Hz',\n        'CDELT2':  0.5,\n        'CRPIX2': 40,\n        'CRVAL2': 20,\n        'NAXIS2': 20,\n        'CTYPE3': 'GLON-CAR',\n        'CUNIT3': 'deg',\n        'CDELT3':  0.1,\n        'CRPIX3': 45,\n        'CRVAL3': 25,\n        'NAXIS3': 30\n}\n\nWCS_SPECTRAL_CUBE_NONE_TYPES = WCS(header=HEADER_SPECTRAL_CUBE_NONE_TYPES)\nWCS_SPECTRAL_CUBE_NONE_TYPES.pixel_bounds = [(-1, 11), (-2, 18), (5, 15)]\n\n\nEXPECTED_ELLIPSIS_REPR_NONE_TYPES = \"\"\"\nSlicedLowLevelWCS Transformation\n\nThis transformation has 3 pixel and 3 world dimensions\n\nArray shape (Numpy order): (30, 20, 10)\n\nPixel Dim  Axis Name  Data size  Bounds\n        0  None              10  (-1, 11)\n        1  None              20  (-2, 18)\n        2  None              30  (5, 15)\n\nWorld Dim  Axis Name  Physical Type     Units\n        0  None       pos.galactic.lat  deg\n        1  None       None              Hz\n        2  None       pos.galactic.lon  deg\n\nCorrelation between pixel and world axes:\n\n             Pixel Dim\nWorld Dim    0    1    2\n        0  yes   no  yes\n        1   no  yes   no\n        2  yes   no  yes\n\"\"\"\n\n\ndef test_ellipsis_none_types():\n\n    wcs = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE_NONE_TYPES, Ellipsis)\n\n    assert wcs.pixel_n_dim == 3\n    assert wcs.world_n_dim == 3\n    assert wcs.array_shape == (30, 20, 10)\n    assert wcs.pixel_shape == (10, 20, 30)\n    assert wcs.world_axis_physical_types == ['pos.galactic.lat', None, 'pos.galactic.lon']\n    assert wcs.world_axis_units == ['deg', 'Hz', 'deg']\n\n    assert_equal(wcs.axis_correlation_matrix, [[True, False, True],\n                                               [False, True, False], [True, False, True]])\n\n    assert wcs.world_axis_object_components == [('celestial', 1, 'spherical.lat.degree'),\n                                                  ('world', 0, 'value'),\n                                                  ('celestial', 0, 'spherical.lon.degree')]\n\n    assert wcs.world_axis_object_classes['celestial'][0] is SkyCoord\n    assert wcs.world_axis_object_classes['celestial'][1] == ()\n    assert isinstance(wcs.world_axis_object_classes['celestial'][2]['frame'], Galactic)\n    assert wcs.world_axis_object_classes['celestial'][2]['unit'] is u.deg\n\n    assert_allclose(wcs.pixel_to_world_values(29, 39, 44), (10, 20, 25))\n    assert_allclose(wcs.array_index_to_world_values(44, 39, 29), (10, 20, 25))\n\n    assert_allclose(wcs.world_to_pixel_values(10, 20, 25), (29., 39., 44.))\n    assert_equal(wcs.world_to_array_index_values(10, 20, 25), (44, 39, 29))\n\n    assert_equal(wcs.pixel_bounds, [(-1, 11), (-2, 18), (5, 15)])\n\n    assert str(wcs) == EXPECTED_ELLIPSIS_REPR_NONE_TYPES.strip()\n    assert EXPECTED_ELLIPSIS_REPR_NONE_TYPES.strip() in repr(wcs)\n\n\nCASES = [(slice(None), slice(None), slice(None)),\n         (slice(None), slice(3, None), slice(3, None)),\n         (slice(None), slice(None, 16), slice(None, 16)),\n         (slice(None), slice(3, 16), slice(3, 16)),\n         (slice(2, None), slice(None), slice(2, None)),\n         (slice(2, None), slice(3, None), slice(5, None)),\n         (slice(2, None), slice(None, 16), slice(2, 18)),\n         (slice(2, None), slice(3, 16), slice(5, 18)),\n         (slice(None, 10), slice(None), slice(None, 10)),\n         (slice(None, 10), slice(3, None), slice(3, 10)),\n         (slice(None, 10), slice(None, 16), slice(None, 10)),\n         (slice(None, 10), slice(3, 16), slice(3, 10)),\n         (slice(2, 10), slice(None), slice(2, 10)),\n         (slice(2, 10), slice(3, None), slice(5, 10)),\n         (slice(2, 10), slice(None, 16), slice(2, 10)),\n         (slice(2, 10), slice(3, 16), slice(5, 10)),\n         (slice(None), 3, 3),\n         (slice(2, None), 3, 5),\n         (slice(None, 10), 3, 3),\n         (slice(2, 10), 3, 5)]\n\n\n@pytest.mark.parametrize(('slice1', 'slice2', 'expected'), CASES)\ndef test_combine_slices(slice1, slice2, expected):\n    assert combine_slices(slice1, slice2) == expected\n\n\ndef test_nested_slicing():\n    # Make sure that if we call slicing several times, the result is the same\n    # as calling the slicing once with the final slice settings.\n    wcs = WCS_SPECTRAL_CUBE\n    sub1 = SlicedLowLevelWCS(\n                SlicedLowLevelWCS(\n                    SlicedLowLevelWCS(wcs, [slice(None), slice(1, 10), slice(None)]),\n                    [3, slice(2, None)]),\n                [slice(None), slice(2, 8)])\n    sub2 = wcs[3, 3:10, 2:8]\n    assert_allclose(sub1.pixel_to_world_values(3, 5),\n                    sub2.pixel_to_world_values(3, 5))\n    assert not isinstance(sub1._wcs, SlicedLowLevelWCS)\n\n\ndef test_too_much_slicing():\n    wcs = WCS_SPECTRAL_CUBE\n    with pytest.raises(ValueError, match='Cannot slice WCS: the resulting WCS '\n                                         'should have at least one pixel and '\n                                         'one world dimension'):\n        wcs[0, 1, 2]\n\n\nHEADER_TIME_1D = \"\"\"\nSIMPLE  = T\nBITPIX  = -32\nNAXIS   = 1\nNAXIS1  = 2048\nTIMESYS = 'UTC'\nTREFPOS = 'TOPOCENT'\nMJDREF  = 50002.6\nCTYPE1  = 'UTC'\nCRVAL1  = 5\nCUNIT1  = 's'\nCRPIX1  = 1.0\nCDELT1  = 2\nOBSGEO-L= -20\nOBSGEO-B= -70\nOBSGEO-H= 2530\n\"\"\"\n\n\n@pytest.fixture\ndef header_time_1d():\n    return Header.fromstring(HEADER_TIME_1D, sep='\\n')\n\n\n@pytest.fixture\ndef time_1d_wcs(header_time_1d):\n    with warnings.catch_warnings():\n        warnings.simplefilter('ignore', FITSFixedWarning)\n        return WCS(header_time_1d)\n\n\ndef test_1d_sliced_low_level(time_1d_wcs):\n    sll = SlicedLowLevelWCS(time_1d_wcs, np.s_[10:20])\n    world = sll.pixel_to_world_values([1, 2])\n    assert isinstance(world, np.ndarray)\n    assert np.allclose(world, [27, 29])\n\n\ndef validate_info_dict(result, expected):\n    result_value = result.pop(\"value\")\n    expected_value = expected.pop(\"value\")\n\n    np.testing.assert_allclose(result_value, expected_value)\n    assert result == expected\n\n\ndef test_dropped_dimensions():\n    wcs = WCS_SPECTRAL_CUBE\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, :, :])\n\n    assert sub.dropped_world_dimensions == {}\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, 2:5, :])\n\n    assert sub.dropped_world_dimensions == {}\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, 0])\n\n    waocomp =sub.dropped_world_dimensions.pop(\"world_axis_object_components\")\n    assert len(waocomp) == 1 and waocomp[0][0] == \"spectral\" and waocomp[0][1] == 0\n    waocls = sub.dropped_world_dimensions.pop(\"world_axis_object_classes\")\n    assert len(waocls) == 1 and \"spectral\" in waocls and waocls[\"spectral\"][0] == u.Quantity\n    validate_info_dict(sub.dropped_world_dimensions, {\n        \"value\": [0.5],\n        \"world_axis_physical_types\": [\"em.freq\"],\n        \"world_axis_names\": [\"Frequency\"],\n        \"world_axis_units\": [\"Hz\"],\n        \"serialized_classes\": False,\n        })\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[:, 0, 0])\n\n    waocomp =sub.dropped_world_dimensions.pop(\"world_axis_object_components\")\n    assert len(waocomp) == 1 and waocomp[0][0] == \"spectral\" and waocomp[0][1] == 0\n    waocls = sub.dropped_world_dimensions.pop(\"world_axis_object_classes\")\n    assert len(waocls) == 1 and \"spectral\" in waocls and waocls[\"spectral\"][0] == u.Quantity\n    validate_info_dict(sub.dropped_world_dimensions, {\n        \"value\": [0.5],\n        \"world_axis_physical_types\": [\"em.freq\"],\n        \"world_axis_names\": [\"Frequency\"],\n        \"world_axis_units\": [\"Hz\"],\n        \"serialized_classes\": False,\n        })\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[0, :, 0])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [12.86995801, 20.49217541],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\", \"pos.galactic.lon\"],\n        \"world_axis_names\": [\"Latitude\", \"Longitude\"],\n        \"world_axis_units\": [\"deg\", \"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree'), ('celestial', 0, 'spherical.lon.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n    sub = SlicedLowLevelWCS(wcs, np.s_[5, :5, 12])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    validate_info_dict(dwd, {\n        \"value\": [11.67648267, 21.01921192],\n        \"world_axis_physical_types\": [\"pos.galactic.lat\", \"pos.galactic.lon\"],\n        \"world_axis_names\": [\"Latitude\", \"Longitude\"],\n        \"world_axis_units\": [\"deg\", \"deg\"],\n        \"serialized_classes\": False,\n        \"world_axis_object_components\": [('celestial', 1, 'spherical.lat.degree'), ('celestial', 0, 'spherical.lon.degree')],\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], Galactic)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n\n\ndef test_dropped_dimensions_4d(cube_4d_fitswcs):\n\n    sub = SlicedLowLevelWCS(cube_4d_fitswcs, np.s_[:, 12, 5, 5])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    wao_components = dwd.pop(\"world_axis_object_components\")\n\n    validate_info_dict(dwd, {\n        \"value\": [4.e+00, -2.e+00,  1.e+10],\n        \"world_axis_physical_types\": [\"pos.eq.ra\", \"pos.eq.dec\", \"em.freq\"],\n        \"world_axis_names\": ['Right Ascension', 'Declination', 'Frequency'],\n        \"world_axis_units\": [\"deg\", \"deg\", \"Hz\"],\n        \"serialized_classes\": False,\n        })\n\n    assert wao_classes['celestial'][0] is SkyCoord\n    assert wao_classes['celestial'][1] == ()\n    assert isinstance(wao_classes['celestial'][2]['frame'], ICRS)\n    assert wao_classes['celestial'][2]['unit'] is u.deg\n    assert wao_classes['spectral'][0:3] == (u.Quantity, (), {})\n\n    assert wao_components[0] == ('celestial', 0, 'spherical.lon.degree')\n    assert wao_components[1] == ('celestial', 1, 'spherical.lat.degree')\n    assert wao_components[2][0:2] == ('spectral', 0)\n\n    sub = SlicedLowLevelWCS(cube_4d_fitswcs, np.s_[12, 12])\n\n    dwd = sub.dropped_world_dimensions\n    wao_classes = dwd.pop(\"world_axis_object_classes\")\n    wao_components = dwd.pop(\"world_axis_object_components\")\n    validate_info_dict(dwd, {\n        \"value\": [1.e+10, 5.e+00],\n        \"world_axis_physical_types\": [\"em.freq\", \"time\"],\n        \"world_axis_names\": [\"Frequency\", \"Time\"],\n        \"world_axis_units\": [\"Hz\", \"s\"],\n        \"serialized_classes\": False,\n        })\n    assert wao_components[0][0:2] == ('spectral', 0)\n    assert wao_components[1][0] == 'time'\n    assert wao_components[1][1] == 0\n\n    assert wao_classes['spectral'][0:3] == (u.Quantity, (), {})\n    assert wao_classes['time'][0:3] == (Time, (), {})\n\n\ndef test_pixel_to_world_values_different_int_types():\n    int_sliced = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, np.s_[:, 0, :])\n    np64_sliced = SlicedLowLevelWCS(WCS_SPECTRAL_CUBE, np.s_[:, np.int64(0), :])\n    pixel_arrays = ([0, 1], [0, 1])\n    for int_coord, np64_coord in zip(int_sliced.pixel_to_world_values(*pixel_arrays),\n                                     np64_sliced.pixel_to_world_values(*pixel_arrays)):\n        assert all(int_coord == np64_coord)"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-13977", "model_patch": "", "raw_model_patch": "", "original_file_content": "# The purpose of these tests are to ensure that calling ufuncs with quantities\n# returns quantities with the right units, or raises exceptions.\n\nimport concurrent.futures\nimport warnings\nfrom collections import namedtuple\n\nimport numpy as np\nimport pytest\nfrom erfa import ufunc as erfa_ufunc\nfrom numpy.testing import assert_allclose, assert_array_equal\n\nfrom astropy import units as u\nfrom astropy.units import quantity_helper as qh\nfrom astropy.units.quantity_helper.converters import UfuncHelpers\nfrom astropy.units.quantity_helper.helpers import helper_sqrt\nfrom astropy.utils.compat.optional_deps import HAS_SCIPY\n\ntestcase = namedtuple(\"testcase\", [\"f\", \"q_in\", \"q_out\"])\ntestexc = namedtuple(\"testexc\", [\"f\", \"q_in\", \"exc\", \"msg\"])\ntestwarn = namedtuple(\"testwarn\", [\"f\", \"q_in\", \"wfilter\"])\n\n\n@pytest.mark.skip\ndef test_testcase(tc):\n    results = tc.f(*tc.q_in)\n    # careful of the following line, would break on a function returning\n    # a single tuple (as opposed to tuple of return values)\n    results = (results,) if not isinstance(results, tuple) else results\n    for result, expected in zip(results, tc.q_out):\n        assert result.unit == expected.unit\n        assert_allclose(result.value, expected.value, atol=1.0e-15)\n\n\n@pytest.mark.skip\ndef test_testexc(te):\n    with pytest.raises(te.exc) as exc:\n        te.f(*te.q_in)\n    if te.msg is not None:\n        assert te.msg in exc.value.args[0]\n\n\n@pytest.mark.skip\ndef test_testwarn(tw):\n    with warnings.catch_warnings():\n        warnings.filterwarnings(tw.wfilter)\n        tw.f(*tw.q_in)\n\n\nclass TestUfuncHelpers:\n    # Note that this test should work even if scipy is present, since\n    # the scipy.special ufuncs are only loaded on demand.\n    # The test passes independently of whether erfa is already loaded\n    # (which will be the case for a full test, since coordinates uses it).\n    def test_coverage(self):\n        \"\"\"Test that we cover all ufunc's\"\"\"\n\n        all_np_ufuncs = {\n            ufunc\n            for ufunc in np.core.umath.__dict__.values()\n            if isinstance(ufunc, np.ufunc)\n        }\n\n        all_q_ufuncs = qh.UNSUPPORTED_UFUNCS | set(qh.UFUNC_HELPERS.keys())\n        # Check that every numpy ufunc is covered.\n        assert all_np_ufuncs - all_q_ufuncs == set()\n        # Check that all ufuncs we cover come from numpy or erfa.\n        # (Since coverage for erfa is incomplete, we do not check\n        # this the other way).\n        all_erfa_ufuncs = {\n            ufunc\n            for ufunc in erfa_ufunc.__dict__.values()\n            if isinstance(ufunc, np.ufunc)\n        }\n        assert all_q_ufuncs - all_np_ufuncs - all_erfa_ufuncs == set()\n\n    def test_scipy_registered(self):\n        # Should be registered as existing even if scipy is not available.\n        assert \"scipy.special\" in qh.UFUNC_HELPERS.modules\n\n    def test_removal_addition(self):\n        assert np.add in qh.UFUNC_HELPERS\n        assert np.add not in qh.UNSUPPORTED_UFUNCS\n        qh.UFUNC_HELPERS[np.add] = None\n        assert np.add not in qh.UFUNC_HELPERS\n        assert np.add in qh.UNSUPPORTED_UFUNCS\n        qh.UFUNC_HELPERS[np.add] = qh.UFUNC_HELPERS[np.subtract]\n        assert np.add in qh.UFUNC_HELPERS\n        assert np.add not in qh.UNSUPPORTED_UFUNCS\n\n    @pytest.mark.slow\n    def test_thread_safety(self, fast_thread_switching):\n        def dummy_ufunc(*args, **kwargs):\n            return np.sqrt(*args, **kwargs)\n\n        def register():\n            return {dummy_ufunc: helper_sqrt}\n\n        workers = 8\n        with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:\n            for p in range(10000):\n                helpers = UfuncHelpers()\n                helpers.register_module(\n                    \"astropy.units.tests.test_quantity_ufuncs\",\n                    [\"dummy_ufunc\"],\n                    register,\n                )\n                futures = [\n                    executor.submit(lambda: helpers[dummy_ufunc])\n                    for i in range(workers)\n                ]\n                values = [future.result() for future in futures]\n                assert values == [helper_sqrt] * workers\n\n\nclass TestQuantityTrigonometricFuncs:\n    \"\"\"\n    Test trigonometric functions\n    \"\"\"\n\n    @pytest.mark.parametrize(\n        \"tc\",\n        (\n            testcase(\n                f=np.sin,\n                q_in=(30.0 * u.degree,),\n                q_out=(0.5 * u.dimensionless_unscaled,),\n            ),\n            testcase(\n                f=np.sin,\n                q_in=(np.array([0.0, np.pi / 4.0, np.pi / 2.0]) * u.radian,),\n                q_out=(np.array([0.0, 1.0 / np.sqrt(2.0), 1.0]) * u.one,),\n            ),\n            testcase(\n                f=np.arcsin,\n                q_in=(np.sin(30.0 * u.degree),),\n                q_out=(np.radians(30.0) * u.radian,),\n            ),\n            testcase(\n                f=np.arcsin,\n                q_in=(np.sin(np.array([0.0, np.pi / 4.0, np.pi / 2.0]) * u.radian),),\n                q_out=(np.array([0.0, np.pi / 4.0, np.pi / 2.0]) * u.radian,),\n            ),\n            testcase(\n                f=np.cos,\n                q_in=(np.pi / 3.0 * u.radian,),\n                q_out=(0.5 * u.dimensionless_unscaled,),\n            ),\n            testcase(\n                f=np.cos,\n                q_in=(np.array([0.0, np.pi / 4.0, np.pi / 2.0]) * u.radian,),\n                q_out=(np.array([1.0, 1.0 / np.sqrt(2.0), 0.0]) * u.one,),\n            ),\n            testcase(\n                f=np.arccos,\n                q_in=(np.cos(np.pi / 3.0 * u.radian),),\n                q_out=(np.pi / 3.0 * u.radian,),\n            ),\n            testcase(\n                f=np.arccos,\n                q_in=(np.cos(np.array([0.0, np.pi / 4.0, np.pi / 2.0]) * u.radian),),\n                q_out=(np.array([0.0, np.pi / 4.0, np.pi / 2.0]) * u.radian,),\n            ),\n            testcase(\n                f=np.tan,\n                q_in=(np.pi / 3.0 * u.radian,),\n                q_out=(np.sqrt(3.0) * u.dimensionless_unscaled,),\n            ),\n            testcase(\n                f=np.tan,\n                q_in=(np.array([0.0, 45.0, 135.0, 180.0]) * u.degree,),\n                q_out=(np.array([0.0, 1.0, -1.0, 0.0]) * u.dimensionless_unscaled,),\n            ),\n            testcase(\n                f=np.arctan,\n                q_in=(np.tan(np.pi / 3.0 * u.radian),),\n                q_out=(np.pi / 3.0 * u.radian,),\n            ),\n            testcase(\n                f=np.arctan,\n                q_in=(np.tan(np.array([10.0, 30.0, 70.0, 80.0]) * u.degree),),\n                q_out=(np.radians(np.array([10.0, 30.0, 70.0, 80.0]) * u.degree),),\n            ),\n            testcase(\n                f=np.arctan2,\n                q_in=(np.array([10.0, 30.0, 70.0, 80.0]) * u.m, 2.0 * u.km),\n                q_out=(\n                    np.arctan2(np.array([10.0, 30.0, 70.0, 80.0]), 2000.0) * u.radian,\n                ),\n            ),\n            testcase(\n                f=np.arctan2,\n                q_in=((np.array([10.0, 80.0]) * u.m / (2.0 * u.km)).to(u.one), 1.0),\n                q_out=(np.arctan2(np.array([10.0, 80.0]) / 2000.0, 1.0) * u.radian,),\n            ),\n            testcase(f=np.deg2rad, q_in=(180.0 * u.degree,), q_out=(np.pi * u.radian,)),\n            testcase(f=np.radians, q_in=(180.0 * u.degree,), q_out=(np.pi * u.radian,)),\n            testcase(f=np.deg2rad, q_in=(3.0 * u.radian,), q_out=(3.0 * u.radian,)),\n            testcase(f=np.radians, q_in=(3.0 * u.radian,), q_out=(3.0 * u.radian,)),\n            testcase(f=np.rad2deg, q_in=(60.0 * u.degree,), q_out=(60.0 * u.degree,)),\n            testcase(f=np.degrees, q_in=(60.0 * u.degree,), q_out=(60.0 * u.degree,)),\n            testcase(f=np.rad2deg, q_in=(np.pi * u.radian,), q_out=(180.0 * u.degree,)),\n            testcase(f=np.degrees, q_in=(np.pi * u.radian,), q_out=(180.0 * u.degree,)),\n        ),\n    )\n    def test_testcases(self, tc):\n        return test_testcase(tc)\n\n    @pytest.mark.parametrize(\n        \"te\",\n        (\n            testexc(f=np.deg2rad, q_in=(3.0 * u.m,), exc=TypeError, msg=None),\n            testexc(f=np.radians, q_in=(3.0 * u.m,), exc=TypeError, msg=None),\n            testexc(f=np.rad2deg, q_in=(3.0 * u.m), exc=TypeError, msg=None),\n            testexc(f=np.degrees, q_in=(3.0 * u.m), exc=TypeError, msg=None),\n            testexc(\n                f=np.sin,\n                q_in=(3.0 * u.m,),\n                exc=TypeError,\n                msg=\"Can only apply 'sin' function to quantities with angle units\",\n            ),\n            testexc(\n                f=np.arcsin,\n                q_in=(3.0 * u.m,),\n                exc=TypeError,\n                msg=\"Can only apply 'arcsin' function to dimensionless quantities\",\n            ),\n            testexc(\n                f=np.cos,\n                q_in=(3.0 * u.s,),\n                exc=TypeError,\n                msg=\"Can only apply 'cos' function to quantities with angle units\",\n            ),\n            testexc(\n                f=np.arccos,\n                q_in=(3.0 * u.s,),\n                exc=TypeError,\n                msg=\"Can only apply 'arccos' function to dimensionless quantities\",\n            ),\n            testexc(\n                f=np.tan,\n                q_in=(np.array([1, 2, 3]) * u.N,),\n                exc=TypeError,\n                msg=\"Can only apply 'tan' function to quantities with angle units\",\n            ),\n            testexc(\n                f=np.arctan,\n                q_in=(np.array([1, 2, 3]) * u.N,),\n                exc=TypeError,\n                msg=\"Can only apply 'arctan' function to dimensionless quantities\",\n            ),\n            testexc(\n                f=np.arctan2,\n                q_in=(np.array([1, 2, 3]) * u.N, 1.0 * u.s),\n                exc=u.UnitsError,\n                msg=\"compatible dimensions\",\n            ),\n            testexc(\n                f=np.arctan2,\n                q_in=(np.array([1, 2, 3]) * u.N, 1.0),\n                exc=u.UnitsError,\n                msg=\"dimensionless quantities when other arg\",\n            ),\n        ),\n    )\n    def test_testexcs(self, te):\n        return test_testexc(te)\n\n    @pytest.mark.parametrize(\n        \"tw\",\n        (testwarn(f=np.arcsin, q_in=(27.0 * u.pc / (15 * u.kpc),), wfilter=\"error\"),),\n    )\n    def test_testwarns(self, tw):\n        return test_testwarn(tw)\n\n\nclass TestQuantityMathFuncs:\n    \"\"\"\n    Test other mathematical functions\n    \"\"\"\n\n    def test_multiply_scalar(self):\n        assert np.multiply(4.0 * u.m, 2.0 / u.s) == 8.0 * u.m / u.s\n        assert np.multiply(4.0 * u.m, 2.0) == 8.0 * u.m\n        assert np.multiply(4.0, 2.0 / u.s) == 8.0 / u.s\n\n    def test_multiply_array(self):\n        assert np.all(\n            np.multiply(np.arange(3.0) * u.m, 2.0 / u.s)\n            == np.arange(0, 6.0, 2.0) * u.m / u.s\n        )\n\n    @pytest.mark.skipif(\n        not isinstance(getattr(np, \"matmul\", None), np.ufunc),\n        reason=\"np.matmul is not yet a gufunc\",\n    )\n    def test_matmul(self):\n        q = np.arange(3.0) * u.m\n        r = np.matmul(q, q)\n        assert r == 5.0 * u.m**2\n        # less trivial case.\n        q1 = np.eye(3) * u.m\n        q2 = np.array(\n            [[[1., 0., 0.],\n              [0., 1., 0.],\n              [0., 0., 1.]],\n             [[0., 1., 0.],\n              [0., 0., 1.],\n              [1., 0., 0.]],\n             [[0., 0., 1.],\n              [1., 0., 0.],\n              [0., 1., 0.]]]\n        ) / u.s  # fmt: skip\n        r2 = np.matmul(q1, q2)\n        assert np.all(r2 == np.matmul(q1.value, q2.value) * q1.unit * q2.unit)\n\n    @pytest.mark.parametrize(\"function\", (np.divide, np.true_divide))\n    def test_divide_scalar(self, function):\n        assert function(4.0 * u.m, 2.0 * u.s) == function(4.0, 2.0) * u.m / u.s\n        assert function(4.0 * u.m, 2.0) == function(4.0, 2.0) * u.m\n        assert function(4.0, 2.0 * u.s) == function(4.0, 2.0) / u.s\n\n    @pytest.mark.parametrize(\"function\", (np.divide, np.true_divide))\n    def test_divide_array(self, function):\n        assert np.all(\n            function(np.arange(3.0) * u.m, 2.0 * u.s)\n            == function(np.arange(3.0), 2.0) * u.m / u.s\n        )\n\n    def test_floor_divide_remainder_and_divmod(self):\n        inch = u.Unit(0.0254 * u.m)\n        dividend = np.array([1.0, 2.0, 3.0]) * u.m\n        divisor = np.array([3.0, 4.0, 5.0]) * inch\n        quotient = dividend // divisor\n        remainder = dividend % divisor\n        assert_allclose(quotient.value, [13.0, 19.0, 23.0])\n        assert quotient.unit == u.dimensionless_unscaled\n        assert_allclose(remainder.value, [0.0094, 0.0696, 0.079])\n        assert remainder.unit == dividend.unit\n        quotient2 = np.floor_divide(dividend, divisor)\n        remainder2 = np.remainder(dividend, divisor)\n        assert np.all(quotient2 == quotient)\n        assert np.all(remainder2 == remainder)\n        quotient3, remainder3 = divmod(dividend, divisor)\n        assert np.all(quotient3 == quotient)\n        assert np.all(remainder3 == remainder)\n\n        with pytest.raises(TypeError):\n            divmod(dividend, u.km)\n\n        with pytest.raises(TypeError):\n            dividend // u.km\n\n        with pytest.raises(TypeError):\n            dividend % u.km\n\n        quotient4, remainder4 = np.divmod(dividend, divisor)\n        assert np.all(quotient4 == quotient)\n        assert np.all(remainder4 == remainder)\n        with pytest.raises(TypeError):\n            np.divmod(dividend, u.km)\n\n    def test_sqrt_scalar(self):\n        assert np.sqrt(4.0 * u.m) == 2.0 * u.m**0.5\n\n    def test_sqrt_array(self):\n        assert np.all(\n            np.sqrt(np.array([1.0, 4.0, 9.0]) * u.m)\n            == np.array([1.0, 2.0, 3.0]) * u.m**0.5\n        )\n\n    def test_square_scalar(self):\n        assert np.square(4.0 * u.m) == 16.0 * u.m**2\n\n    def test_square_array(self):\n        assert np.all(\n            np.square(np.array([1.0, 2.0, 3.0]) * u.m)\n            == np.array([1.0, 4.0, 9.0]) * u.m**2\n        )\n\n    def test_reciprocal_scalar(self):\n        assert np.reciprocal(4.0 * u.m) == 0.25 / u.m\n\n    def test_reciprocal_array(self):\n        assert np.all(\n            np.reciprocal(np.array([1.0, 2.0, 4.0]) * u.m)\n            == np.array([1.0, 0.5, 0.25]) / u.m\n        )\n\n    def test_heaviside_scalar(self):\n        assert np.heaviside(0.0 * u.m, 0.5) == 0.5 * u.dimensionless_unscaled\n        assert (\n            np.heaviside(0.0 * u.s, 25 * u.percent) == 0.25 * u.dimensionless_unscaled\n        )\n        assert np.heaviside(2.0 * u.J, 0.25) == 1.0 * u.dimensionless_unscaled\n\n    def test_heaviside_array(self):\n        values = np.array([-1.0, 0.0, 0.0, +1.0])\n        halfway = np.array([0.75, 0.25, 0.75, 0.25]) * u.dimensionless_unscaled\n        assert np.all(\n            np.heaviside(values * u.m, halfway * u.dimensionless_unscaled)\n            == [0, 0.25, 0.75, +1.0] * u.dimensionless_unscaled\n        )\n\n    @pytest.mark.parametrize(\"function\", (np.cbrt,))\n    def test_cbrt_scalar(self, function):\n        assert function(8.0 * u.m**3) == 2.0 * u.m\n\n    @pytest.mark.parametrize(\"function\", (np.cbrt,))\n    def test_cbrt_array(self, function):\n        # Calculate cbrt on both sides since on Windows the cube root of 64\n        # does not exactly equal 4.  See 4388.\n        values = np.array([1.0, 8.0, 64.0])\n        assert np.all(function(values * u.m**3) == function(values) * u.m)\n\n    def test_power_scalar(self):\n        assert np.power(4.0 * u.m, 2.0) == 16.0 * u.m**2\n        assert np.power(4.0, 200.0 * u.cm / u.m) == u.Quantity(\n            16.0, u.dimensionless_unscaled\n        )\n        # regression check on #1696\n        assert np.power(4.0 * u.m, 0.0) == 1.0 * u.dimensionless_unscaled\n\n    def test_power_array(self):\n        assert np.all(\n            np.power(np.array([1.0, 2.0, 3.0]) * u.m, 3.0)\n            == np.array([1.0, 8.0, 27.0]) * u.m**3\n        )\n        # regression check on #1696\n        assert np.all(\n            np.power(np.arange(4.0) * u.m, 0.0) == 1.0 * u.dimensionless_unscaled\n        )\n\n    def test_float_power_array(self):\n        assert np.all(\n            np.float_power(np.array([1.0, 2.0, 3.0]) * u.m, 3.0)\n            == np.array([1.0, 8.0, 27.0]) * u.m**3\n        )\n        # regression check on #1696\n        assert np.all(\n            np.float_power(np.arange(4.0) * u.m, 0.0) == 1.0 * u.dimensionless_unscaled\n        )\n\n    def test_power_array_array(self):\n        with pytest.raises(ValueError):\n            np.power(4.0 * u.m, [2.0, 4.0])\n\n    def test_power_array_array2(self):\n        with pytest.raises(ValueError):\n            np.power([2.0, 4.0] * u.m, [2.0, 4.0])\n\n    def test_power_array_array3(self):\n        # Identical unit fractions are converted automatically to dimensionless\n        # and should be allowed as base for np.power: #4764\n        q = [2.0, 4.0] * u.m / u.m\n        powers = [2.0, 4.0]\n        res = np.power(q, powers)\n        assert np.all(res.value == q.value**powers)\n        assert res.unit == u.dimensionless_unscaled\n        # The same holds for unit fractions that are scaled dimensionless.\n        q2 = [2.0, 4.0] * u.m / u.cm\n        # Test also against different types of exponent\n        for cls in (list, tuple, np.array, np.ma.array, u.Quantity):\n            res2 = np.power(q2, cls(powers))\n            assert np.all(res2.value == q2.to_value(1) ** powers)\n            assert res2.unit == u.dimensionless_unscaled\n        # Though for single powers, we keep the composite unit.\n        res3 = q2**2\n        assert np.all(res3.value == q2.value**2)\n        assert res3.unit == q2.unit**2\n        assert np.all(res3 == q2 ** [2, 2])\n\n    def test_power_invalid(self):\n        with pytest.raises(TypeError, match=\"raise something to a dimensionless\"):\n            np.power(3.0, 4.0 * u.m)\n\n    def test_copysign_scalar(self):\n        assert np.copysign(3 * u.m, 1.0) == 3.0 * u.m\n        assert np.copysign(3 * u.m, 1.0 * u.s) == 3.0 * u.m\n        assert np.copysign(3 * u.m, -1.0) == -3.0 * u.m\n        assert np.copysign(3 * u.m, -1.0 * u.s) == -3.0 * u.m\n\n    def test_copysign_array(self):\n        assert np.all(\n            np.copysign(np.array([1.0, 2.0, 3.0]) * u.s, -1.0)\n            == -np.array([1.0, 2.0, 3.0]) * u.s\n        )\n        assert np.all(\n            np.copysign(np.array([1.0, 2.0, 3.0]) * u.s, -1.0 * u.m)\n            == -np.array([1.0, 2.0, 3.0]) * u.s\n        )\n        assert np.all(\n            np.copysign(\n                np.array([1.0, 2.0, 3.0]) * u.s, np.array([-2.0, 2.0, -4.0]) * u.m\n            )\n            == np.array([-1.0, 2.0, -3.0]) * u.s\n        )\n\n        q = np.copysign(np.array([1.0, 2.0, 3.0]), -3 * u.m)\n        assert np.all(q == np.array([-1.0, -2.0, -3.0]))\n        assert not isinstance(q, u.Quantity)\n\n    def test_ldexp_scalar(self):\n        assert np.ldexp(4.0 * u.m, 2) == 16.0 * u.m\n\n    def test_ldexp_array(self):\n        assert np.all(\n            np.ldexp(np.array([1.0, 2.0, 3.0]) * u.m, [3, 2, 1])\n            == np.array([8.0, 8.0, 6.0]) * u.m\n        )\n\n    def test_ldexp_invalid(self):\n        with pytest.raises(TypeError):\n            np.ldexp(3.0 * u.m, 4.0)\n\n        with pytest.raises(TypeError):\n            np.ldexp(3.0, u.Quantity(4, u.m, dtype=int))\n\n    @pytest.mark.parametrize(\n        \"function\", (np.exp, np.expm1, np.exp2, np.log, np.log2, np.log10, np.log1p)\n    )\n    def test_exp_scalar(self, function):\n        q = function(3.0 * u.m / (6.0 * u.m))\n        assert q.unit == u.dimensionless_unscaled\n        assert q.value == function(0.5)\n\n    @pytest.mark.parametrize(\n        \"function\", (np.exp, np.expm1, np.exp2, np.log, np.log2, np.log10, np.log1p)\n    )\n    def test_exp_array(self, function):\n        q = function(np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.m))\n        assert q.unit == u.dimensionless_unscaled\n        assert np.all(q.value == function(np.array([1.0 / 3.0, 1.0 / 2.0, 1.0])))\n        # should also work on quantities that can be made dimensionless\n        q2 = function(np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.cm))\n        assert q2.unit == u.dimensionless_unscaled\n        assert_allclose(q2.value, function(np.array([100.0 / 3.0, 100.0 / 2.0, 100.0])))\n\n    @pytest.mark.parametrize(\n        \"function\", (np.exp, np.expm1, np.exp2, np.log, np.log2, np.log10, np.log1p)\n    )\n    def test_exp_invalid_units(self, function):\n        # Can't use exp() with non-dimensionless quantities\n        with pytest.raises(\n            TypeError,\n            match=(\n                f\"Can only apply '{function.__name__}' function \"\n                \"to dimensionless quantities\"\n            ),\n        ):\n            function(3.0 * u.m / u.s)\n\n    def test_modf_scalar(self):\n        q = np.modf(9.0 * u.m / (600.0 * u.cm))\n        assert q == (0.5 * u.dimensionless_unscaled, 1.0 * u.dimensionless_unscaled)\n\n    def test_modf_array(self):\n        v = np.arange(10.0) * u.m / (500.0 * u.cm)\n        q = np.modf(v)\n        n = np.modf(v.to_value(u.dimensionless_unscaled))\n        assert q[0].unit == u.dimensionless_unscaled\n        assert q[1].unit == u.dimensionless_unscaled\n        assert all(q[0].value == n[0])\n        assert all(q[1].value == n[1])\n\n    def test_frexp_scalar(self):\n        q = np.frexp(3.0 * u.m / (6.0 * u.m))\n        assert q == (np.array(0.5), np.array(0.0))\n\n    def test_frexp_array(self):\n        q = np.frexp(np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.m))\n        assert all(\n            (_q0, _q1) == np.frexp(_d)\n            for _q0, _q1, _d in zip(q[0], q[1], [1.0 / 3.0, 1.0 / 2.0, 1.0])\n        )\n\n    def test_frexp_invalid_units(self):\n        # Can't use prod() with non-dimensionless quantities\n        with pytest.raises(\n            TypeError,\n            match=(\n                \"Can only apply 'frexp' function to unscaled dimensionless quantities\"\n            ),\n        ):\n            np.frexp(3.0 * u.m / u.s)\n\n        # also does not work on quantities that can be made dimensionless\n        with pytest.raises(\n            TypeError,\n            match=(\n                \"Can only apply 'frexp' function to unscaled dimensionless quantities\"\n            ),\n        ):\n            np.frexp(np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.cm))\n\n    @pytest.mark.parametrize(\"function\", (np.logaddexp, np.logaddexp2))\n    def test_dimensionless_twoarg_array(self, function):\n        q = function(np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.cm), 1.0)\n        assert q.unit == u.dimensionless_unscaled\n        assert_allclose(\n            q.value, function(np.array([100.0 / 3.0, 100.0 / 2.0, 100.0]), 1.0)\n        )\n\n    @pytest.mark.parametrize(\"function\", (np.logaddexp, np.logaddexp2))\n    def test_dimensionless_twoarg_invalid_units(self, function):\n        with pytest.raises(\n            TypeError,\n            match=(\n                f\"Can only apply '{function.__name__}' function to dimensionless\"\n                \" quantities\"\n            ),\n        ):\n            function(1.0 * u.km / u.s, 3.0 * u.m / u.s)\n\n\nclass TestInvariantUfuncs:\n    @pytest.mark.parametrize(\n        \"ufunc\",\n        [\n            np.absolute,\n            np.fabs,\n            np.conj,\n            np.conjugate,\n            np.negative,\n            np.spacing,\n            np.rint,\n            np.floor,\n            np.ceil,\n            np.positive,\n        ],\n    )\n    def test_invariant_scalar(self, ufunc):\n        q_i = 4.7 * u.m\n        q_o = ufunc(q_i)\n        assert isinstance(q_o, u.Quantity)\n        assert q_o.unit == q_i.unit\n        assert q_o.value == ufunc(q_i.value)\n\n    @pytest.mark.parametrize(\n        \"ufunc\", [np.absolute, np.conjugate, np.negative, np.rint, np.floor, np.ceil]\n    )\n    def test_invariant_array(self, ufunc):\n        q_i = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\n        q_o = ufunc(q_i)\n        assert isinstance(q_o, u.Quantity)\n        assert q_o.unit == q_i.unit\n        assert np.all(q_o.value == ufunc(q_i.value))\n\n    @pytest.mark.parametrize(\n        \"ufunc\",\n        [\n            np.add,\n            np.subtract,\n            np.hypot,\n            np.maximum,\n            np.minimum,\n            np.nextafter,\n            np.remainder,\n            np.mod,\n            np.fmod,\n        ],\n    )\n    def test_invariant_twoarg_scalar(self, ufunc):\n        q_i1 = 4.7 * u.m\n        q_i2 = 9.4 * u.km\n        q_o = ufunc(q_i1, q_i2)\n        assert isinstance(q_o, u.Quantity)\n        assert q_o.unit == q_i1.unit\n        assert_allclose(q_o.value, ufunc(q_i1.value, q_i2.to_value(q_i1.unit)))\n\n    @pytest.mark.parametrize(\n        \"ufunc\",\n        [\n            np.add,\n            np.subtract,\n            np.hypot,\n            np.maximum,\n            np.minimum,\n            np.nextafter,\n            np.remainder,\n            np.mod,\n            np.fmod,\n        ],\n    )\n    def test_invariant_twoarg_array(self, ufunc):\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\n        q_i2 = np.array([10.0, -5.0, 1.0e6]) * u.g / u.us\n        q_o = ufunc(q_i1, q_i2)\n        assert isinstance(q_o, u.Quantity)\n        assert q_o.unit == q_i1.unit\n        assert_allclose(q_o.value, ufunc(q_i1.value, q_i2.to_value(q_i1.unit)))\n\n    @pytest.mark.parametrize(\n        (\"ufunc\", \"arbitrary\"),\n        [\n            (np.add, 0.0),\n            (np.subtract, 0.0),\n            (np.hypot, 0.0),\n            (np.maximum, 0.0),\n            (np.minimum, 0.0),\n            (np.nextafter, 0.0),\n            (np.remainder, np.inf),\n            (np.mod, np.inf),\n            (np.fmod, np.inf),\n        ],\n    )\n    def test_invariant_twoarg_one_arbitrary(self, ufunc, arbitrary):\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\n        q_o = ufunc(q_i1, arbitrary)\n        assert isinstance(q_o, u.Quantity)\n        assert q_o.unit == q_i1.unit\n        assert_allclose(q_o.value, ufunc(q_i1.value, arbitrary))\n\n    @pytest.mark.parametrize(\n        \"ufunc\",\n        [\n            np.add,\n            np.subtract,\n            np.hypot,\n            np.maximum,\n            np.minimum,\n            np.nextafter,\n            np.remainder,\n            np.mod,\n            np.fmod,\n        ],\n    )\n    def test_invariant_twoarg_invalid_units(self, ufunc):\n        q_i1 = 4.7 * u.m\n        q_i2 = 9.4 * u.s\n        with pytest.raises(u.UnitsError, match=\"compatible dimensions\"):\n            ufunc(q_i1, q_i2)\n\n\nclass TestComparisonUfuncs:\n    @pytest.mark.parametrize(\n        \"ufunc\",\n        [np.greater, np.greater_equal, np.less, np.less_equal, np.not_equal, np.equal],\n    )\n    def test_comparison_valid_units(self, ufunc):\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\n        q_i2 = np.array([10.0, -5.0, 1.0e6]) * u.g / u.Ms\n        q_o = ufunc(q_i1, q_i2)\n        assert not isinstance(q_o, u.Quantity)\n        assert q_o.dtype == bool\n        assert np.all(q_o == ufunc(q_i1.value, q_i2.to_value(q_i1.unit)))\n        q_o2 = ufunc(q_i1 / q_i2, 2.0)\n        assert not isinstance(q_o2, u.Quantity)\n        assert q_o2.dtype == bool\n        assert np.all(\n            q_o2 == ufunc((q_i1 / q_i2).to_value(u.dimensionless_unscaled), 2.0)\n        )\n        # comparison with 0., inf, nan is OK even for dimensional quantities\n        # (though ignore numpy runtime warnings for comparisons with nan).\n        with warnings.catch_warnings():\n            warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n            for arbitrary_unit_value in (0.0, np.inf, np.nan):\n                ufunc(q_i1, arbitrary_unit_value)\n                ufunc(q_i1, arbitrary_unit_value * np.ones(len(q_i1)))\n            # and just for completeness\n            ufunc(q_i1, np.array([0.0, np.inf, np.nan]))\n\n    @pytest.mark.parametrize(\n        \"ufunc\",\n        [np.greater, np.greater_equal, np.less, np.less_equal, np.not_equal, np.equal],\n    )\n    def test_comparison_invalid_units(self, ufunc):\n        q_i1 = 4.7 * u.m\n        q_i2 = 9.4 * u.s\n        with pytest.raises(u.UnitsError, match=\"compatible dimensions\"):\n            ufunc(q_i1, q_i2)\n\n    @pytest.mark.parametrize(\"ufunc\", (np.isfinite, np.isinf, np.isnan, np.signbit))\n    def test_onearg_test_ufuncs(self, ufunc):\n        q = [1.0, np.inf, -np.inf, np.nan, -1.0, 0.0] * u.m\n        out = ufunc(q)\n        assert not isinstance(out, u.Quantity)\n        assert out.dtype == bool\n        assert np.all(out == ufunc(q.value))\n\n    # Ignore RuntimeWarning raised on Windows and s390.\n    @pytest.mark.filterwarnings(\"ignore:.*invalid value encountered in sign\")\n    def test_sign(self):\n        q = [1.0, np.inf, -np.inf, np.nan, -1.0, 0.0] * u.m\n\n        out = np.sign(q)\n        assert not isinstance(out, u.Quantity)\n        assert out.dtype == q.dtype\n        assert np.all((out == np.sign(q.value)) | (np.isnan(out) & np.isnan(q.value)))\n\n\nclass TestInplaceUfuncs:\n    @pytest.mark.parametrize(\"value\", [1.0, np.arange(10.0)])\n    def test_one_argument_ufunc_inplace(self, value):\n        # without scaling\n        s = value * u.rad\n        check = s\n        np.sin(s, out=s)\n        assert check is s\n        assert check.unit == u.dimensionless_unscaled\n        # with scaling\n        s2 = (value * u.rad).to(u.deg)\n        check2 = s2\n        np.sin(s2, out=s2)\n        assert check2 is s2\n        assert check2.unit == u.dimensionless_unscaled\n        assert_allclose(s.value, s2.value)\n\n    @pytest.mark.parametrize(\"value\", [1.0, np.arange(10.0)])\n    def test_one_argument_ufunc_inplace_2(self, value):\n        \"\"\"Check inplace works with non-quantity input and quantity output\"\"\"\n        s = value * u.m\n        check = s\n        np.absolute(value, out=s)\n        assert check is s\n        assert np.all(check.value == np.absolute(value))\n        assert check.unit is u.dimensionless_unscaled\n        np.sqrt(value, out=s)\n        assert check is s\n        assert np.all(check.value == np.sqrt(value))\n        assert check.unit is u.dimensionless_unscaled\n        np.exp(value, out=s)\n        assert check is s\n        assert np.all(check.value == np.exp(value))\n        assert check.unit is u.dimensionless_unscaled\n        np.arcsin(value / 10.0, out=s)\n        assert check is s\n        assert np.all(check.value == np.arcsin(value / 10.0))\n        assert check.unit is u.radian\n\n    @pytest.mark.parametrize(\"value\", [1.0, np.arange(10.0)])\n    def test_one_argument_two_output_ufunc_inplace(self, value):\n        v = 100.0 * value * u.cm / u.m\n        v_copy = v.copy()\n        tmp = v.copy()\n        check = v\n        np.modf(v, tmp, v)\n        assert check is v\n        assert check.unit == u.dimensionless_unscaled\n        v2 = v_copy.to(u.dimensionless_unscaled)\n        check2 = v2\n        np.modf(v2, tmp, v2)\n        assert check2 is v2\n        assert check2.unit == u.dimensionless_unscaled\n        # can also replace in last position if no scaling is needed\n        v3 = v_copy.to(u.dimensionless_unscaled)\n        check3 = v3\n        np.modf(v3, v3, tmp)\n        assert check3 is v3\n        assert check3.unit == u.dimensionless_unscaled\n        # can also replace input with first output when scaling\n        v4 = v_copy.copy()\n        check4 = v4\n        np.modf(v4, v4, tmp)\n        assert check4 is v4\n        assert check4.unit == u.dimensionless_unscaled\n\n    @pytest.mark.parametrize(\"value\", [1.0, np.arange(10.0)])\n    def test_two_argument_ufunc_inplace_1(self, value):\n        s = value * u.cycle\n        check = s\n        s /= 2.0\n        assert check is s\n        assert np.all(check.value == value / 2.0)\n        s /= u.s\n        assert check is s\n        assert check.unit == u.cycle / u.s\n        s *= 2.0 * u.s\n        assert check is s\n        assert np.all(check == value * u.cycle)\n\n    @pytest.mark.parametrize(\"value\", [1.0, np.arange(10.0)])\n    def test_two_argument_ufunc_inplace_2(self, value):\n        s = value * u.cycle\n        check = s\n        np.arctan2(s, s, out=s)\n        assert check is s\n        assert check.unit == u.radian\n        with pytest.raises(u.UnitsError):\n            s += 1.0 * u.m\n        assert check is s\n        assert check.unit == u.radian\n        np.arctan2(1.0 * u.deg, s, out=s)\n        assert check is s\n        assert check.unit == u.radian\n        np.add(1.0 * u.deg, s, out=s)\n        assert check is s\n        assert check.unit == u.deg\n        np.multiply(2.0 / u.s, s, out=s)\n        assert check is s\n        assert check.unit == u.deg / u.s\n\n    def test_two_argument_ufunc_inplace_3(self):\n        s = np.array([1.0, 2.0, 3.0]) * u.dimensionless_unscaled\n        np.add(np.array([1.0, 2.0, 3.0]), np.array([1.0, 2.0, 3.0]) * 2.0, out=s)\n        assert np.all(s.value == np.array([3.0, 6.0, 9.0]))\n        assert s.unit is u.dimensionless_unscaled\n        np.arctan2(np.array([1.0, 2.0, 3.0]), np.array([1.0, 2.0, 3.0]) * 2.0, out=s)\n        assert_allclose(s.value, np.arctan2(1.0, 2.0))\n        assert s.unit is u.radian\n\n    @pytest.mark.parametrize(\"value\", [1.0, np.arange(10.0)])\n    def test_two_argument_two_output_ufunc_inplace(self, value):\n        v = value * u.m\n        divisor = 70.0 * u.cm\n        v1 = v.copy()\n        tmp = v.copy()\n        check = np.divmod(v1, divisor, out=(tmp, v1))\n        assert check[0] is tmp and check[1] is v1\n        assert tmp.unit == u.dimensionless_unscaled\n        assert v1.unit == v.unit\n        v2 = v.copy()\n        check2 = np.divmod(v2, divisor, out=(v2, tmp))\n        assert check2[0] is v2 and check2[1] is tmp\n        assert v2.unit == u.dimensionless_unscaled\n        assert tmp.unit == v.unit\n        v3a = v.copy()\n        v3b = v.copy()\n        check3 = np.divmod(v3a, divisor, out=(v3a, v3b))\n        assert check3[0] is v3a and check3[1] is v3b\n        assert v3a.unit == u.dimensionless_unscaled\n        assert v3b.unit == v.unit\n\n    def test_ufunc_inplace_non_contiguous_data(self):\n        # ensure inplace works also for non-contiguous data (closes #1834)\n        s = np.arange(10.0) * u.m\n        s_copy = s.copy()\n        s2 = s[::2]\n        s2 += 1.0 * u.cm\n        assert np.all(s[::2] > s_copy[::2])\n        assert np.all(s[1::2] == s_copy[1::2])\n\n    def test_ufunc_inplace_non_standard_dtype(self):\n        \"\"\"Check that inplace operations check properly for casting.\n\n        First two tests that check that float32 is kept close #3976.\n        \"\"\"\n        a1 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.float32)\n        a1 *= np.float32(10)\n        assert a1.unit is u.m\n        assert a1.dtype == np.float32\n        a2 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.float32)\n        a2 += 20.0 * u.km\n        assert a2.unit is u.m\n        assert a2.dtype == np.float32\n        # For integer, in-place only works if no conversion is done.\n        a3 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.int32)\n        a3 += u.Quantity(10, u.m, dtype=np.int64)\n        assert a3.unit is u.m\n        assert a3.dtype == np.int32\n        a4 = u.Quantity([1, 2, 3, 4], u.m, dtype=np.int32)\n        with pytest.raises(TypeError):\n            a4 += u.Quantity(10, u.mm, dtype=np.int64)\n\n    @pytest.mark.parametrize(\"ufunc\", (np.equal, np.greater))\n    def test_comparison_ufuncs_inplace(self, ufunc):\n        q_i1 = np.array([-3.3, 2.1, 10.2]) * u.kg / u.s\n        q_i2 = np.array([10.0, -5.0, 1.0e6]) * u.g / u.Ms\n        check = np.empty(q_i1.shape, bool)\n        ufunc(q_i1.value, q_i2.to_value(q_i1.unit), out=check)\n\n        result = np.empty(q_i1.shape, bool)\n        q_o = ufunc(q_i1, q_i2, out=result)\n        assert q_o is result\n        assert type(q_o) is np.ndarray\n        assert q_o.dtype == bool\n        assert np.all(q_o == check)\n\n    @pytest.mark.parametrize(\"ufunc\", (np.isfinite, np.signbit))\n    def test_onearg_test_ufuncs_inplace(self, ufunc):\n        q = [1.0, np.inf, -np.inf, np.nan, -1.0, 0.0] * u.m\n        check = np.empty(q.shape, bool)\n        ufunc(q.value, out=check)\n\n        result = np.empty(q.shape, bool)\n        out = ufunc(q, out=result)\n        assert out is result\n        assert type(out) is np.ndarray\n        assert out.dtype == bool\n        assert np.all(out == ufunc(q.value))\n\n    # Ignore RuntimeWarning raised on Windows and s390.\n    @pytest.mark.filterwarnings(\"ignore:.*invalid value encountered in sign\")\n    def test_sign_inplace(self):\n        q = [1.0, np.inf, -np.inf, np.nan, -1.0, 0.0] * u.m\n        check = np.empty(q.shape, q.dtype)\n\n        np.sign(q.value, out=check)\n\n        result = np.empty(q.shape, q.dtype)\n        out = np.sign(q, out=result)\n        assert out is result\n        assert type(out) is np.ndarray\n        assert out.dtype == q.dtype\n        assert np.all((out == np.sign(q.value)) | (np.isnan(out) & np.isnan(q.value)))\n\n    def test_ndarray_inplace_op_with_quantity(self):\n        \"\"\"Regression test for gh-13911.\"\"\"\n        a = np.arange(3.0)\n        q = u.Quantity([12.5, 25.0], u.percent)\n        a[:2] += q  # This used to fail\n        assert_array_equal(a, np.array([0.125, 1.25, 2.0]))\n\n\n@pytest.mark.skipif(\n    not hasattr(np.core.umath, \"clip\"), reason=\"no clip ufunc available\"\n)\nclass TestClip:\n    \"\"\"Test the clip ufunc.\n\n    In numpy, this is hidden behind a function that does not backwards\n    compatibility checks.  We explicitly test the ufunc here.\n    \"\"\"\n\n    def setup_method(self):\n        self.clip = np.core.umath.clip\n\n    def test_clip_simple(self):\n        q = np.arange(-1.0, 10.0) * u.m\n        q_min = 125 * u.cm\n        q_max = 0.0055 * u.km\n        result = self.clip(q, q_min, q_max)\n        assert result.unit == q.unit\n        expected = (\n            self.clip(q.value, q_min.to_value(q.unit), q_max.to_value(q.unit)) * q.unit\n        )\n        assert np.all(result == expected)\n\n    def test_clip_unitless_parts(self):\n        q = np.arange(-1.0, 10.0) * u.m\n        qlim = 0.0055 * u.km\n        # one-sided\n        result1 = self.clip(q, -np.inf, qlim)\n        expected1 = self.clip(q.value, -np.inf, qlim.to_value(q.unit)) * q.unit\n        assert np.all(result1 == expected1)\n        result2 = self.clip(q, qlim, np.inf)\n        expected2 = self.clip(q.value, qlim.to_value(q.unit), np.inf) * q.unit\n        assert np.all(result2 == expected2)\n        # Zero\n        result3 = self.clip(q, np.zeros(q.shape), qlim)\n        expected3 = self.clip(q.value, 0, qlim.to_value(q.unit)) * q.unit\n        assert np.all(result3 == expected3)\n        # Two unitless parts, array-shaped.\n        result4 = self.clip(q, np.zeros(q.shape), np.full(q.shape, np.inf))\n        expected4 = self.clip(q.value, 0, np.inf) * q.unit\n        assert np.all(result4 == expected4)\n\n    def test_clip_dimensionless(self):\n        q = np.arange(-1.0, 10.0) * u.dimensionless_unscaled\n        result = self.clip(q, 200 * u.percent, 5.0)\n        expected = self.clip(q, 2.0, 5.0)\n        assert result.unit == u.dimensionless_unscaled\n        assert np.all(result == expected)\n\n    def test_clip_ndarray(self):\n        a = np.arange(-1.0, 10.0)\n        result = self.clip(a, 200 * u.percent, 5.0 * u.dimensionless_unscaled)\n        assert isinstance(result, u.Quantity)\n        expected = self.clip(a, 2.0, 5.0) * u.dimensionless_unscaled\n        assert np.all(result == expected)\n\n    def test_clip_quantity_inplace(self):\n        q = np.arange(-1.0, 10.0) * u.m\n        q_min = 125 * u.cm\n        q_max = 0.0055 * u.km\n        expected = (\n            self.clip(q.value, q_min.to_value(q.unit), q_max.to_value(q.unit)) * q.unit\n        )\n        result = self.clip(q, q_min, q_max, out=q)\n        assert result is q\n        assert np.all(result == expected)\n\n    def test_clip_ndarray_dimensionless_output(self):\n        a = np.arange(-1.0, 10.0)\n        q = np.zeros_like(a) * u.m\n        expected = self.clip(a, 2.0, 5.0) * u.dimensionless_unscaled\n        result = self.clip(a, 200 * u.percent, 5.0 * u.dimensionless_unscaled, out=q)\n        assert result is q\n        assert result.unit == u.dimensionless_unscaled\n        assert np.all(result == expected)\n\n    def test_clip_errors(self):\n        q = np.arange(-1.0, 10.0) * u.m\n        with pytest.raises(u.UnitsError):\n            self.clip(q, 0, 1 * u.s)\n        with pytest.raises(u.UnitsError):\n            self.clip(q.value, 0, 1 * u.s)\n        with pytest.raises(u.UnitsError):\n            self.clip(q, -1, 0.0)\n        with pytest.raises(u.UnitsError):\n            self.clip(q, 0.0, 1.0)\n\n\nclass TestUfuncAt:\n    \"\"\"Test that 'at' method for ufuncs (calculates in-place at given indices)\n\n    For Quantities, since calculations are in-place, it makes sense only\n    if the result is still a quantity, and if the unit does not have to change\n    \"\"\"\n\n    def test_one_argument_ufunc_at(self):\n        q = np.arange(10.0) * u.m\n        i = np.array([1, 2])\n        qv = q.value.copy()\n        np.negative.at(q, i)\n        np.negative.at(qv, i)\n        assert np.all(q.value == qv)\n        assert q.unit is u.m\n\n        # cannot change from quantity to bool array\n        with pytest.raises(TypeError):\n            np.isfinite.at(q, i)\n\n        # for selective in-place, cannot change the unit\n        with pytest.raises(u.UnitsError):\n            np.square.at(q, i)\n\n        # except if the unit does not change (i.e., dimensionless)\n        d = np.arange(10.0) * u.dimensionless_unscaled\n        dv = d.value.copy()\n        np.square.at(d, i)\n        np.square.at(dv, i)\n        assert np.all(d.value == dv)\n        assert d.unit is u.dimensionless_unscaled\n\n        d = np.arange(10.0) * u.dimensionless_unscaled\n        dv = d.value.copy()\n        np.log.at(d, i)\n        np.log.at(dv, i)\n        assert np.all(d.value == dv)\n        assert d.unit is u.dimensionless_unscaled\n\n        # also for sine it doesn't work, even if given an angle\n        a = np.arange(10.0) * u.radian\n        with pytest.raises(u.UnitsError):\n            np.sin.at(a, i)\n\n        # except, for consistency, if we have made radian equivalent to\n        # dimensionless (though hopefully it will never be needed)\n        av = a.value.copy()\n        with u.add_enabled_equivalencies(u.dimensionless_angles()):\n            np.sin.at(a, i)\n            np.sin.at(av, i)\n            assert_allclose(a.value, av)\n\n            # but we won't do double conversion\n            ad = np.arange(10.0) * u.degree\n            with pytest.raises(u.UnitsError):\n                np.sin.at(ad, i)\n\n    def test_two_argument_ufunc_at(self):\n        s = np.arange(10.0) * u.m\n        i = np.array([1, 2])\n        check = s.value.copy()\n        np.add.at(s, i, 1.0 * u.km)\n        np.add.at(check, i, 1000.0)\n        assert np.all(s.value == check)\n        assert s.unit is u.m\n\n        with pytest.raises(u.UnitsError):\n            np.add.at(s, i, 1.0 * u.s)\n\n        # also raise UnitsError if unit would have to be changed\n        with pytest.raises(u.UnitsError):\n            np.multiply.at(s, i, 1 * u.s)\n\n        # but be fine if it does not\n        s = np.arange(10.0) * u.m\n        check = s.value.copy()\n        np.multiply.at(s, i, 2.0 * u.dimensionless_unscaled)\n        np.multiply.at(check, i, 2)\n        assert np.all(s.value == check)\n        s = np.arange(10.0) * u.m\n        np.multiply.at(s, i, 2.0)\n        assert np.all(s.value == check)\n\n        # of course cannot change class of data either\n        with pytest.raises(TypeError):\n            np.greater.at(s, i, 1.0 * u.km)\n\n\nclass TestUfuncReduceReduceatAccumulate:\n    \"\"\"Test 'reduce', 'reduceat' and 'accumulate' methods for ufuncs\n\n    For Quantities, it makes sense only if the unit does not have to change\n    \"\"\"\n\n    def test_one_argument_ufunc_reduce_accumulate(self):\n        # one argument cannot be used\n        s = np.arange(10.0) * u.radian\n        i = np.array([0, 5, 1, 6])\n        with pytest.raises(ValueError):\n            np.sin.reduce(s)\n        with pytest.raises(ValueError):\n            np.sin.accumulate(s)\n        with pytest.raises(ValueError):\n            np.sin.reduceat(s, i)\n\n    def test_two_argument_ufunc_reduce_accumulate(self):\n        s = np.arange(10.0) * u.m\n        i = np.array([0, 5, 1, 6])\n        check = s.value.copy()\n        s_add_reduce = np.add.reduce(s)\n        check_add_reduce = np.add.reduce(check)\n        assert s_add_reduce.value == check_add_reduce\n        assert s_add_reduce.unit is u.m\n\n        s_add_accumulate = np.add.accumulate(s)\n        check_add_accumulate = np.add.accumulate(check)\n        assert np.all(s_add_accumulate.value == check_add_accumulate)\n        assert s_add_accumulate.unit is u.m\n\n        s_add_reduceat = np.add.reduceat(s, i)\n        check_add_reduceat = np.add.reduceat(check, i)\n        assert np.all(s_add_reduceat.value == check_add_reduceat)\n        assert s_add_reduceat.unit is u.m\n\n        # reduce(at) or accumulate on comparisons makes no sense,\n        # as intermediate result is not even a Quantity\n        with pytest.raises(TypeError):\n            np.greater.reduce(s)\n\n        with pytest.raises(TypeError):\n            np.greater.accumulate(s)\n\n        with pytest.raises(TypeError):\n            np.greater.reduceat(s, i)\n\n        # raise UnitsError if unit would have to be changed\n        with pytest.raises(u.UnitsError):\n            np.multiply.reduce(s)\n\n        with pytest.raises(u.UnitsError):\n            np.multiply.accumulate(s)\n\n        with pytest.raises(u.UnitsError):\n            np.multiply.reduceat(s, i)\n\n        # but be fine if it does not\n        s = np.arange(10.0) * u.dimensionless_unscaled\n        check = s.value.copy()\n        s_multiply_reduce = np.multiply.reduce(s)\n        check_multiply_reduce = np.multiply.reduce(check)\n        assert s_multiply_reduce.value == check_multiply_reduce\n        assert s_multiply_reduce.unit is u.dimensionless_unscaled\n        s_multiply_accumulate = np.multiply.accumulate(s)\n        check_multiply_accumulate = np.multiply.accumulate(check)\n        assert np.all(s_multiply_accumulate.value == check_multiply_accumulate)\n        assert s_multiply_accumulate.unit is u.dimensionless_unscaled\n        s_multiply_reduceat = np.multiply.reduceat(s, i)\n        check_multiply_reduceat = np.multiply.reduceat(check, i)\n        assert np.all(s_multiply_reduceat.value == check_multiply_reduceat)\n        assert s_multiply_reduceat.unit is u.dimensionless_unscaled\n\n\nclass TestUfuncOuter:\n    \"\"\"Test 'outer' methods for ufuncs\n\n    Just a few spot checks, since it uses the same code as the regular\n    ufunc call\n    \"\"\"\n\n    def test_one_argument_ufunc_outer(self):\n        # one argument cannot be used\n        s = np.arange(10.0) * u.radian\n        with pytest.raises(ValueError):\n            np.sin.outer(s)\n\n    def test_two_argument_ufunc_outer(self):\n        s1 = np.arange(10.0) * u.m\n        s2 = np.arange(2.0) * u.s\n        check1 = s1.value\n        check2 = s2.value\n        s12_multiply_outer = np.multiply.outer(s1, s2)\n        check12_multiply_outer = np.multiply.outer(check1, check2)\n        assert np.all(s12_multiply_outer.value == check12_multiply_outer)\n        assert s12_multiply_outer.unit == s1.unit * s2.unit\n\n        # raise UnitsError if appropriate\n        with pytest.raises(u.UnitsError):\n            np.add.outer(s1, s2)\n\n        # but be fine if it does not\n        s3 = np.arange(2.0) * s1.unit\n        check3 = s3.value\n        s13_add_outer = np.add.outer(s1, s3)\n        check13_add_outer = np.add.outer(check1, check3)\n        assert np.all(s13_add_outer.value == check13_add_outer)\n        assert s13_add_outer.unit is s1.unit\n\n        s13_greater_outer = np.greater.outer(s1, s3)\n        check13_greater_outer = np.greater.outer(check1, check3)\n        assert type(s13_greater_outer) is np.ndarray\n        assert np.all(s13_greater_outer == check13_greater_outer)\n\n\nif HAS_SCIPY:\n    from scipy import special as sps\n\n    erf_like_ufuncs = (\n        sps.erf, sps.erfc, sps.erfcx, sps.erfi,\n        sps.gamma, sps.gammaln, sps.loggamma, sps.gammasgn, sps.psi,\n        sps.rgamma, sps.digamma, sps.wofz, sps.dawsn,\n        sps.entr, sps.exprel, sps.expm1, sps.log1p, sps.exp2, sps.exp10,\n    )  # fmt: skip\n\n    if isinstance(sps.erfinv, np.ufunc):\n        erf_like_ufuncs += (sps.erfinv, sps.erfcinv)\n\n    def test_scipy_registration():\n        \"\"\"Check that scipy gets loaded upon first use.\"\"\"\n        assert sps.erf not in qh.UFUNC_HELPERS\n        sps.erf(1.0 * u.percent)\n        assert sps.erf in qh.UFUNC_HELPERS\n        if isinstance(sps.erfinv, np.ufunc):\n            assert sps.erfinv in qh.UFUNC_HELPERS\n        else:\n            assert sps.erfinv not in qh.UFUNC_HELPERS\n\n    class TestScipySpecialUfuncs:\n        @pytest.mark.parametrize(\"function\", erf_like_ufuncs)\n        def test_erf_scalar(self, function):\n            TestQuantityMathFuncs.test_exp_scalar(None, function)\n\n        @pytest.mark.parametrize(\"function\", erf_like_ufuncs)\n        def test_erf_array(self, function):\n            TestQuantityMathFuncs.test_exp_array(None, function)\n\n        @pytest.mark.parametrize(\"function\", erf_like_ufuncs)\n        def test_erf_invalid_units(self, function):\n            TestQuantityMathFuncs.test_exp_invalid_units(None, function)\n\n        @pytest.mark.parametrize(\"function\", (sps.cbrt,))\n        def test_cbrt_scalar(self, function):\n            TestQuantityMathFuncs.test_cbrt_scalar(None, function)\n\n        @pytest.mark.parametrize(\"function\", (sps.cbrt,))\n        def test_cbrt_array(self, function):\n            TestQuantityMathFuncs.test_cbrt_array(None, function)\n\n        @pytest.mark.parametrize(\"function\", (sps.radian,))\n        def test_radian(self, function):\n            q1 = function(180.0 * u.degree, 0.0 * u.arcmin, 0.0 * u.arcsec)\n            assert_allclose(q1.value, np.pi)\n            assert q1.unit == u.radian\n\n            q2 = function(0.0 * u.degree, 30.0 * u.arcmin, 0.0 * u.arcsec)\n            assert_allclose(q2.value, (30.0 * u.arcmin).to(u.radian).value)\n            assert q2.unit == u.radian\n\n            q3 = function(0.0 * u.degree, 0.0 * u.arcmin, 30.0 * u.arcsec)\n            assert_allclose(q3.value, (30.0 * u.arcsec).to(u.radian).value)\n\n            # the following doesn't make much sense in terms of the name of the\n            # routine, but we check it gives the correct result.\n            q4 = function(3.0 * u.radian, 0.0 * u.arcmin, 0.0 * u.arcsec)\n            assert_allclose(q4.value, 3.0)\n            assert q4.unit == u.radian\n\n            with pytest.raises(TypeError):\n                function(3.0 * u.m, 2.0 * u.s, 1.0 * u.kg)\n\n        jv_like_ufuncs = (\n            sps.jv, sps.jn, sps.jve, sps.yn, sps.yv, sps.yve, sps.kn, sps.kv,\n            sps.kve, sps.iv, sps.ive, sps.hankel1, sps.hankel1e, sps.hankel2,\n            sps.hankel2e,\n        )  # fmt: skip\n\n        @pytest.mark.parametrize(\"function\", jv_like_ufuncs)\n        def test_jv_scalar(self, function):\n            q = function(2.0 * u.m / (2.0 * u.m), 3.0 * u.m / (6.0 * u.m))\n            assert q.unit == u.dimensionless_unscaled\n            assert q.value == function(1.0, 0.5)\n\n        @pytest.mark.parametrize(\"function\", jv_like_ufuncs)\n        def test_jv_array(self, function):\n            q = function(\n                np.ones(3) * u.m / (1.0 * u.m),\n                np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.m),\n            )\n            assert q.unit == u.dimensionless_unscaled\n            assert np.all(\n                q.value == function(np.ones(3), np.array([1.0 / 3.0, 1.0 / 2.0, 1.0]))\n            )\n            # should also work on quantities that can be made dimensionless\n            q2 = function(\n                np.ones(3) * u.m / (1.0 * u.m),\n                np.array([2.0, 3.0, 6.0]) * u.m / (6.0 * u.cm),\n            )\n            assert q2.unit == u.dimensionless_unscaled\n            assert_allclose(\n                q2.value,\n                function(np.ones(3), np.array([100.0 / 3.0, 100.0 / 2.0, 100.0])),\n            )\n\n        @pytest.mark.parametrize(\"function\", jv_like_ufuncs)\n        def test_jv_invalid_units(self, function):\n            # Can't use jv() with non-dimensionless quantities\n            with pytest.raises(\n                TypeError,\n                match=(\n                    f\"Can only apply '{function.__name__}' function to dimensionless\"\n                    \" quantities\"\n                ),\n            ):\n                function(1.0 * u.kg, 3.0 * u.m / u.s)"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-14096", "model_patch": "diff --git a/astropy/coordinates/tests/test_sky_coord.py b/astropy/coordinates/tests/test_sky_coord.py\nindex ec75242..30d8d53 100644\n--- a/astropy/coordinates/tests/test_sky_coord.py\n+++ b/astropy/coordinates/tests/test_sky_coord.py\n@@ -877,6 +877,100 @@ def test_position_angle():\n     cfk5 = SkyCoord(1 * u.deg, 0 * u.deg, frame=\"fk5\")\n     # because of the frame transform, it's just a *bit* more than 90 degrees\n     assert cicrs.position_angle(cfk5) > 90.0 * u.deg\n+\n+\n+def test_subclass_property_exception_error():\n+    \"\"\"Regression test for gh-8340.\n+\n+    Non-existing attribute access inside a property should give attribute\n+    error for the attribute, not for the property.\n+    \"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.random_attr\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"random_attr\"):\n+        # Before this matched \"prop\" rather than \"random_attr\"\n+        c.prop\n+\n+\n+def test_subclass_property_exception_error_multiple_levels():\n+    \"\"\"Test that nested property access also gives correct error messages.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop1(self):\n+            return self.prop2\n+        \n+        @property\n+        def prop2(self):\n+            return self.nonexistent_attr\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"nonexistent_attr\"):\n+        # Should report the deepest missing attribute, not intermediate properties\n+        c.prop1\n+\n+\n+def test_subclass_property_exception_error_method_call():\n+    \"\"\"Test that method calls within properties also give correct error messages.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.missing_method()\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"missing_method\"):\n+        # Should report the missing method, not the property\n+        c.prop\n+\n+\n+def test_subclass_property_works_normally():\n+    \"\"\"Test that valid properties in subclasses work correctly.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.ra  # This should work fine\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    # This should not raise an exception\n+    result = c.prop\n+    assert result == c.ra\n+\n+\n+def test_subclass_direct_attribute_error():\n+    \"\"\"Test that direct attribute access on subclass still gives correct error.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        pass\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"nonexistent\"):\n+        # Direct attribute access should still work as before\n+        c.nonexistent\n+\n+\n+def test_subclass_property_with_existing_skycoord_attr():\n+    \"\"\"Test that properties can access existing SkyCoord attributes correctly.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def ra_degrees(self):\n+            return self.ra.degree\n+        \n+        @property\n+        def dec_degrees(self):\n+            return self.dec.degree\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    # These should work without any issues\n+    assert isinstance(c.ra_degrees, float)\n+    assert isinstance(c.dec_degrees, float)\n     assert cicrs.position_angle(cfk5) < 91.0 * u.deg\n \n \n", "raw_model_patch": "diff --git a/astropy/coordinates/tests/test_sky_coord.py b/astropy/coordinates/tests/test_sky_coord.py\nindex ec75242..30d8d53 100644\n--- a/astropy/coordinates/tests/test_sky_coord.py\n+++ b/astropy/coordinates/tests/test_sky_coord.py\n@@ -877,6 +877,100 @@ def test_position_angle():\n     cfk5 = SkyCoord(1 * u.deg, 0 * u.deg, frame=\"fk5\")\n     # because of the frame transform, it's just a *bit* more than 90 degrees\n     assert cicrs.position_angle(cfk5) > 90.0 * u.deg\n+\n+\n+def test_subclass_property_exception_error():\n+    \"\"\"Regression test for gh-8340.\n+\n+    Non-existing attribute access inside a property should give attribute\n+    error for the attribute, not for the property.\n+    \"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.random_attr\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"random_attr\"):\n+        # Before this matched \"prop\" rather than \"random_attr\"\n+        c.prop\n+\n+\n+def test_subclass_property_exception_error_multiple_levels():\n+    \"\"\"Test that nested property access also gives correct error messages.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop1(self):\n+            return self.prop2\n+        \n+        @property\n+        def prop2(self):\n+            return self.nonexistent_attr\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"nonexistent_attr\"):\n+        # Should report the deepest missing attribute, not intermediate properties\n+        c.prop1\n+\n+\n+def test_subclass_property_exception_error_method_call():\n+    \"\"\"Test that method calls within properties also give correct error messages.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.missing_method()\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"missing_method\"):\n+        # Should report the missing method, not the property\n+        c.prop\n+\n+\n+def test_subclass_property_works_normally():\n+    \"\"\"Test that valid properties in subclasses work correctly.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def prop(self):\n+            return self.ra  # This should work fine\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    # This should not raise an exception\n+    result = c.prop\n+    assert result == c.ra\n+\n+\n+def test_subclass_direct_attribute_error():\n+    \"\"\"Test that direct attribute access on subclass still gives correct error.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        pass\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    with pytest.raises(AttributeError, match=\"nonexistent\"):\n+        # Direct attribute access should still work as before\n+        c.nonexistent\n+\n+\n+def test_subclass_property_with_existing_skycoord_attr():\n+    \"\"\"Test that properties can access existing SkyCoord attributes correctly.\"\"\"\n+\n+    class custom_coord(SkyCoord):\n+        @property\n+        def ra_degrees(self):\n+            return self.ra.degree\n+        \n+        @property\n+        def dec_degrees(self):\n+            return self.dec.degree\n+\n+    c = custom_coord(\"00h42m30s\", \"+41d12m00s\", frame=\"icrs\")\n+    # These should work without any issues\n+    assert isinstance(c.ra_degrees, float)\n+    assert isinstance(c.dec_degrees, float)\n     assert cicrs.position_angle(cfk5) < 91.0 * u.deg\n \n \n", "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\n\"\"\"\nTests for the SkyCoord class.  Note that there are also SkyCoord tests in\ntest_api_ape5.py\n\"\"\"\n\nimport copy\nfrom copy import deepcopy\n\nimport numpy as np\nimport numpy.testing as npt\nimport pytest\nfrom erfa import ErfaWarning\n\nfrom astropy import units as u\nfrom astropy.coordinates import (\n    FK4,\n    FK5,\n    GCRS,\n    ICRS,\n    AltAz,\n    Angle,\n    Attribute,\n    BaseCoordinateFrame,\n    CartesianRepresentation,\n    EarthLocation,\n    Galactic,\n    Latitude,\n    RepresentationMapping,\n    SkyCoord,\n    SphericalRepresentation,\n    UnitSphericalRepresentation,\n    frame_transform_graph,\n)\nfrom astropy.coordinates.representation import (\n    DUPLICATE_REPRESENTATIONS,\n    REPRESENTATION_CLASSES,\n)\nfrom astropy.coordinates.tests.helper import skycoord_equal\nfrom astropy.coordinates.transformations import FunctionTransform\nfrom astropy.io import fits\nfrom astropy.tests.helper import assert_quantity_allclose as assert_allclose\nfrom astropy.time import Time\nfrom astropy.units import allclose as quantity_allclose\nfrom astropy.utils import isiterable\nfrom astropy.utils.compat.optional_deps import HAS_SCIPY\nfrom astropy.wcs import WCS\n\nRA = 1.0 * u.deg\nDEC = 2.0 * u.deg\nC_ICRS = ICRS(RA, DEC)\nC_FK5 = C_ICRS.transform_to(FK5())\nJ2001 = Time(\"J2001\")\n\n\ndef allclose(a, b, rtol=0.0, atol=None):\n    if atol is None:\n        atol = 1.0e-8 * getattr(a, \"unit\", 1.0)\n    return quantity_allclose(a, b, rtol, atol)\n\n\ndef setup_function(func):\n    func.REPRESENTATION_CLASSES_ORIG = deepcopy(REPRESENTATION_CLASSES)\n    func.DUPLICATE_REPRESENTATIONS_ORIG = deepcopy(DUPLICATE_REPRESENTATIONS)\n\n\ndef teardown_function(func):\n    REPRESENTATION_CLASSES.clear()\n    REPRESENTATION_CLASSES.update(func.REPRESENTATION_CLASSES_ORIG)\n    DUPLICATE_REPRESENTATIONS.clear()\n    DUPLICATE_REPRESENTATIONS.update(func.DUPLICATE_REPRESENTATIONS_ORIG)\n\n\ndef test_is_transformable_to_str_input():\n    \"\"\"Test method ``is_transformable_to`` with string input.\n\n    The only difference from the frame method of the same name is that\n    strings are allowed. As the frame tests cover ``is_transform_to``, here\n    we only test the added string option.\n\n    \"\"\"\n    # make example SkyCoord\n    c = SkyCoord(90 * u.deg, -11 * u.deg)\n\n    # iterate through some frames, checking consistency\n    names = frame_transform_graph.get_names()\n    for name in names:\n        frame = frame_transform_graph.lookup_name(name)()\n        assert c.is_transformable_to(name) == c.is_transformable_to(frame)\n\n\ndef test_transform_to():\n    for frame in (\n        FK5(),\n        FK5(equinox=Time(\"J1975.0\")),\n        FK4(),\n        FK4(equinox=Time(\"J1975.0\")),\n        SkyCoord(RA, DEC, frame=\"fk4\", equinox=\"J1980\"),\n    ):\n        c_frame = C_ICRS.transform_to(frame)\n        s_icrs = SkyCoord(RA, DEC, frame=\"icrs\")\n        s_frame = s_icrs.transform_to(frame)\n        assert allclose(c_frame.ra, s_frame.ra)\n        assert allclose(c_frame.dec, s_frame.dec)\n        assert allclose(c_frame.distance, s_frame.distance)\n\n\n# set up for parametrized test\nrt_sets = []\nrt_frames = [ICRS, FK4, FK5, Galactic]\nfor rt_frame0 in rt_frames:\n    for rt_frame1 in rt_frames:\n        for equinox0 in (None, \"J1975.0\"):\n            for obstime0 in (None, \"J1980.0\"):\n                for equinox1 in (None, \"J1975.0\"):\n                    for obstime1 in (None, \"J1980.0\"):\n                        rt_sets.append(\n                            (\n                                rt_frame0,\n                                rt_frame1,\n                                equinox0,\n                                equinox1,\n                                obstime0,\n                                obstime1,\n                            )\n                        )\nrt_args = (\"frame0\", \"frame1\", \"equinox0\", \"equinox1\", \"obstime0\", \"obstime1\")\n\n\n@pytest.mark.parametrize(rt_args, rt_sets)\ndef test_round_tripping(frame0, frame1, equinox0, equinox1, obstime0, obstime1):\n    \"\"\"\n    Test round tripping out and back using transform_to in every combination.\n    \"\"\"\n    attrs0 = {\"equinox\": equinox0, \"obstime\": obstime0}\n    attrs1 = {\"equinox\": equinox1, \"obstime\": obstime1}\n\n    # Remove None values\n    attrs0 = {k: v for k, v in attrs0.items() if v is not None}\n    attrs1 = {k: v for k, v in attrs1.items() if v is not None}\n\n    # Go out and back\n    sc = SkyCoord(RA, DEC, frame=frame0, **attrs0)\n\n    # Keep only frame attributes for frame1\n    attrs1 = {\n        attr: val for attr, val in attrs1.items() if attr in frame1.frame_attributes\n    }\n    sc2 = sc.transform_to(frame1(**attrs1))\n\n    # When coming back only keep frame0 attributes for transform_to\n    attrs0 = {\n        attr: val for attr, val in attrs0.items() if attr in frame0.frame_attributes\n    }\n    # also, if any are None, fill in with defaults\n    for attrnm in frame0.frame_attributes:\n        if attrs0.get(attrnm, None) is None:\n            if attrnm == \"obstime\" and frame0.get_frame_attr_defaults()[attrnm] is None:\n                if \"equinox\" in attrs0:\n                    attrs0[attrnm] = attrs0[\"equinox\"]\n            else:\n                attrs0[attrnm] = frame0.get_frame_attr_defaults()[attrnm]\n    sc_rt = sc2.transform_to(frame0(**attrs0))\n\n    if frame0 is Galactic:\n        assert allclose(sc.l, sc_rt.l)\n        assert allclose(sc.b, sc_rt.b)\n    else:\n        assert allclose(sc.ra, sc_rt.ra)\n        assert allclose(sc.dec, sc_rt.dec)\n    if equinox0:\n        assert type(sc.equinox) is Time and sc.equinox == sc_rt.equinox\n    if obstime0:\n        assert type(sc.obstime) is Time and sc.obstime == sc_rt.obstime\n\n\ndef test_coord_init_string():\n    \"\"\"\n    Spherical or Cartesian representation input coordinates.\n    \"\"\"\n    sc = SkyCoord(\"1d 2d\")\n    assert allclose(sc.ra, 1 * u.deg)\n    assert allclose(sc.dec, 2 * u.deg)\n\n    sc = SkyCoord(\"1d\", \"2d\")\n    assert allclose(sc.ra, 1 * u.deg)\n    assert allclose(sc.dec, 2 * u.deg)\n\n    sc = SkyCoord(\"1\u00b02\u20323\u2033\", \"2\u00b03\u20324\u2033\")\n    assert allclose(sc.ra, Angle(\"1\u00b02\u20323\u2033\"))\n    assert allclose(sc.dec, Angle(\"2\u00b03\u20324\u2033\"))\n\n    sc = SkyCoord(\"1\u00b02\u20323\u2033 2\u00b03\u20324\u2033\")\n    assert allclose(sc.ra, Angle(\"1\u00b02\u20323\u2033\"))\n    assert allclose(sc.dec, Angle(\"2\u00b03\u20324\u2033\"))\n\n    with pytest.raises(ValueError) as err:\n        SkyCoord(\"1d 2d 3d\")\n    assert \"Cannot parse first argument data\" in str(err.value)\n\n    sc1 = SkyCoord(\"8 00 00 +5 00 00.0\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc1, SkyCoord)\n    assert allclose(sc1.ra, Angle(120 * u.deg))\n    assert allclose(sc1.dec, Angle(5 * u.deg))\n\n    sc11 = SkyCoord(\"8h00m00s+5d00m00.0s\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc11, SkyCoord)\n    assert allclose(sc1.ra, Angle(120 * u.deg))\n    assert allclose(sc1.dec, Angle(5 * u.deg))\n\n    sc2 = SkyCoord(\"8 00 -5 00 00.0\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc2, SkyCoord)\n    assert allclose(sc2.ra, Angle(120 * u.deg))\n    assert allclose(sc2.dec, Angle(-5 * u.deg))\n\n    sc3 = SkyCoord(\"8 00 -5 00.6\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc3, SkyCoord)\n    assert allclose(sc3.ra, Angle(120 * u.deg))\n    assert allclose(sc3.dec, Angle(-5.01 * u.deg))\n\n    sc4 = SkyCoord(\"J080000.00-050036.00\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc4, SkyCoord)\n    assert allclose(sc4.ra, Angle(120 * u.deg))\n    assert allclose(sc4.dec, Angle(-5.01 * u.deg))\n\n    sc41 = SkyCoord(\"J080000+050036\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc41, SkyCoord)\n    assert allclose(sc41.ra, Angle(120 * u.deg))\n    assert allclose(sc41.dec, Angle(+5.01 * u.deg))\n\n    sc5 = SkyCoord(\"8h00.6m -5d00.6m\", unit=(u.hour, u.deg), frame=\"icrs\")\n    assert isinstance(sc5, SkyCoord)\n    assert allclose(sc5.ra, Angle(120.15 * u.deg))\n    assert allclose(sc5.dec, Angle(-5.01 * u.deg))\n\n    sc6 = SkyCoord(\"8h00.6m -5d00.6m\", unit=(u.hour, u.deg), frame=\"fk4\")\n    assert isinstance(sc6, SkyCoord)\n    assert allclose(sc6.ra, Angle(120.15 * u.deg))\n    assert allclose(sc6.dec, Angle(-5.01 * u.deg))\n\n    sc61 = SkyCoord(\"8h00.6m-5d00.6m\", unit=(u.hour, u.deg), frame=\"fk4\")\n    assert isinstance(sc61, SkyCoord)\n    assert allclose(sc6.ra, Angle(120.15 * u.deg))\n    assert allclose(sc6.dec, Angle(-5.01 * u.deg))\n\n    sc61 = SkyCoord(\"8h00.6-5d00.6\", unit=(u.hour, u.deg), frame=\"fk4\")\n    assert isinstance(sc61, SkyCoord)\n    assert allclose(sc6.ra, Angle(120.15 * u.deg))\n    assert allclose(sc6.dec, Angle(-5.01 * u.deg))\n\n    sc7 = SkyCoord(\"J1874221.60+122421.6\", unit=u.deg)\n    assert isinstance(sc7, SkyCoord)\n    assert allclose(sc7.ra, Angle(187.706 * u.deg))\n    assert allclose(sc7.dec, Angle(12.406 * u.deg))\n\n    with pytest.raises(ValueError):\n        SkyCoord(\"8 00 -5 00.6\", unit=(u.deg, u.deg), frame=\"galactic\")\n\n\ndef test_coord_init_unit():\n    \"\"\"\n    Test variations of the unit keyword.\n    \"\"\"\n    for unit in (\n        \"deg\",\n        \"deg,deg\",\n        \" deg , deg \",\n        u.deg,\n        (u.deg, u.deg),\n        np.array([\"deg\", \"deg\"]),\n    ):\n        sc = SkyCoord(1, 2, unit=unit)\n        assert allclose(sc.ra, Angle(1 * u.deg))\n        assert allclose(sc.dec, Angle(2 * u.deg))\n\n    for unit in (\n        \"hourangle\",\n        \"hourangle,hourangle\",\n        \" hourangle , hourangle \",\n        u.hourangle,\n        [u.hourangle, u.hourangle],\n    ):\n        sc = SkyCoord(1, 2, unit=unit)\n        assert allclose(sc.ra, Angle(15 * u.deg))\n        assert allclose(sc.dec, Angle(30 * u.deg))\n\n    for unit in (\"hourangle,deg\", (u.hourangle, u.deg)):\n        sc = SkyCoord(1, 2, unit=unit)\n        assert allclose(sc.ra, Angle(15 * u.deg))\n        assert allclose(sc.dec, Angle(2 * u.deg))\n\n    for unit in (\"deg,deg,deg,deg\", [u.deg, u.deg, u.deg, u.deg], None):\n        with pytest.raises(ValueError) as err:\n            SkyCoord(1, 2, unit=unit)\n        assert \"Unit keyword must have one to three unit values\" in str(err.value)\n\n    for unit in (\"m\", (u.m, u.deg), \"\"):\n        with pytest.raises(u.UnitsError) as err:\n            SkyCoord(1, 2, unit=unit)\n\n\ndef test_coord_init_list():\n    \"\"\"\n    Spherical or Cartesian representation input coordinates.\n    \"\"\"\n    sc = SkyCoord(\n        [(\"1d\", \"2d\"), (1 * u.deg, 2 * u.deg), \"1d 2d\", (\"1\u00b0\", \"2\u00b0\"), \"1\u00b0 2\u00b0\"],\n        unit=\"deg\",\n    )\n    assert allclose(sc.ra, Angle(\"1d\"))\n    assert allclose(sc.dec, Angle(\"2d\"))\n\n    with pytest.raises(ValueError) as err:\n        SkyCoord([\"1d 2d 3d\"])\n    assert \"Cannot parse first argument data\" in str(err.value)\n\n    with pytest.raises(ValueError) as err:\n        SkyCoord([(\"1d\", \"2d\", \"3d\")])\n    assert \"Cannot parse first argument data\" in str(err.value)\n\n    sc = SkyCoord([1 * u.deg, 1 * u.deg], [2 * u.deg, 2 * u.deg])\n    assert allclose(sc.ra, Angle(\"1d\"))\n    assert allclose(sc.dec, Angle(\"2d\"))\n\n    with pytest.raises(\n        ValueError,\n        match=\"One or more elements of input sequence does not have a length\",\n    ):\n        SkyCoord([1 * u.deg, 2 * u.deg])  # this list is taken as RA w/ missing dec\n\n\ndef test_coord_init_array():\n    \"\"\"\n    Input in the form of a list array or numpy array\n    \"\"\"\n    for a in ([\"1 2\", \"3 4\"], [[\"1\", \"2\"], [\"3\", \"4\"]], [[1, 2], [3, 4]]):\n        sc = SkyCoord(a, unit=\"deg\")\n        assert allclose(sc.ra - [1, 3] * u.deg, 0 * u.deg)\n        assert allclose(sc.dec - [2, 4] * u.deg, 0 * u.deg)\n\n        sc = SkyCoord(np.array(a), unit=\"deg\")\n        assert allclose(sc.ra - [1, 3] * u.deg, 0 * u.deg)\n        assert allclose(sc.dec - [2, 4] * u.deg, 0 * u.deg)\n\n\ndef test_coord_init_representation():\n    \"\"\"\n    Spherical or Cartesian representation input coordinates.\n    \"\"\"\n    coord = SphericalRepresentation(lon=8 * u.deg, lat=5 * u.deg, distance=1 * u.kpc)\n    sc = SkyCoord(coord, frame=\"icrs\")\n    assert allclose(sc.ra, coord.lon)\n    assert allclose(sc.dec, coord.lat)\n    assert allclose(sc.distance, coord.distance)\n\n    with pytest.raises(ValueError) as err:\n        SkyCoord(coord, frame=\"icrs\", ra=\"1d\")\n    assert \"conflicts with keyword argument 'ra'\" in str(err.value)\n\n    coord = CartesianRepresentation(1 * u.one, 2 * u.one, 3 * u.one)\n    sc = SkyCoord(coord, frame=\"icrs\")\n    sc_cart = sc.represent_as(CartesianRepresentation)\n    assert allclose(sc_cart.x, 1.0)\n    assert allclose(sc_cart.y, 2.0)\n    assert allclose(sc_cart.z, 3.0)\n\n\ndef test_frame_init():\n    \"\"\"\n    Different ways of providing the frame.\n    \"\"\"\n\n    sc = SkyCoord(RA, DEC, frame=\"icrs\")\n    assert sc.frame.name == \"icrs\"\n\n    sc = SkyCoord(RA, DEC, frame=ICRS)\n    assert sc.frame.name == \"icrs\"\n\n    sc = SkyCoord(sc)\n    assert sc.frame.name == \"icrs\"\n\n    sc = SkyCoord(C_ICRS)\n    assert sc.frame.name == \"icrs\"\n\n    SkyCoord(C_ICRS, frame=\"icrs\")\n    assert sc.frame.name == \"icrs\"\n\n    with pytest.raises(ValueError) as err:\n        SkyCoord(C_ICRS, frame=\"galactic\")\n    assert \"Cannot override frame=\" in str(err.value)\n\n\ndef test_equal():\n    obstime = \"B1955\"\n    sc1 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg, obstime=obstime)\n    sc2 = SkyCoord([1, 20] * u.deg, [3, 4] * u.deg, obstime=obstime)\n\n    # Compare arrays and scalars\n    eq = sc1 == sc2\n    ne = sc1 != sc2\n    assert np.all(eq == [True, False])\n    assert np.all(ne == [False, True])\n    assert isinstance(v := (sc1[0] == sc2[0]), (bool, np.bool_)) and v\n    assert isinstance(v := (sc1[0] != sc2[0]), (bool, np.bool_)) and not v\n\n    # Broadcasting\n    eq = sc1[0] == sc2\n    ne = sc1[0] != sc2\n    assert np.all(eq == [True, False])\n    assert np.all(ne == [False, True])\n\n    # With diff only in velocity\n    sc1 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg, radial_velocity=[1, 2] * u.km / u.s)\n    sc2 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg, radial_velocity=[1, 20] * u.km / u.s)\n\n    eq = sc1 == sc2\n    ne = sc1 != sc2\n    assert np.all(eq == [True, False])\n    assert np.all(ne == [False, True])\n    assert isinstance(v := (sc1[0] == sc2[0]), (bool, np.bool_)) and v\n    assert isinstance(v := (sc1[0] != sc2[0]), (bool, np.bool_)) and not v\n\n\ndef test_equal_different_type():\n    sc1 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg, obstime=\"B1955\")\n    # Test equals and not equals operators against different types\n    assert sc1 != \"a string\"\n    assert not (sc1 == \"a string\")\n\n\ndef test_equal_exceptions():\n    sc1 = SkyCoord(1 * u.deg, 2 * u.deg, obstime=\"B1955\")\n    sc2 = SkyCoord(1 * u.deg, 2 * u.deg)\n    with pytest.raises(\n        ValueError,\n        match=(\n            \"cannot compare: extra frame attribute 'obstime' is not equivalent\"\n            r\" \\(perhaps compare the frames directly to avoid this exception\\)\"\n        ),\n    ):\n        sc1 == sc2\n    # Note that this exception is the only one raised directly in SkyCoord.\n    # All others come from lower-level classes and are tested in test_frames.py.\n\n\ndef test_attr_inheritance():\n    \"\"\"\n    When initializing from an existing coord the representation attrs like\n    equinox should be inherited to the SkyCoord.  If there is a conflict\n    then raise an exception.\n    \"\"\"\n    sc = SkyCoord(1, 2, frame=\"icrs\", unit=\"deg\", equinox=\"J1999\", obstime=\"J2001\")\n    sc2 = SkyCoord(sc)\n    assert sc2.equinox == sc.equinox\n    assert sc2.obstime == sc.obstime\n    assert allclose(sc2.ra, sc.ra)\n    assert allclose(sc2.dec, sc.dec)\n    assert allclose(sc2.distance, sc.distance)\n\n    sc2 = SkyCoord(sc.frame)  # Doesn't have equinox there so we get FK4 defaults\n    assert sc2.equinox != sc.equinox\n    assert sc2.obstime != sc.obstime\n    assert allclose(sc2.ra, sc.ra)\n    assert allclose(sc2.dec, sc.dec)\n    assert allclose(sc2.distance, sc.distance)\n\n    sc = SkyCoord(1, 2, frame=\"fk4\", unit=\"deg\", equinox=\"J1999\", obstime=\"J2001\")\n    sc2 = SkyCoord(sc)\n    assert sc2.equinox == sc.equinox\n    assert sc2.obstime == sc.obstime\n    assert allclose(sc2.ra, sc.ra)\n    assert allclose(sc2.dec, sc.dec)\n    assert allclose(sc2.distance, sc.distance)\n\n    sc2 = SkyCoord(sc.frame)  # sc.frame has equinox, obstime\n    assert sc2.equinox == sc.equinox\n    assert sc2.obstime == sc.obstime\n    assert allclose(sc2.ra, sc.ra)\n    assert allclose(sc2.dec, sc.dec)\n    assert allclose(sc2.distance, sc.distance)\n\n\n@pytest.mark.parametrize(\"frame\", [\"fk4\", \"fk5\", \"icrs\"])\ndef test_setitem_no_velocity(frame):\n    \"\"\"Test different flavors of item setting for a SkyCoord without a velocity\n    for different frames.  Include a frame attribute that is sometimes an\n    actual frame attribute and sometimes an extra frame attribute.\n    \"\"\"\n    sc0 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg, obstime=\"B1955\", frame=frame)\n    sc2 = SkyCoord([10, 20] * u.deg, [30, 40] * u.deg, obstime=\"B1955\", frame=frame)\n\n    sc1 = sc0.copy()\n    sc1[1] = sc2[0]\n    assert np.allclose(sc1.ra.to_value(u.deg), [1, 10])\n    assert np.allclose(sc1.dec.to_value(u.deg), [3, 30])\n    assert sc1.obstime == Time(\"B1955\")\n    assert sc1.frame.name == frame\n\n    sc1 = sc0.copy()\n    sc1[:] = sc2[0]\n    assert np.allclose(sc1.ra.to_value(u.deg), [10, 10])\n    assert np.allclose(sc1.dec.to_value(u.deg), [30, 30])\n\n    sc1 = sc0.copy()\n    sc1[:] = sc2[:]\n    assert np.allclose(sc1.ra.to_value(u.deg), [10, 20])\n    assert np.allclose(sc1.dec.to_value(u.deg), [30, 40])\n\n    sc1 = sc0.copy()\n    sc1[[1, 0]] = sc2[:]\n    assert np.allclose(sc1.ra.to_value(u.deg), [20, 10])\n    assert np.allclose(sc1.dec.to_value(u.deg), [40, 30])\n\n\ndef test_setitem_initially_broadcast():\n    sc = SkyCoord(np.ones((2, 1)) * u.deg, np.ones((1, 3)) * u.deg)\n    sc[1, 1] = SkyCoord(0 * u.deg, 0 * u.deg)\n    expected = np.ones((2, 3)) * u.deg\n    expected[1, 1] = 0.0\n    assert np.all(sc.ra == expected)\n    assert np.all(sc.dec == expected)\n\n\ndef test_setitem_velocities():\n    \"\"\"Test different flavors of item setting for a SkyCoord with a velocity.\"\"\"\n    sc0 = SkyCoord(\n        [1, 2] * u.deg,\n        [3, 4] * u.deg,\n        radial_velocity=[1, 2] * u.km / u.s,\n        obstime=\"B1950\",\n        frame=\"fk4\",\n    )\n    sc2 = SkyCoord(\n        [10, 20] * u.deg,\n        [30, 40] * u.deg,\n        radial_velocity=[10, 20] * u.km / u.s,\n        obstime=\"B1950\",\n        frame=\"fk4\",\n    )\n\n    sc1 = sc0.copy()\n    sc1[1] = sc2[0]\n    assert np.allclose(sc1.ra.to_value(u.deg), [1, 10])\n    assert np.allclose(sc1.dec.to_value(u.deg), [3, 30])\n    assert np.allclose(sc1.radial_velocity.to_value(u.km / u.s), [1, 10])\n    assert sc1.obstime == Time(\"B1950\")\n    assert sc1.frame.name == \"fk4\"\n\n    sc1 = sc0.copy()\n    sc1[:] = sc2[0]\n    assert np.allclose(sc1.ra.to_value(u.deg), [10, 10])\n    assert np.allclose(sc1.dec.to_value(u.deg), [30, 30])\n    assert np.allclose(sc1.radial_velocity.to_value(u.km / u.s), [10, 10])\n\n    sc1 = sc0.copy()\n    sc1[:] = sc2[:]\n    assert np.allclose(sc1.ra.to_value(u.deg), [10, 20])\n    assert np.allclose(sc1.dec.to_value(u.deg), [30, 40])\n    assert np.allclose(sc1.radial_velocity.to_value(u.km / u.s), [10, 20])\n\n    sc1 = sc0.copy()\n    sc1[[1, 0]] = sc2[:]\n    assert np.allclose(sc1.ra.to_value(u.deg), [20, 10])\n    assert np.allclose(sc1.dec.to_value(u.deg), [40, 30])\n    assert np.allclose(sc1.radial_velocity.to_value(u.km / u.s), [20, 10])\n\n\ndef test_setitem_exceptions():\n    class SkyCoordSub(SkyCoord):\n        pass\n\n    obstime = \"B1955\"\n    sc0 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg, frame=\"fk4\")\n    sc2 = SkyCoord([10, 20] * u.deg, [30, 40] * u.deg, frame=\"fk4\", obstime=obstime)\n\n    sc1 = SkyCoordSub(sc0)\n    with pytest.raises(\n        TypeError,\n        match=\"an only set from object of same class: SkyCoordSub vs. SkyCoord\",\n    ):\n        sc1[0] = sc2[0]\n\n    sc1 = SkyCoord(sc0.ra, sc0.dec, frame=\"fk4\", obstime=\"B2001\")\n    with pytest.raises(\n        ValueError, match=\"can only set frame item from an equivalent frame\"\n    ):\n        sc1.frame[0] = sc2.frame[0]\n\n    sc1 = SkyCoord(sc0.ra[0], sc0.dec[0], frame=\"fk4\", obstime=obstime)\n    with pytest.raises(\n        TypeError, match=\"scalar 'FK4' frame object does not support item assignment\"\n    ):\n        sc1[0] = sc2[0]\n\n    # Different differentials\n    sc1 = SkyCoord(\n        [1, 2] * u.deg,\n        [3, 4] * u.deg,\n        pm_ra_cosdec=[1, 2] * u.mas / u.yr,\n        pm_dec=[3, 4] * u.mas / u.yr,\n    )\n    sc2 = SkyCoord(\n        [10, 20] * u.deg, [30, 40] * u.deg, radial_velocity=[10, 20] * u.km / u.s\n    )\n    with pytest.raises(\n        TypeError,\n        match=(\n            \"can only set from object of same class: \"\n            \"UnitSphericalCosLatDifferential vs. RadialDifferential\"\n        ),\n    ):\n        sc1[0] = sc2[0]\n\n\ndef test_insert():\n    sc0 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg)\n    sc1 = SkyCoord(5 * u.deg, 6 * u.deg)\n    sc3 = SkyCoord([10, 20] * u.deg, [30, 40] * u.deg)\n    sc4 = SkyCoord([[1, 2], [3, 4]] * u.deg, [[5, 6], [7, 8]] * u.deg)\n    sc5 = SkyCoord([[10, 2], [30, 4]] * u.deg, [[50, 6], [70, 8]] * u.deg)\n\n    # Insert a scalar\n    sc = sc0.insert(1, sc1)\n    assert skycoord_equal(sc, SkyCoord([1, 5, 2] * u.deg, [3, 6, 4] * u.deg))\n\n    # Insert length=2 array at start of array\n    sc = sc0.insert(0, sc3)\n    assert skycoord_equal(sc, SkyCoord([10, 20, 1, 2] * u.deg, [30, 40, 3, 4] * u.deg))\n\n    # Insert length=2 array at end of array\n    sc = sc0.insert(2, sc3)\n    assert skycoord_equal(sc, SkyCoord([1, 2, 10, 20] * u.deg, [3, 4, 30, 40] * u.deg))\n\n    # Multidimensional\n    sc = sc4.insert(1, sc5)\n    assert skycoord_equal(\n        sc,\n        SkyCoord(\n            [[1, 2], [10, 2], [30, 4], [3, 4]] * u.deg,\n            [[5, 6], [50, 6], [70, 8], [7, 8]] * u.deg,\n        ),\n    )\n\n\ndef test_insert_exceptions():\n    sc0 = SkyCoord([1, 2] * u.deg, [3, 4] * u.deg)\n    sc1 = SkyCoord(5 * u.deg, 6 * u.deg)\n    # sc3 = SkyCoord([10, 20]*u.deg, [30, 40]*u.deg)\n    sc4 = SkyCoord([[1, 2], [3, 4]] * u.deg, [[5, 6], [7, 8]] * u.deg)\n\n    with pytest.raises(TypeError, match=\"cannot insert into scalar\"):\n        sc1.insert(0, sc0)\n\n    with pytest.raises(ValueError, match=\"axis must be 0\"):\n        sc0.insert(0, sc1, axis=1)\n\n    with pytest.raises(TypeError, match=\"obj arg must be an integer\"):\n        sc0.insert(slice(None), sc0)\n\n    with pytest.raises(\n        IndexError, match=\"index -100 is out of bounds for axis 0 with size 2\"\n    ):\n        sc0.insert(-100, sc0)\n\n    # Bad shape\n    with pytest.raises(\n        ValueError,\n        match=r\"could not broadcast input array from shape \\(2,2\\) into shape \\(2,?\\)\",\n    ):\n        sc0.insert(0, sc4)\n\n\ndef test_attr_conflicts():\n    \"\"\"\n    Check conflicts resolution between coordinate attributes and init kwargs.\n    \"\"\"\n    sc = SkyCoord(1, 2, frame=\"icrs\", unit=\"deg\", equinox=\"J1999\", obstime=\"J2001\")\n\n    # OK if attrs both specified but with identical values\n    SkyCoord(sc, equinox=\"J1999\", obstime=\"J2001\")\n\n    # OK because sc.frame doesn't have obstime\n    SkyCoord(sc.frame, equinox=\"J1999\", obstime=\"J2100\")\n\n    # Not OK if attrs don't match\n    with pytest.raises(ValueError) as err:\n        SkyCoord(sc, equinox=\"J1999\", obstime=\"J2002\")\n    assert \"Coordinate attribute 'obstime'=\" in str(err.value)\n\n    # Same game but with fk4 which has equinox and obstime frame attrs\n    sc = SkyCoord(1, 2, frame=\"fk4\", unit=\"deg\", equinox=\"J1999\", obstime=\"J2001\")\n\n    # OK if attrs both specified but with identical values\n    SkyCoord(sc, equinox=\"J1999\", obstime=\"J2001\")\n\n    # Not OK if SkyCoord attrs don't match\n    with pytest.raises(ValueError) as err:\n        SkyCoord(sc, equinox=\"J1999\", obstime=\"J2002\")\n    assert \"Frame attribute 'obstime' has conflicting\" in str(err.value)\n\n    # Not OK because sc.frame has different attrs\n    with pytest.raises(ValueError) as err:\n        SkyCoord(sc.frame, equinox=\"J1999\", obstime=\"J2002\")\n    assert \"Frame attribute 'obstime' has conflicting\" in str(err.value)\n\n\ndef test_frame_attr_getattr():\n    \"\"\"\n    When accessing frame attributes like equinox, the value should come\n    from self.frame when that object has the relevant attribute, otherwise\n    from self.\n    \"\"\"\n    sc = SkyCoord(1, 2, frame=\"icrs\", unit=\"deg\", equinox=\"J1999\", obstime=\"J2001\")\n    assert sc.equinox == \"J1999\"  # Just the raw value (not validated)\n    assert sc.obstime == \"J2001\"\n\n    sc = SkyCoord(1, 2, frame=\"fk4\", unit=\"deg\", equinox=\"J1999\", obstime=\"J2001\")\n    assert sc.equinox == Time(\"J1999\")  # Coming from the self.frame object\n    assert sc.obstime == Time(\"J2001\")\n\n    sc = SkyCoord(1, 2, frame=\"fk4\", unit=\"deg\", equinox=\"J1999\")\n    assert sc.equinox == Time(\"J1999\")\n    assert sc.obstime == Time(\"J1999\")\n\n\ndef test_to_string():\n    \"\"\"\n    Basic testing of converting SkyCoord to strings.  This just tests\n    for a single input coordinate and and 1-element list.  It does not\n    test the underlying `Angle.to_string` method itself.\n    \"\"\"\n    coord = \"1h2m3s 1d2m3s\"\n    for wrap in (lambda x: x, lambda x: [x]):\n        sc = SkyCoord(wrap(coord))\n        assert sc.to_string() == wrap(\"15.5125 1.03417\")\n        assert sc.to_string(\"dms\") == wrap(\"15d30m45s 1d02m03s\")\n        assert sc.to_string(\"hmsdms\") == wrap(\"01h02m03s +01d02m03s\")\n        with_kwargs = sc.to_string(\"hmsdms\", precision=3, pad=True, alwayssign=True)\n        assert with_kwargs == wrap(\"+01h02m03.000s +01d02m03.000s\")\n\n\n@pytest.mark.parametrize(\"cls_other\", [SkyCoord, ICRS])\ndef test_seps(cls_other):\n    sc1 = SkyCoord(0 * u.deg, 1 * u.deg)\n    sc2 = cls_other(0 * u.deg, 2 * u.deg)\n\n    sep = sc1.separation(sc2)\n\n    assert (sep - 1 * u.deg) / u.deg < 1e-10\n\n    with pytest.raises(ValueError):\n        sc1.separation_3d(sc2)\n\n    sc3 = SkyCoord(1 * u.deg, 1 * u.deg, distance=1 * u.kpc)\n    sc4 = cls_other(1 * u.deg, 1 * u.deg, distance=2 * u.kpc)\n    sep3d = sc3.separation_3d(sc4)\n\n    assert sep3d == 1 * u.kpc\n\n\ndef test_repr():\n    sc1 = SkyCoord(0 * u.deg, 1 * u.deg, frame=\"icrs\")\n    sc2 = SkyCoord(1 * u.deg, 1 * u.deg, frame=\"icrs\", distance=1 * u.kpc)\n\n    assert repr(sc1) == \"<SkyCoord (ICRS): (ra, dec) in deg\\n    (0., 1.)>\"\n    assert (\n        repr(sc2)\n        == \"<SkyCoord (ICRS): (ra, dec, distance) in (deg, deg, kpc)\\n    (1., 1., 1.)>\"\n    )\n\n    sc3 = SkyCoord(0.25 * u.deg, [1, 2.5] * u.deg, frame=\"icrs\")\n    assert repr(sc3).startswith(\"<SkyCoord (ICRS): (ra, dec) in deg\\n\")\n\n    sc_default = SkyCoord(0 * u.deg, 1 * u.deg)\n    assert repr(sc_default) == \"<SkyCoord (ICRS): (ra, dec) in deg\\n    (0., 1.)>\"\n\n\ndef test_repr_altaz():\n    sc2 = SkyCoord(1 * u.deg, 1 * u.deg, frame=\"icrs\", distance=1 * u.kpc)\n    loc = EarthLocation(-2309223 * u.m, -3695529 * u.m, -4641767 * u.m)\n    time = Time(\"2005-03-21 00:00:00\")\n    sc4 = sc2.transform_to(AltAz(location=loc, obstime=time))\n    assert repr(sc4).startswith(\n        \"<SkyCoord (AltAz: obstime=2005-03-21 00:00:00.000, \"\n        \"location=(-2309223., -3695529., -4641767.) m, pressure=0.0 hPa, \"\n        \"temperature=0.0 deg_C, relative_humidity=0.0, obswl=1.0 micron):\"\n        \" (az, alt, distance) in (deg, deg, kpc)\\n\"\n    )\n\n\ndef test_ops():\n    \"\"\"\n    Tests miscellaneous operations like `len`\n    \"\"\"\n    sc = SkyCoord(0 * u.deg, 1 * u.deg, frame=\"icrs\")\n    sc_arr = SkyCoord(0 * u.deg, [1, 2] * u.deg, frame=\"icrs\")\n    sc_empty = SkyCoord([] * u.deg, [] * u.deg, frame=\"icrs\")\n\n    assert sc.isscalar\n    assert not sc_arr.isscalar\n    assert not sc_empty.isscalar\n\n    with pytest.raises(TypeError):\n        len(sc)\n    assert len(sc_arr) == 2\n    assert len(sc_empty) == 0\n\n    assert bool(sc)\n    assert bool(sc_arr)\n    assert not bool(sc_empty)\n\n    assert sc_arr[0].isscalar\n    assert len(sc_arr[:1]) == 1\n    # A scalar shouldn't be indexable\n    with pytest.raises(TypeError):\n        sc[0:]\n    # but it should be possible to just get an item\n    sc_item = sc[()]\n    assert sc_item.shape == ()\n    # and to turn it into an array\n    sc_1d = sc[np.newaxis]\n    assert sc_1d.shape == (1,)\n\n    with pytest.raises(TypeError):\n        iter(sc)\n    assert not isiterable(sc)\n    assert isiterable(sc_arr)\n    assert isiterable(sc_empty)\n    it = iter(sc_arr)\n    assert next(it).dec == sc_arr[0].dec\n    assert next(it).dec == sc_arr[1].dec\n    with pytest.raises(StopIteration):\n        next(it)\n\n\ndef test_none_transform():\n    \"\"\"\n    Ensure that transforming from a SkyCoord with no frame provided works like\n    ICRS\n    \"\"\"\n    sc = SkyCoord(0 * u.deg, 1 * u.deg)\n    sc_arr = SkyCoord(0 * u.deg, [1, 2] * u.deg)\n\n    sc2 = sc.transform_to(ICRS)\n    assert sc.ra == sc2.ra and sc.dec == sc2.dec\n\n    sc5 = sc.transform_to(\"fk5\")\n    assert sc5.ra == sc2.transform_to(\"fk5\").ra\n\n    sc_arr2 = sc_arr.transform_to(ICRS)\n    sc_arr5 = sc_arr.transform_to(\"fk5\")\n    npt.assert_array_equal(sc_arr5.ra, sc_arr2.transform_to(\"fk5\").ra)\n\n\ndef test_position_angle():\n    c1 = SkyCoord(0 * u.deg, 0 * u.deg)\n\n    c2 = SkyCoord(1 * u.deg, 0 * u.deg)\n    assert_allclose(c1.position_angle(c2) - 90.0 * u.deg, 0 * u.deg)\n\n    c3 = SkyCoord(1 * u.deg, 0.1 * u.deg)\n    assert c1.position_angle(c3) < 90 * u.deg\n\n    c4 = SkyCoord(0 * u.deg, 1 * u.deg)\n    assert_allclose(c1.position_angle(c4), 0 * u.deg)\n\n    carr1 = SkyCoord(0 * u.deg, [0, 1, 2] * u.deg)\n    carr2 = SkyCoord([-1, -2, -3] * u.deg, [0.1, 1.1, 2.1] * u.deg)\n\n    res = carr1.position_angle(carr2)\n    assert res.shape == (3,)\n    assert np.all(res < 360 * u.degree)\n    assert np.all(res > 270 * u.degree)\n\n    cicrs = SkyCoord(0 * u.deg, 0 * u.deg, frame=\"icrs\")\n    cfk5 = SkyCoord(1 * u.deg, 0 * u.deg, frame=\"fk5\")\n    # because of the frame transform, it's just a *bit* more than 90 degrees\n    assert cicrs.position_angle(cfk5) > 90.0 * u.deg\n    assert cicrs.position_angle(cfk5) < 91.0 * u.deg\n\n\ndef test_position_angle_directly():\n    \"\"\"Regression check for #3800: position_angle should accept floats.\"\"\"\n    from astropy.coordinates.angle_utilities import position_angle\n\n    result = position_angle(10.0, 20.0, 10.0, 20.0)\n    assert result.unit is u.radian\n    assert result.value == 0.0\n\n\ndef test_sep_pa_equivalence():\n    \"\"\"Regression check for bug in #5702.\n\n    PA and separation from object 1 to 2 should be consistent with those\n    from 2 to 1\n    \"\"\"\n    cfk5 = SkyCoord(1 * u.deg, 0 * u.deg, frame=\"fk5\")\n    cfk5B1950 = SkyCoord(1 * u.deg, 0 * u.deg, frame=\"fk5\", equinox=\"B1950\")\n    # test with both default and explicit equinox #5722 and #3106\n    sep_forward = cfk5.separation(cfk5B1950)\n    sep_backward = cfk5B1950.separation(cfk5)\n    assert sep_forward != 0 and sep_backward != 0\n    assert_allclose(sep_forward, sep_backward)\n    posang_forward = cfk5.position_angle(cfk5B1950)\n    posang_backward = cfk5B1950.position_angle(cfk5)\n    assert posang_forward != 0 and posang_backward != 0\n    assert 179 < (posang_forward - posang_backward).wrap_at(360 * u.deg).degree < 181\n    dcfk5 = SkyCoord(1 * u.deg, 0 * u.deg, frame=\"fk5\", distance=1 * u.pc)\n    dcfk5B1950 = SkyCoord(\n        1 * u.deg, 0 * u.deg, frame=\"fk5\", equinox=\"B1950\", distance=1.0 * u.pc\n    )\n    sep3d_forward = dcfk5.separation_3d(dcfk5B1950)\n    sep3d_backward = dcfk5B1950.separation_3d(dcfk5)\n    assert sep3d_forward != 0 and sep3d_backward != 0\n    assert_allclose(sep3d_forward, sep3d_backward)\n\n\ndef test_directional_offset_by():\n    # Round-trip tests: where is sc2 from sc1?\n    # Use those offsets from sc1 and verify you get to sc2.\n    npoints = 7  # How many points when doing vectors of SkyCoords\n    for sc1 in [\n        SkyCoord(0 * u.deg, -90 * u.deg),  # South pole\n        SkyCoord(0 * u.deg, 90 * u.deg),  # North pole\n        SkyCoord(1 * u.deg, 2 * u.deg),\n        SkyCoord(\n            np.linspace(0, 359, npoints),\n            np.linspace(-90, 90, npoints),\n            unit=u.deg,\n            frame=\"fk4\",\n        ),\n        SkyCoord(\n            np.linspace(359, 0, npoints),\n            np.linspace(-90, 90, npoints),\n            unit=u.deg,\n            frame=\"icrs\",\n        ),\n        SkyCoord(\n            np.linspace(-3, 3, npoints),\n            np.linspace(-90, 90, npoints),\n            unit=(u.rad, u.deg),\n            frame=\"barycentricmeanecliptic\",\n        ),\n    ]:\n        for sc2 in [\n            SkyCoord(5 * u.deg, 10 * u.deg),\n            SkyCoord(\n                np.linspace(0, 359, npoints),\n                np.linspace(-90, 90, npoints),\n                unit=u.deg,\n                frame=\"galactic\",\n            ),\n        ]:\n            # Find the displacement from sc1 to sc2,\n            posang = sc1.position_angle(sc2)\n            sep = sc1.separation(sc2)\n\n            # then do the offset from sc1 and verify that you are at sc2\n            sc2a = sc1.directional_offset_by(position_angle=posang, separation=sep)\n            assert np.max(np.abs(sc2.separation(sc2a).arcsec)) < 1e-3\n\n    # Specific test cases\n    # Go over the North pole a little way, and\n    # over the South pole a long way, to get to same spot\n    sc1 = SkyCoord(0 * u.deg, 89 * u.deg)\n    for posang, sep in [(0 * u.deg, 2 * u.deg), (180 * u.deg, 358 * u.deg)]:\n        sc2 = sc1.directional_offset_by(posang, sep)\n        assert allclose([sc2.ra.degree, sc2.dec.degree], [180, 89])\n        # Go twice as far to ensure that dec is actually changing\n        # and that >360deg is supported\n        sc2 = sc1.directional_offset_by(posang, 2 * sep)\n        assert allclose([sc2.ra.degree, sc2.dec.degree], [180, 87])\n\n    # Verify that a separation of 180 deg in any direction gets to the antipode\n    # and 360 deg returns to start\n    sc1 = SkyCoord(10 * u.deg, 47 * u.deg)\n    for posang in np.linspace(0, 377, npoints):\n        sc2 = sc1.directional_offset_by(posang, 180 * u.deg)\n        assert allclose([sc2.ra.degree, sc2.dec.degree], [190, -47])\n        sc2 = sc1.directional_offset_by(posang, 360 * u.deg)\n        assert allclose([sc2.ra.degree, sc2.dec.degree], [10, 47])\n\n    # Verify that a 90 degree posang, which means East\n    # corresponds to an increase in RA, by ~separation/cos(dec) and\n    # a slight convergence to equator\n    sc1 = SkyCoord(10 * u.deg, 60 * u.deg)\n    sc2 = sc1.directional_offset_by(90 * u.deg, 1.0 * u.deg)\n    assert 11.9 < sc2.ra.degree < 12.0\n    assert 59.9 < sc2.dec.degree < 60.0\n\n\ndef test_table_to_coord():\n    \"\"\"\n    Checks \"end-to-end\" use of `Table` with `SkyCoord` - the `Quantity`\n    initializer is the intermediary that translate the table columns into\n    something coordinates understands.\n\n    (Regression test for #1762 )\n    \"\"\"\n    from astropy.table import Column, Table\n\n    t = Table()\n    t.add_column(Column(data=[1, 2, 3], name=\"ra\", unit=u.deg))\n    t.add_column(Column(data=[4, 5, 6], name=\"dec\", unit=u.deg))\n\n    c = SkyCoord(t[\"ra\"], t[\"dec\"])\n\n    assert allclose(c.ra.to(u.deg), [1, 2, 3] * u.deg)\n    assert allclose(c.dec.to(u.deg), [4, 5, 6] * u.deg)\n\n\ndef assert_quantities_allclose(coord, q1s, attrs):\n    \"\"\"\n    Compare two tuples of quantities.  This assumes that the values in q1 are of\n    order(1) and uses atol=1e-13, rtol=0.  It also asserts that the units of the\n    two quantities are the *same*, in order to check that the representation\n    output has the expected units.\n    \"\"\"\n    q2s = [getattr(coord, attr) for attr in attrs]\n    assert len(q1s) == len(q2s)\n    for q1, q2 in zip(q1s, q2s):\n        assert q1.shape == q2.shape\n        assert allclose(q1, q2, rtol=0, atol=1e-13 * q1.unit)\n\n\n# Sets of inputs corresponding to Galactic frame\nbase_unit_attr_sets = [\n    (\"spherical\", u.karcsec, u.karcsec, u.kpc, Latitude, \"l\", \"b\", \"distance\"),\n    (\"unitspherical\", u.karcsec, u.karcsec, None, Latitude, \"l\", \"b\", None),\n    (\"physicsspherical\", u.karcsec, u.karcsec, u.kpc, Angle, \"phi\", \"theta\", \"r\"),\n    (\"cartesian\", u.km, u.km, u.km, u.Quantity, \"u\", \"v\", \"w\"),\n    (\"cylindrical\", u.km, u.karcsec, u.km, Angle, \"rho\", \"phi\", \"z\"),\n]\n\nunits_attr_sets = []\nfor base_unit_attr_set in base_unit_attr_sets:\n    repr_name = base_unit_attr_set[0]\n    for representation in (repr_name, REPRESENTATION_CLASSES[repr_name]):\n        for c1, c2, c3 in ((1, 2, 3), ([1], [2], [3])):\n            for arrayify in True, False:\n                if arrayify:\n                    c1 = np.array(c1)\n                    c2 = np.array(c2)\n                    c3 = np.array(c3)\n                units_attr_sets.append(\n                    base_unit_attr_set + (representation, c1, c2, c3)\n                )\nunits_attr_args = (\n    \"repr_name\",\n    \"unit1\",\n    \"unit2\",\n    \"unit3\",\n    \"cls2\",\n    \"attr1\",\n    \"attr2\",\n    \"attr3\",\n    \"representation\",\n    \"c1\",\n    \"c2\",\n    \"c3\",\n)\n\n\n@pytest.mark.parametrize(\n    units_attr_args, [x for x in units_attr_sets if x[0] != \"unitspherical\"]\n)\ndef test_skycoord_three_components(\n    repr_name,\n    unit1,\n    unit2,\n    unit3,\n    cls2,\n    attr1,\n    attr2,\n    attr3,\n    representation,\n    c1,\n    c2,\n    c3,\n):\n    \"\"\"\n    Tests positional inputs using components (COMP1, COMP2, COMP3)\n    and various representations.  Use weird units and Galactic frame.\n    \"\"\"\n    sc = SkyCoord(\n        c1,\n        c2,\n        c3,\n        unit=(unit1, unit2, unit3),\n        representation_type=representation,\n        frame=Galactic,\n    )\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n    sc = SkyCoord(\n        1000 * c1 * u.Unit(unit1 / 1000),\n        cls2(c2, unit=unit2),\n        1000 * c3 * u.Unit(unit3 / 1000),\n        frame=Galactic,\n        unit=(unit1, unit2, unit3),\n        representation_type=representation,\n    )\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n    kwargs = {attr3: c3}\n    sc = SkyCoord(\n        c1,\n        c2,\n        unit=(unit1, unit2, unit3),\n        frame=Galactic,\n        representation_type=representation,\n        **kwargs,\n    )\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n    kwargs = {attr1: c1, attr2: c2, attr3: c3}\n    sc = SkyCoord(\n        frame=Galactic,\n        unit=(unit1, unit2, unit3),\n        representation_type=representation,\n        **kwargs,\n    )\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n\n@pytest.mark.parametrize(\n    units_attr_args,\n    [x for x in units_attr_sets if x[0] in (\"spherical\", \"unitspherical\")],\n)\ndef test_skycoord_spherical_two_components(\n    repr_name,\n    unit1,\n    unit2,\n    unit3,\n    cls2,\n    attr1,\n    attr2,\n    attr3,\n    representation,\n    c1,\n    c2,\n    c3,\n):\n    \"\"\"\n    Tests positional inputs using components (COMP1, COMP2) for spherical\n    representations.  Use weird units and Galactic frame.\n    \"\"\"\n    sc = SkyCoord(\n        c1, c2, unit=(unit1, unit2), frame=Galactic, representation_type=representation\n    )\n    assert_quantities_allclose(sc, (c1 * unit1, c2 * unit2), (attr1, attr2))\n\n    sc = SkyCoord(\n        1000 * c1 * u.Unit(unit1 / 1000),\n        cls2(c2, unit=unit2),\n        frame=Galactic,\n        unit=(unit1, unit2, unit3),\n        representation_type=representation,\n    )\n    assert_quantities_allclose(sc, (c1 * unit1, c2 * unit2), (attr1, attr2))\n\n    kwargs = {attr1: c1, attr2: c2}\n    sc = SkyCoord(\n        frame=Galactic,\n        unit=(unit1, unit2),\n        representation_type=representation,\n        **kwargs,\n    )\n    assert_quantities_allclose(sc, (c1 * unit1, c2 * unit2), (attr1, attr2))\n\n\n@pytest.mark.parametrize(\n    units_attr_args, [x for x in units_attr_sets if x[0] != \"unitspherical\"]\n)\ndef test_galactic_three_components(\n    repr_name,\n    unit1,\n    unit2,\n    unit3,\n    cls2,\n    attr1,\n    attr2,\n    attr3,\n    representation,\n    c1,\n    c2,\n    c3,\n):\n    \"\"\"\n    Tests positional inputs using components (COMP1, COMP2, COMP3)\n    and various representations.  Use weird units and Galactic frame.\n    \"\"\"\n    sc = Galactic(\n        1000 * c1 * u.Unit(unit1 / 1000),\n        cls2(c2, unit=unit2),\n        1000 * c3 * u.Unit(unit3 / 1000),\n        representation_type=representation,\n    )\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n    kwargs = {attr3: c3 * unit3}\n    sc = Galactic(c1 * unit1, c2 * unit2, representation_type=representation, **kwargs)\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n    kwargs = {attr1: c1 * unit1, attr2: c2 * unit2, attr3: c3 * unit3}\n    sc = Galactic(representation_type=representation, **kwargs)\n    assert_quantities_allclose(\n        sc, (c1 * unit1, c2 * unit2, c3 * unit3), (attr1, attr2, attr3)\n    )\n\n\n@pytest.mark.parametrize(\n    units_attr_args,\n    [x for x in units_attr_sets if x[0] in (\"spherical\", \"unitspherical\")],\n)\ndef test_galactic_spherical_two_components(\n    repr_name,\n    unit1,\n    unit2,\n    unit3,\n    cls2,\n    attr1,\n    attr2,\n    attr3,\n    representation,\n    c1,\n    c2,\n    c3,\n):\n    \"\"\"\n    Tests positional inputs using components (COMP1, COMP2) for spherical\n    representations.  Use weird units and Galactic frame.\n    \"\"\"\n\n    sc = Galactic(\n        1000 * c1 * u.Unit(unit1 / 1000),\n        cls2(c2, unit=unit2),\n        representation_type=representation,\n    )\n    assert_quantities_allclose(sc, (c1 * unit1, c2 * unit2), (attr1, attr2))\n\n    sc = Galactic(c1 * unit1, c2 * unit2, representation_type=representation)\n    assert_quantities_allclose(sc, (c1 * unit1, c2 * unit2), (attr1, attr2))\n\n    kwargs = {attr1: c1 * unit1, attr2: c2 * unit2}\n    sc = Galactic(representation_type=representation, **kwargs)\n    assert_quantities_allclose(sc, (c1 * unit1, c2 * unit2), (attr1, attr2))\n\n\n@pytest.mark.parametrize(\n    (\"repr_name\", \"unit1\", \"unit2\", \"unit3\", \"cls2\", \"attr1\", \"attr2\", \"attr3\"),\n    [x for x in base_unit_attr_sets if x[0] != \"unitspherical\"],\n)\ndef test_skycoord_coordinate_input(\n    repr_name, unit1, unit2, unit3, cls2, attr1, attr2, attr3\n):\n    c1, c2, c3 = 1, 2, 3\n    sc = SkyCoord(\n        [(c1, c2, c3)],\n        unit=(unit1, unit2, unit3),\n        representation_type=repr_name,\n        frame=\"galactic\",\n    )\n    assert_quantities_allclose(\n        sc, ([c1] * unit1, [c2] * unit2, [c3] * unit3), (attr1, attr2, attr3)\n    )\n\n    c1, c2, c3 = 1 * unit1, 2 * unit2, 3 * unit3\n    sc = SkyCoord([(c1, c2, c3)], representation_type=repr_name, frame=\"galactic\")\n    assert_quantities_allclose(\n        sc, ([1] * unit1, [2] * unit2, [3] * unit3), (attr1, attr2, attr3)\n    )\n\n\ndef test_skycoord_string_coordinate_input():\n    sc = SkyCoord(\"01 02 03 +02 03 04\", unit=\"deg\", representation_type=\"unitspherical\")\n    assert_quantities_allclose(\n        sc,\n        (Angle(\"01:02:03\", unit=\"deg\"), Angle(\"02:03:04\", unit=\"deg\")),\n        (\"ra\", \"dec\"),\n    )\n    sc = SkyCoord(\n        [\"01 02 03 +02 03 04\"], unit=\"deg\", representation_type=\"unitspherical\"\n    )\n    assert_quantities_allclose(\n        sc,\n        (Angle([\"01:02:03\"], unit=\"deg\"), Angle([\"02:03:04\"], unit=\"deg\")),\n        (\"ra\", \"dec\"),\n    )\n\n\ndef test_units():\n    sc = SkyCoord(1, 2, 3, unit=\"m\", representation_type=\"cartesian\")  # All get meters\n    assert sc.x.unit is u.m\n    assert sc.y.unit is u.m\n    assert sc.z.unit is u.m\n\n    # All get u.m\n    sc = SkyCoord(1, 2 * u.km, 3, unit=\"m\", representation_type=\"cartesian\")\n    assert sc.x.unit is u.m\n    assert sc.y.unit is u.m\n    assert sc.z.unit is u.m\n\n    sc = SkyCoord(1, 2, 3, unit=u.m, representation_type=\"cartesian\")  # All get u.m\n    assert sc.x.unit is u.m\n    assert sc.y.unit is u.m\n    assert sc.z.unit is u.m\n\n    sc = SkyCoord(1, 2, 3, unit=\"m, km, pc\", representation_type=\"cartesian\")\n    assert_quantities_allclose(sc, (1 * u.m, 2 * u.km, 3 * u.pc), (\"x\", \"y\", \"z\"))\n\n    with pytest.raises(u.UnitsError) as err:\n        SkyCoord(1, 2, 3, unit=(u.m, u.m), representation_type=\"cartesian\")\n    assert \"should have matching physical types\" in str(err.value)\n\n    SkyCoord(1, 2, 3, unit=(u.m, u.km, u.pc), representation_type=\"cartesian\")\n    assert_quantities_allclose(sc, (1 * u.m, 2 * u.km, 3 * u.pc), (\"x\", \"y\", \"z\"))\n\n\n@pytest.mark.xfail\ndef test_units_known_fail():\n    # should fail but doesn't => corner case oddity\n    with pytest.raises(u.UnitsError):\n        SkyCoord(1, 2, 3, unit=u.deg, representation_type=\"spherical\")\n\n\ndef test_nodata_failure():\n    with pytest.raises(ValueError):\n        SkyCoord()\n\n\n@pytest.mark.parametrize((\"mode\", \"origin\"), [(\"wcs\", 0), (\"all\", 0), (\"all\", 1)])\ndef test_wcs_methods(mode, origin):\n    from astropy.utils.data import get_pkg_data_contents\n    from astropy.wcs import WCS\n    from astropy.wcs.utils import pixel_to_skycoord\n\n    header = get_pkg_data_contents(\n        \"../../wcs/tests/data/maps/1904-66_TAN.hdr\", encoding=\"binary\"\n    )\n    wcs = WCS(header)\n\n    ref = SkyCoord(0.1 * u.deg, -89.0 * u.deg, frame=\"icrs\")\n\n    xp, yp = ref.to_pixel(wcs, mode=mode, origin=origin)\n\n    # WCS is in FK5 so we need to transform back to ICRS\n    new = pixel_to_skycoord(xp, yp, wcs, mode=mode, origin=origin).transform_to(\"icrs\")\n\n    assert_allclose(new.ra.degree, ref.ra.degree)\n    assert_allclose(new.dec.degree, ref.dec.degree)\n\n    # also try to round-trip with `from_pixel`\n    scnew = SkyCoord.from_pixel(xp, yp, wcs, mode=mode, origin=origin).transform_to(\n        \"icrs\"\n    )\n    assert_allclose(scnew.ra.degree, ref.ra.degree)\n    assert_allclose(scnew.dec.degree, ref.dec.degree)\n\n    # Also make sure the right type comes out\n    class SkyCoord2(SkyCoord):\n        pass\n\n    scnew2 = SkyCoord2.from_pixel(xp, yp, wcs, mode=mode, origin=origin)\n    assert scnew.__class__ is SkyCoord\n    assert scnew2.__class__ is SkyCoord2\n\n\ndef test_frame_attr_transform_inherit():\n    \"\"\"\n    Test that frame attributes get inherited as expected during transform.\n    Driven by #3106.\n    \"\"\"\n    c = SkyCoord(1 * u.deg, 2 * u.deg, frame=FK5)\n    c2 = c.transform_to(FK4)\n    assert c2.equinox.value == \"B1950.000\"\n    assert c2.obstime.value == \"B1950.000\"\n\n    c2 = c.transform_to(FK4(equinox=\"J1975\", obstime=\"J1980\"))\n    assert c2.equinox.value == \"J1975.000\"\n    assert c2.obstime.value == \"J1980.000\"\n\n    c = SkyCoord(1 * u.deg, 2 * u.deg, frame=FK4)\n    c2 = c.transform_to(FK5)\n    assert c2.equinox.value == \"J2000.000\"\n    assert c2.obstime is None\n\n    c = SkyCoord(1 * u.deg, 2 * u.deg, frame=FK4, obstime=\"J1980\")\n    c2 = c.transform_to(FK5)\n    assert c2.equinox.value == \"J2000.000\"\n    assert c2.obstime.value == \"J1980.000\"\n\n    c = SkyCoord(1 * u.deg, 2 * u.deg, frame=FK4, equinox=\"J1975\", obstime=\"J1980\")\n    c2 = c.transform_to(FK5)\n    assert c2.equinox.value == \"J1975.000\"\n    assert c2.obstime.value == \"J1980.000\"\n\n    c2 = c.transform_to(FK5(equinox=\"J1990\"))\n    assert c2.equinox.value == \"J1990.000\"\n    assert c2.obstime.value == \"J1980.000\"\n\n    # The work-around for #5722\n    c = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"fk5\")\n    c1 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"fk5\", equinox=\"B1950.000\")\n    c2 = c1.transform_to(c)\n    assert not c2.is_equivalent_frame(c)  # counterintuitive, but documented\n    assert c2.equinox.value == \"B1950.000\"\n    c3 = c1.transform_to(c, merge_attributes=False)\n    assert c3.equinox.value == \"J2000.000\"\n    assert c3.is_equivalent_frame(c)\n\n\ndef test_deepcopy():\n    c1 = SkyCoord(1 * u.deg, 2 * u.deg)\n    c2 = copy.copy(c1)\n    c3 = copy.deepcopy(c1)\n\n    c4 = SkyCoord(\n        [1, 2] * u.m,\n        [2, 3] * u.m,\n        [3, 4] * u.m,\n        representation_type=\"cartesian\",\n        frame=\"fk5\",\n        obstime=\"J1999.9\",\n        equinox=\"J1988.8\",\n    )\n    c5 = copy.deepcopy(c4)\n    assert np.all(c5.x == c4.x)  # and y and z\n    assert c5.frame.name == c4.frame.name\n    assert c5.obstime == c4.obstime\n    assert c5.equinox == c4.equinox\n    assert c5.representation_type == c4.representation_type\n\n\ndef test_no_copy():\n    c1 = SkyCoord(np.arange(10.0) * u.hourangle, np.arange(20.0, 30.0) * u.deg)\n    c2 = SkyCoord(c1, copy=False)\n    # Note: c1.ra and c2.ra will *not* share memory, as these are recalculated\n    # to be in \"preferred\" units.  See discussion in #4883.\n    assert np.may_share_memory(c1.data.lon, c2.data.lon)\n    c3 = SkyCoord(c1, copy=True)\n    assert not np.may_share_memory(c1.data.lon, c3.data.lon)\n\n\ndef test_immutable():\n    c1 = SkyCoord(1 * u.deg, 2 * u.deg)\n    with pytest.raises(AttributeError):\n        c1.ra = 3.0\n\n    c1.foo = 42\n    assert c1.foo == 42\n\n\n@pytest.mark.skipif(not HAS_SCIPY, reason=\"Requires scipy\")\ndef test_search_around():\n    \"\"\"\n    Test the search_around_* methods\n\n    Here we don't actually test the values are right, just that the methods of\n    SkyCoord work.  The accuracy tests are in ``test_matching.py``\n    \"\"\"\n    from astropy.utils import NumpyRNGContext\n\n    with NumpyRNGContext(987654321):\n        sc1 = SkyCoord(\n            np.random.rand(20) * 360.0 * u.degree,\n            (np.random.rand(20) * 180.0 - 90.0) * u.degree,\n        )\n        sc2 = SkyCoord(\n            np.random.rand(100) * 360.0 * u.degree,\n            (np.random.rand(100) * 180.0 - 90.0) * u.degree,\n        )\n\n        sc1ds = SkyCoord(ra=sc1.ra, dec=sc1.dec, distance=np.random.rand(20) * u.kpc)\n        sc2ds = SkyCoord(ra=sc2.ra, dec=sc2.dec, distance=np.random.rand(100) * u.kpc)\n\n    idx1_sky, idx2_sky, d2d_sky, d3d_sky = sc1.search_around_sky(sc2, 10 * u.deg)\n    idx1_3d, idx2_3d, d2d_3d, d3d_3d = sc1ds.search_around_3d(sc2ds, 250 * u.pc)\n\n\ndef test_init_with_frame_instance_keyword():\n    # Frame instance\n    c1 = SkyCoord(3 * u.deg, 4 * u.deg, frame=FK5(equinox=\"J2010\"))\n    assert c1.equinox == Time(\"J2010\")\n\n    # Frame instance with data (data gets ignored)\n    c2 = SkyCoord(\n        3 * u.deg, 4 * u.deg, frame=FK5(1.0 * u.deg, 2 * u.deg, equinox=\"J2010\")\n    )\n    assert c2.equinox == Time(\"J2010\")\n    assert allclose(c2.ra.degree, 3)\n    assert allclose(c2.dec.degree, 4)\n\n    # SkyCoord instance\n    c3 = SkyCoord(3 * u.deg, 4 * u.deg, frame=c1)\n    assert c3.equinox == Time(\"J2010\")\n\n    # Check duplicate arguments\n    with pytest.raises(ValueError) as err:\n        c = SkyCoord(3 * u.deg, 4 * u.deg, frame=FK5(equinox=\"J2010\"), equinox=\"J2001\")\n    assert \"Cannot specify frame attribute 'equinox'\" in str(err.value)\n\n\ndef test_guess_from_table():\n    from astropy.table import Column, Table\n    from astropy.utils import NumpyRNGContext\n\n    tab = Table()\n    with NumpyRNGContext(987654321):\n        tab.add_column(Column(data=np.random.rand(10), unit=\"deg\", name=\"RA[J2000]\"))\n        tab.add_column(Column(data=np.random.rand(10), unit=\"deg\", name=\"DEC[J2000]\"))\n\n    sc = SkyCoord.guess_from_table(tab)\n    npt.assert_array_equal(sc.ra.deg, tab[\"RA[J2000]\"])\n    npt.assert_array_equal(sc.dec.deg, tab[\"DEC[J2000]\"])\n\n    # try without units in the table\n    tab[\"RA[J2000]\"].unit = None\n    tab[\"DEC[J2000]\"].unit = None\n    # should fail if not given explicitly\n    with pytest.raises(u.UnitsError):\n        sc2 = SkyCoord.guess_from_table(tab)\n\n    # but should work if provided\n    sc2 = SkyCoord.guess_from_table(tab, unit=u.deg)\n    npt.assert_array_equal(sc2.ra.deg, tab[\"RA[J2000]\"])\n    npt.assert_array_equal(sc2.dec.deg, tab[\"DEC[J2000]\"])\n\n    # should fail if two options are available - ambiguity bad!\n    tab.add_column(Column(data=np.random.rand(10), name=\"RA_J1900\"))\n    with pytest.raises(ValueError) as excinfo:\n        SkyCoord.guess_from_table(tab, unit=u.deg)\n    assert \"J1900\" in excinfo.value.args[0] and \"J2000\" in excinfo.value.args[0]\n\n    tab.remove_column(\"RA_J1900\")\n    tab[\"RA[J2000]\"].unit = u.deg\n    tab[\"DEC[J2000]\"].unit = u.deg\n\n    # but should succeed if the ambiguity can be broken b/c one of the matches\n    # is the name of a different component\n    tab.add_column(Column(data=np.random.rand(10) * u.mas / u.yr, name=\"pm_ra_cosdec\"))\n    tab.add_column(Column(data=np.random.rand(10) * u.mas / u.yr, name=\"pm_dec\"))\n    sc3 = SkyCoord.guess_from_table(tab)\n    assert u.allclose(sc3.ra, tab[\"RA[J2000]\"])\n    assert u.allclose(sc3.dec, tab[\"DEC[J2000]\"])\n    assert u.allclose(sc3.pm_ra_cosdec, tab[\"pm_ra_cosdec\"])\n    assert u.allclose(sc3.pm_dec, tab[\"pm_dec\"])\n\n    # should fail if stuff doesn't have proper units\n    tab[\"RA[J2000]\"].unit = None\n    tab[\"DEC[J2000]\"].unit = None\n    with pytest.raises(u.UnitTypeError, match=\"no unit was given.\"):\n        SkyCoord.guess_from_table(tab)\n\n    tab.remove_column(\"pm_ra_cosdec\")\n    tab.remove_column(\"pm_dec\")\n\n    # should also fail if user specifies something already in the table, but\n    # should succeed even if the user has to give one of the components\n    with pytest.raises(ValueError):\n        SkyCoord.guess_from_table(tab, ra=tab[\"RA[J2000]\"], unit=u.deg)\n\n    oldra = tab[\"RA[J2000]\"]\n    tab.remove_column(\"RA[J2000]\")\n    sc3 = SkyCoord.guess_from_table(tab, ra=oldra, unit=u.deg)\n    npt.assert_array_equal(sc3.ra.deg, oldra)\n    npt.assert_array_equal(sc3.dec.deg, tab[\"DEC[J2000]\"])\n\n    # check a few non-ICRS/spherical systems\n    x, y, z = np.arange(3).reshape(3, 1) * u.pc\n    l, b = np.arange(2).reshape(2, 1) * u.deg\n\n    tabcart = Table([x, y, z], names=(\"x\", \"y\", \"z\"))\n    tabgal = Table([b, l], names=(\"b\", \"l\"))\n\n    sc_cart = SkyCoord.guess_from_table(tabcart, representation_type=\"cartesian\")\n    npt.assert_array_equal(sc_cart.x, x)\n    npt.assert_array_equal(sc_cart.y, y)\n    npt.assert_array_equal(sc_cart.z, z)\n\n    sc_gal = SkyCoord.guess_from_table(tabgal, frame=\"galactic\")\n    npt.assert_array_equal(sc_gal.l, l)\n    npt.assert_array_equal(sc_gal.b, b)\n\n    # also try some column names that *end* with the attribute name\n    tabgal[\"b\"].name = \"gal_b\"\n    tabgal[\"l\"].name = \"gal_l\"\n    SkyCoord.guess_from_table(tabgal, frame=\"galactic\")\n\n    tabgal[\"gal_b\"].name = \"blob\"\n    tabgal[\"gal_l\"].name = \"central\"\n    with pytest.raises(ValueError):\n        SkyCoord.guess_from_table(tabgal, frame=\"galactic\")\n\n\ndef test_skycoord_list_creation():\n    \"\"\"\n    Test that SkyCoord can be created in a reasonable way with lists of SkyCoords\n    (regression for #2702)\n    \"\"\"\n    sc = SkyCoord(ra=[1, 2, 3] * u.deg, dec=[4, 5, 6] * u.deg)\n    sc0 = sc[0]\n    sc2 = sc[2]\n    scnew = SkyCoord([sc0, sc2])\n    assert np.all(scnew.ra == [1, 3] * u.deg)\n    assert np.all(scnew.dec == [4, 6] * u.deg)\n\n    # also check ranges\n    sc01 = sc[:2]\n    scnew2 = SkyCoord([sc01, sc2])\n    assert np.all(scnew2.ra == sc.ra)\n    assert np.all(scnew2.dec == sc.dec)\n\n    # now try with a mix of skycoord, frame, and repr objects\n    frobj = ICRS(2 * u.deg, 5 * u.deg)\n    reprobj = UnitSphericalRepresentation(3 * u.deg, 6 * u.deg)\n    scnew3 = SkyCoord([sc0, frobj, reprobj])\n    assert np.all(scnew3.ra == sc.ra)\n    assert np.all(scnew3.dec == sc.dec)\n\n    # should *fail* if different frame attributes or types are passed in\n    scfk5_j2000 = SkyCoord(1 * u.deg, 4 * u.deg, frame=\"fk5\")\n    with pytest.raises(ValueError):\n        SkyCoord([sc0, scfk5_j2000])\n    scfk5_j2010 = SkyCoord(1 * u.deg, 4 * u.deg, frame=\"fk5\", equinox=\"J2010\")\n    with pytest.raises(ValueError):\n        SkyCoord([scfk5_j2000, scfk5_j2010])\n\n    # but they should inherit if they're all consistent\n    scfk5_2_j2010 = SkyCoord(2 * u.deg, 5 * u.deg, frame=\"fk5\", equinox=\"J2010\")\n    scfk5_3_j2010 = SkyCoord(3 * u.deg, 6 * u.deg, frame=\"fk5\", equinox=\"J2010\")\n\n    scnew4 = SkyCoord([scfk5_j2010, scfk5_2_j2010, scfk5_3_j2010])\n    assert np.all(scnew4.ra == sc.ra)\n    assert np.all(scnew4.dec == sc.dec)\n    assert scnew4.equinox == Time(\"J2010\")\n\n\ndef test_nd_skycoord_to_string():\n    c = SkyCoord(np.ones((2, 2)), 1, unit=(\"deg\", \"deg\"))\n    ts = c.to_string()\n    assert np.all(ts.shape == c.shape)\n    assert np.all(ts == \"1 1\")\n\n\ndef test_equiv_skycoord():\n    sci1 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"icrs\")\n    sci2 = SkyCoord(1 * u.deg, 3 * u.deg, frame=\"icrs\")\n    assert sci1.is_equivalent_frame(sci1)\n    assert sci1.is_equivalent_frame(sci2)\n\n    assert sci1.is_equivalent_frame(ICRS())\n    assert not sci1.is_equivalent_frame(FK5())\n    with pytest.raises(TypeError):\n        sci1.is_equivalent_frame(10)\n\n    scf1 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"fk5\")\n    scf2 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"fk5\", equinox=\"J2005\")\n    # obstime is *not* an FK5 attribute, but we still want scf1 and scf3 to come\n    # to come out different because they're part of SkyCoord\n    scf3 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"fk5\", obstime=\"J2005\")\n\n    assert scf1.is_equivalent_frame(scf1)\n    assert not scf1.is_equivalent_frame(sci1)\n    assert scf1.is_equivalent_frame(FK5())\n\n    assert not scf1.is_equivalent_frame(scf2)\n    assert scf2.is_equivalent_frame(FK5(equinox=\"J2005\"))\n    assert not scf3.is_equivalent_frame(scf1)\n    assert not scf3.is_equivalent_frame(FK5(equinox=\"J2005\"))\n\n\ndef test_equiv_skycoord_with_extra_attrs():\n    \"\"\"Regression test for #10658.\"\"\"\n    # GCRS has a CartesianRepresentationAttribute called obsgeoloc\n    gcrs = GCRS(\n        1 * u.deg, 2 * u.deg, obsgeoloc=CartesianRepresentation([1, 2, 3], unit=u.m)\n    )\n    # Create a SkyCoord where obsgeoloc tags along as an extra attribute\n    sc1 = SkyCoord(gcrs).transform_to(ICRS)\n    # Now create a SkyCoord with an equivalent frame but without the extra attribute\n    sc2 = SkyCoord(sc1.frame)\n    # The SkyCoords are therefore not equivalent, but check both directions\n    assert not sc1.is_equivalent_frame(sc2)\n    # This way around raised a TypeError which is fixed by #10658\n    assert not sc2.is_equivalent_frame(sc1)\n\n\ndef test_constellations():\n    # the actual test for accuracy is in test_funcs - this is just meant to make\n    # sure we get sensible answers\n    sc = SkyCoord(135 * u.deg, 65 * u.deg)\n    assert sc.get_constellation() == \"Ursa Major\"\n    assert sc.get_constellation(short_name=True) == \"UMa\"\n\n    scs = SkyCoord([135] * 2 * u.deg, [65] * 2 * u.deg)\n    npt.assert_equal(scs.get_constellation(), [\"Ursa Major\"] * 2)\n    npt.assert_equal(scs.get_constellation(short_name=True), [\"UMa\"] * 2)\n\n\n@pytest.mark.remote_data\ndef test_constellations_with_nameresolve():\n    assert SkyCoord.from_name(\"And I\").get_constellation(short_name=True) == \"And\"\n\n    # you'd think \"And ...\" should be in Andromeda.  But you'd be wrong.\n    assert SkyCoord.from_name(\"And VI\").get_constellation() == \"Pegasus\"\n\n    # maybe it's because And VI isn't really a galaxy?\n    assert SkyCoord.from_name(\"And XXII\").get_constellation() == \"Pisces\"\n    assert SkyCoord.from_name(\"And XXX\").get_constellation() == \"Cassiopeia\"\n    # ok maybe not\n\n    # ok, but at least some of the others do make sense...\n    assert (\n        SkyCoord.from_name(\"Coma Cluster\").get_constellation(short_name=True) == \"Com\"\n    )\n    assert SkyCoord.from_name(\"Orion Nebula\").get_constellation() == \"Orion\"\n    assert SkyCoord.from_name(\"Triangulum Galaxy\").get_constellation() == \"Triangulum\"\n\n\ndef test_getitem_representation():\n    \"\"\"\n    Make sure current representation survives __getitem__ even if different\n    from data representation.\n    \"\"\"\n    sc = SkyCoord([1, 1] * u.deg, [2, 2] * u.deg)\n    sc.representation_type = \"cartesian\"\n    assert sc[0].representation_type is CartesianRepresentation\n\n\ndef test_spherical_offsets_to_api():\n    i00 = SkyCoord(0 * u.arcmin, 0 * u.arcmin, frame=\"icrs\")\n\n    fk5 = SkyCoord(0 * u.arcmin, 0 * u.arcmin, frame=\"fk5\")\n    with pytest.raises(ValueError):\n        # different frames should fail\n        i00.spherical_offsets_to(fk5)\n\n    i1deg = ICRS(1 * u.deg, 1 * u.deg)\n    dra, ddec = i00.spherical_offsets_to(i1deg)\n    assert_allclose(dra, 1 * u.deg)\n    assert_allclose(ddec, 1 * u.deg)\n\n    # make sure an abbreviated array-based version of the above also works\n    i00s = SkyCoord([0] * 4 * u.arcmin, [0] * 4 * u.arcmin, frame=\"icrs\")\n    i01s = SkyCoord([0] * 4 * u.arcmin, np.arange(4) * u.arcmin, frame=\"icrs\")\n    dra, ddec = i00s.spherical_offsets_to(i01s)\n    assert_allclose(dra, 0 * u.arcmin)\n    assert_allclose(ddec, np.arange(4) * u.arcmin)\n\n\n@pytest.mark.parametrize(\"frame\", [\"icrs\", \"galactic\"])\n@pytest.mark.parametrize(\n    \"comparison_data\",\n    [\n        (0 * u.arcmin, 1 * u.arcmin),\n        (1 * u.arcmin, 0 * u.arcmin),\n        (1 * u.arcmin, 1 * u.arcmin),\n    ],\n)\ndef test_spherical_offsets_roundtrip(frame, comparison_data):\n    i00 = SkyCoord(0 * u.arcmin, 0 * u.arcmin, frame=frame)\n    comparison = SkyCoord(*comparison_data, frame=frame)\n\n    dlon, dlat = i00.spherical_offsets_to(comparison)\n    assert_allclose(dlon, comparison.data.lon)\n    assert_allclose(dlat, comparison.data.lat)\n\n    i00_back = comparison.spherical_offsets_by(-dlon, -dlat)\n\n    # This reaches machine precision when only one component is changed, but for\n    # the third parametrized case (both lon and lat change), the transformation\n    # will have finite accuracy:\n    assert_allclose(i00_back.data.lon, i00.data.lon, atol=1e-10 * u.rad)\n    assert_allclose(i00_back.data.lat, i00.data.lat, atol=1e-10 * u.rad)\n\n    # Test roundtripping the other direction:\n    init_c = SkyCoord(40.0 * u.deg, 40.0 * u.deg, frame=frame)\n    new_c = init_c.spherical_offsets_by(3.534 * u.deg, 2.2134 * u.deg)\n    dlon, dlat = new_c.spherical_offsets_to(init_c)\n    back_c = new_c.spherical_offsets_by(dlon, dlat)\n    assert init_c.separation(back_c) < 1e-10 * u.deg\n\n\ndef test_frame_attr_changes():\n    \"\"\"\n    This tests the case where a frame is added with a new frame attribute after\n    a SkyCoord has been created.  This is necessary because SkyCoords get the\n    attributes set at creation time, but the set of attributes can change as\n    frames are added or removed from the transform graph.  This makes sure that\n    everything continues to work consistently.\n    \"\"\"\n    sc_before = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"icrs\")\n\n    assert \"fakeattr\" not in dir(sc_before)\n\n    class FakeFrame(BaseCoordinateFrame):\n        fakeattr = Attribute()\n\n    # doesn't matter what this does as long as it just puts the frame in the\n    # transform graph\n    transset = (ICRS, FakeFrame, lambda c, f: c)\n    frame_transform_graph.add_transform(*transset)\n    try:\n        assert \"fakeattr\" in dir(sc_before)\n        assert sc_before.fakeattr is None\n\n        sc_after1 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"icrs\")\n        assert \"fakeattr\" in dir(sc_after1)\n        assert sc_after1.fakeattr is None\n\n        sc_after2 = SkyCoord(1 * u.deg, 2 * u.deg, frame=\"icrs\", fakeattr=1)\n        assert sc_after2.fakeattr == 1\n    finally:\n        frame_transform_graph.remove_transform(*transset)\n\n    assert \"fakeattr\" not in dir(sc_before)\n    assert \"fakeattr\" not in dir(sc_after1)\n    assert \"fakeattr\" not in dir(sc_after2)\n\n\ndef test_cache_clear_sc():\n    from astropy.coordinates import SkyCoord\n\n    i = SkyCoord(1 * u.deg, 2 * u.deg)\n\n    # Add an in frame units version of the rep to the cache.\n    repr(i)\n\n    assert len(i.cache[\"representation\"]) == 2\n\n    i.cache.clear()\n\n    assert len(i.cache[\"representation\"]) == 0\n\n\ndef test_set_attribute_exceptions():\n    \"\"\"Ensure no attrbute for any frame can be set directly.\n\n    Though it is fine if the current frame does not have it.\"\"\"\n    sc = SkyCoord(1.0 * u.deg, 2.0 * u.deg, frame=\"fk5\")\n    assert hasattr(sc.frame, \"equinox\")\n    with pytest.raises(AttributeError):\n        sc.equinox = \"B1950\"\n\n    assert sc.relative_humidity is None\n    sc.relative_humidity = 0.5\n    assert sc.relative_humidity == 0.5\n    assert not hasattr(sc.frame, \"relative_humidity\")\n\n\ndef test_extra_attributes():\n    \"\"\"Ensure any extra attributes are dealt with correctly.\n\n    Regression test against #5743.\n    \"\"\"\n    obstime_string = [\"2017-01-01T00:00\", \"2017-01-01T00:10\"]\n    obstime = Time(obstime_string)\n    sc = SkyCoord([5, 10], [20, 30], unit=u.deg, obstime=obstime_string)\n    assert not hasattr(sc.frame, \"obstime\")\n    assert type(sc.obstime) is Time\n    assert sc.obstime.shape == (2,)\n    assert np.all(sc.obstime == obstime)\n    # ensure equivalency still works for more than one obstime.\n    assert sc.is_equivalent_frame(sc)\n    sc_1 = sc[1]\n    assert sc_1.obstime == obstime[1]\n    # Transforming to FK4 should use sc.obstime.\n    sc_fk4 = sc.transform_to(\"fk4\")\n    assert np.all(sc_fk4.frame.obstime == obstime)\n    # And transforming back should not loose it.\n    sc2 = sc_fk4.transform_to(\"icrs\")\n    assert not hasattr(sc2.frame, \"obstime\")\n    assert np.all(sc2.obstime == obstime)\n    # Ensure obstime get taken from the SkyCoord if passed in directly.\n    # (regression test for #5749).\n    sc3 = SkyCoord([0.0, 1.0], [2.0, 3.0], unit=\"deg\", frame=sc)\n    assert np.all(sc3.obstime == obstime)\n    # Finally, check that we can delete such attributes.\n    del sc3.obstime\n    assert sc3.obstime is None\n\n\ndef test_apply_space_motion():\n    # use this 12 year period because it's a multiple of 4 to avoid the quirks\n    # of leap years while having 2 leap seconds in it\n    t1 = Time(\"2000-01-01T00:00\")\n    t2 = Time(\"2012-01-01T00:00\")\n\n    # Check a very simple case first:\n    frame = ICRS(\n        ra=10.0 * u.deg,\n        dec=0 * u.deg,\n        distance=10.0 * u.pc,\n        pm_ra_cosdec=0.1 * u.deg / u.yr,\n        pm_dec=0 * u.mas / u.yr,\n        radial_velocity=0 * u.km / u.s,\n    )\n\n    # Cases that should work (just testing input for now):\n    c1 = SkyCoord(frame, obstime=t1, pressure=101 * u.kPa)\n    with pytest.warns(ErfaWarning, match='ERFA function \"pmsafe\" yielded .*'):\n        # warning raised due to high PM chosen above\n        applied1 = c1.apply_space_motion(new_obstime=t2)\n        applied2 = c1.apply_space_motion(dt=12 * u.year)\n\n    assert isinstance(applied1.frame, c1.frame.__class__)\n    assert isinstance(applied2.frame, c1.frame.__class__)\n    assert_allclose(applied1.ra, applied2.ra)\n    assert_allclose(applied1.pm_ra_cosdec, applied2.pm_ra_cosdec)\n    assert_allclose(applied1.dec, applied2.dec)\n    assert_allclose(applied1.distance, applied2.distance)\n\n    # ensure any frame attributes that were there before get passed through\n    assert applied1.pressure == c1.pressure\n\n    # there were 2 leap seconds between 2000 and 2010, so the difference in\n    # the two forms of time evolution should be ~2 sec\n    adt = np.abs(applied2.obstime - applied1.obstime)\n    assert 1.9 * u.second < adt.to(u.second) < 2.1 * u.second\n\n    c2 = SkyCoord(frame)\n    with pytest.warns(ErfaWarning, match='ERFA function \"pmsafe\" yielded .*'):\n        # warning raised due to high PM chosen above\n        applied3 = c2.apply_space_motion(dt=6 * u.year)\n    assert isinstance(applied3.frame, c1.frame.__class__)\n    assert applied3.obstime is None\n\n    # this should *not* be .6 deg due to space-motion on a sphere, but it\n    # should be fairly close\n    assert 0.5 * u.deg < applied3.ra - c1.ra < 0.7 * u.deg\n\n    # the two cases should only match somewhat due to it being space motion, but\n    # they should be at least this close\n    assert quantity_allclose(\n        applied1.ra - c1.ra, (applied3.ra - c1.ra) * 2, atol=1e-3 * u.deg\n    )\n    # but *not* this close\n    assert not quantity_allclose(\n        applied1.ra - c1.ra, (applied3.ra - c1.ra) * 2, atol=1e-4 * u.deg\n    )\n\n    with pytest.raises(ValueError):\n        c2.apply_space_motion(new_obstime=t2)\n\n\ndef test_custom_frame_skycoord():\n    # also regression check for the case from #7069\n\n    class BlahBleeBlopFrame(BaseCoordinateFrame):\n        default_representation = SphericalRepresentation\n        # without a differential, SkyCoord creation fails\n        # default_differential = SphericalDifferential\n\n        _frame_specific_representation_info = {\n            \"spherical\": [\n                RepresentationMapping(\"lon\", \"lon\", \"recommended\"),\n                RepresentationMapping(\"lat\", \"lat\", \"recommended\"),\n                RepresentationMapping(\"distance\", \"radius\", \"recommended\"),\n            ]\n        }\n\n    SkyCoord(lat=1 * u.deg, lon=2 * u.deg, frame=BlahBleeBlopFrame)\n\n\ndef test_user_friendly_pm_error():\n    \"\"\"\n    This checks that a more user-friendly error message is raised for the user\n    if they pass, e.g., pm_ra instead of pm_ra_cosdec\n    \"\"\"\n\n    with pytest.raises(ValueError) as e:\n        SkyCoord(\n            ra=150 * u.deg,\n            dec=-11 * u.deg,\n            pm_ra=100 * u.mas / u.yr,\n            pm_dec=10 * u.mas / u.yr,\n        )\n    assert \"pm_ra_cosdec\" in str(e.value)\n\n    with pytest.raises(ValueError) as e:\n        SkyCoord(\n            l=150 * u.deg,\n            b=-11 * u.deg,\n            pm_l=100 * u.mas / u.yr,\n            pm_b=10 * u.mas / u.yr,\n            frame=\"galactic\",\n        )\n    assert \"pm_l_cosb\" in str(e.value)\n\n    # The special error should not turn on here:\n    with pytest.raises(ValueError) as e:\n        SkyCoord(\n            x=1 * u.pc,\n            y=2 * u.pc,\n            z=3 * u.pc,\n            pm_ra=100 * u.mas / u.yr,\n            pm_dec=10 * u.mas / u.yr,\n            representation_type=\"cartesian\",\n        )\n    assert \"pm_ra_cosdec\" not in str(e.value)\n\n\ndef test_contained_by():\n    \"\"\"\n    Test Skycoord.contained(wcs,image)\n    \"\"\"\n\n    header = \"\"\"\nWCSAXES =                    2 / Number of coordinate axes\nCRPIX1  =               1045.0 / Pixel coordinate of reference point\nCRPIX2  =               1001.0 / Pixel coordinate of reference point\nPC1_1   =    -0.00556448550786 / Coordinate transformation matrix element\nPC1_2   =   -0.001042120133257 / Coordinate transformation matrix element\nPC2_1   =    0.001181477028705 / Coordinate transformation matrix element\nPC2_2   =   -0.005590809742987 / Coordinate transformation matrix element\nCDELT1  =                  1.0 / [deg] Coordinate increment at reference point\nCDELT2  =                  1.0 / [deg] Coordinate increment at reference point\nCUNIT1  = 'deg'                / Units of coordinate increment and value\nCUNIT2  = 'deg'                / Units of coordinate increment and value\nCTYPE1  = 'RA---TAN'           / TAN (gnomonic) projection + SIP distortions\nCTYPE2  = 'DEC--TAN'           / TAN (gnomonic) projection + SIP distortions\nCRVAL1  =      250.34971683647 / [deg] Coordinate value at reference point\nCRVAL2  =      2.2808772582495 / [deg] Coordinate value at reference point\nLONPOLE =                180.0 / [deg] Native longitude of celestial pole\nLATPOLE =      2.2808772582495 / [deg] Native latitude of celestial pole\nRADESYS = 'ICRS'               / Equatorial coordinate system\nMJD-OBS =      58612.339199259 / [d] MJD of observation matching DATE-OBS\nDATE-OBS= '2019-05-09T08:08:26.816Z' / ISO-8601 observation date matching MJD-OB\nNAXIS   =                    2 / NAXIS\nNAXIS1  =                 2136 / length of first array dimension\nNAXIS2  =                 2078 / length of second array dimension\n    \"\"\"\n\n    test_wcs = WCS(fits.Header.fromstring(header.strip(), \"\\n\"))\n    assert SkyCoord(254, 2, unit=\"deg\").contained_by(test_wcs)\n    assert not SkyCoord(240, 2, unit=\"deg\").contained_by(test_wcs)\n\n    img = np.zeros((2136, 2078))\n    assert SkyCoord(250, 2, unit=\"deg\").contained_by(test_wcs, img)\n    assert not SkyCoord(240, 2, unit=\"deg\").contained_by(test_wcs, img)\n\n    ra = np.array([254.2, 254.1])\n    dec = np.array([2, 12.1])\n    coords = SkyCoord(ra, dec, unit=\"deg\")\n    assert np.all(test_wcs.footprint_contains(coords) == np.array([True, False]))\n\n\ndef test_none_differential_type():\n    \"\"\"\n    This is a regression test for #8021\n    \"\"\"\n    from astropy.coordinates import BaseCoordinateFrame\n\n    class MockHeliographicStonyhurst(BaseCoordinateFrame):\n        default_representation = SphericalRepresentation\n\n        frame_specific_representation_info = {\n            SphericalRepresentation: [\n                RepresentationMapping(\n                    reprname=\"lon\", framename=\"lon\", defaultunit=u.deg\n                ),\n                RepresentationMapping(\n                    reprname=\"lat\", framename=\"lat\", defaultunit=u.deg\n                ),\n                RepresentationMapping(\n                    reprname=\"distance\", framename=\"radius\", defaultunit=None\n                ),\n            ]\n        }\n\n    fr = MockHeliographicStonyhurst(lon=1 * u.deg, lat=2 * u.deg, radius=10 * u.au)\n    SkyCoord(0 * u.deg, fr.lat, fr.radius, frame=fr)  # this was the failure\n\n\ndef test_multiple_aliases():\n    # Define a frame with multiple aliases\n    class MultipleAliasesFrame(BaseCoordinateFrame):\n        name = [\"alias_1\", \"alias_2\"]\n        default_representation = SphericalRepresentation\n\n    # Register a transform, which adds the aliases to the transform graph\n    tfun = lambda c, f: f.__class__(lon=c.lon, lat=c.lat)\n    ftrans = FunctionTransform(\n        tfun,\n        MultipleAliasesFrame,\n        MultipleAliasesFrame,\n        register_graph=frame_transform_graph,\n    )\n\n    coord = SkyCoord(lon=1 * u.deg, lat=2 * u.deg, frame=MultipleAliasesFrame)\n\n    # Test attribute-style access returns self (not a copy)\n    assert coord.alias_1 is coord\n    assert coord.alias_2 is coord\n\n    # Test for aliases in __dir__()\n    assert \"alias_1\" in coord.__dir__()\n    assert \"alias_2\" in coord.__dir__()\n\n    # Test transform_to() calls\n    assert isinstance(coord.transform_to(\"alias_1\").frame, MultipleAliasesFrame)\n    assert isinstance(coord.transform_to(\"alias_2\").frame, MultipleAliasesFrame)\n\n    ftrans.unregister(frame_transform_graph)\n\n\n@pytest.mark.parametrize(\n    \"kwargs, error_message\",\n    [\n        (\n            {\"ra\": 1, \"dec\": 1, \"distance\": 1 * u.pc, \"unit\": \"deg\"},\n            r\"Unit 'deg' \\(angle\\) could not be applied to 'distance'. \",\n        ),\n        (\n            {\n                \"rho\": 1 * u.m,\n                \"phi\": 1,\n                \"z\": 1 * u.m,\n                \"unit\": \"deg\",\n                \"representation_type\": \"cylindrical\",\n            },\n            r\"Unit 'deg' \\(angle\\) could not be applied to 'rho'. \",\n        ),\n    ],\n)\ndef test_passing_inconsistent_coordinates_and_units_raises_helpful_error(\n    kwargs, error_message\n):\n    # https://github.com/astropy/astropy/issues/10725\n    with pytest.raises(ValueError, match=error_message):\n        SkyCoord(**kwargs)\n\n\n@pytest.mark.skipif(not HAS_SCIPY, reason=\"Requires scipy.\")\ndef test_match_to_catalog_3d_and_sky():\n    # Test for issue #5857. See PR #11449\n    cfk5_default = SkyCoord(\n        [1, 2, 3, 4] * u.degree,\n        [0, 0, 0, 0] * u.degree,\n        distance=[1, 1, 1.5, 1] * u.kpc,\n        frame=\"fk5\",\n    )\n    cfk5_J1950 = cfk5_default.transform_to(FK5(equinox=\"J1950\"))\n\n    idx, angle, quantity = cfk5_J1950.match_to_catalog_3d(cfk5_default)\n    npt.assert_array_equal(idx, [0, 1, 2, 3])\n    assert_allclose(angle, 0 * u.deg, atol=1e-14 * u.deg, rtol=0)\n    assert_allclose(quantity, 0 * u.kpc, atol=1e-14 * u.kpc, rtol=0)\n\n    idx, angle, distance = cfk5_J1950.match_to_catalog_sky(cfk5_default)\n    npt.assert_array_equal(idx, [0, 1, 2, 3])\n    assert_allclose(angle, 0 * u.deg, atol=1e-14 * u.deg, rtol=0)\n    assert_allclose(distance, 0 * u.kpc, atol=1e-14 * u.kpc, rtol=0)"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-14182", "model_patch": "diff --git a/astropy/io/ascii/tests/test_rst.py b/astropy/io/ascii/tests/test_rst.py\nindex e786c06..1f419bc 100644\n--- a/astropy/io/ascii/tests/test_rst.py\n+++ b/astropy/io/ascii/tests/test_rst.py\n@@ -69,6 +69,111 @@ def test_read_normal_names_include():\n     assert_equal(dat[0][1], 3)\n \n \n+def test_rst_with_header_rows():\n+    \"\"\"Round-trip a table with header_rows specified\"\"\"\n+    lines = [\n+        \"======= ======== ====\",\n+        \"   wave response ints\",\n+        \"     nm       ct     \",\n+        \"float64  float32 int8\",\n+        \"======= ======== ====\",\n+        \"  350.0      1.0    1\",\n+        \"  950.0      2.0    2\",\n+        \"======= ======== ====\",\n+    ]\n+    tbl = QTable.read(lines, format=\"ascii.rst\", header_rows=[\"name\", \"unit\", \"dtype\"])\n+    assert tbl[\"wave\"].unit == u.nm\n+    assert tbl[\"response\"].unit == u.ct\n+    assert tbl[\"wave\"].dtype == np.float64\n+    assert tbl[\"response\"].dtype == np.float32\n+    assert tbl[\"ints\"].dtype == np.int8\n+\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\", \"dtype\"])\n+    assert out.getvalue().splitlines() == lines\n+\n+\n+def test_rst_header_rows_basic():\n+    \"\"\"Test basic RST output with header_rows parameter\"\"\"\n+    from astropy.table import Table\n+    \n+    # Create a simple table\n+    tbl = Table({'col1': [1, 2], 'col2': [3, 4]})\n+    \n+    # Test that header_rows parameter is accepted without error\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\"])\n+    \n+    # Verify output contains expected structure\n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) > 0\n+    assert \"====\" in output_lines[0]  # RST table border\n+    assert \"col1\" in output_lines[1] or \"col2\" in output_lines[1]  # Column names\n+\n+\n+def test_rst_header_rows_with_units():\n+    \"\"\"Test RST output with header_rows including units\"\"\"\n+    # Create a table with units\n+    tbl = QTable({'wave': [350, 950]*u.nm, 'response': [0.7, 1.2]*u.count})\n+    \n+    # Test writing with header_rows\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\"])\n+    \n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) > 0\n+    \n+    # Should contain table structure\n+    assert \"====\" in output_lines[0]\n+    \n+    # Should contain column names and units in separate rows\n+    found_wave = False\n+    found_nm = False\n+    for line in output_lines:\n+        if \"wave\" in line:\n+            found_wave = True\n+        if \"nm\" in line:\n+            found_nm = True\n+    \n+    assert found_wave, \"Column name 'wave' not found in output\"\n+    assert found_nm, \"Unit 'nm' not found in output\"\n+\n+\n+def test_rst_header_rows_empty_list():\n+    \"\"\"Test RST output with empty header_rows list\"\"\"\n+    from astropy.table import Table\n+    \n+    tbl = Table({'a': [1, 2], 'b': [3, 4]})\n+    \n+    # Should work with empty header_rows\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[])\n+    \n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) > 0\n+    assert \"====\" in output_lines[0]\n+\n+\n+def test_rst_header_rows_multiple():\n+    \"\"\"Test RST output with multiple header rows\"\"\"\n+    # Create table with metadata that can generate multiple header rows\n+    tbl = QTable({\n+        'wavelength': [400, 500, 600]*u.nm, \n+        'flux': [1.0, 2.0, 3.0]*u.Jy\n+    })\n+    \n+    # Test with multiple header row types\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\"])\n+    \n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) >= 6  # At least borders + 2 header rows + data rows\n+    \n+    # Verify structure\n+    assert \"====\" in output_lines[0]\n+    assert \"====\" in output_lines[-1]\n+\n+\n def test_read_normal_exclude():\n     \"\"\"Nice, typical SimpleRST table with col name excluded\"\"\"\n     table = \"\"\"\n", "raw_model_patch": "diff --git a/astropy/io/ascii/tests/test_rst.py b/astropy/io/ascii/tests/test_rst.py\nindex e786c06..1f419bc 100644\n--- a/astropy/io/ascii/tests/test_rst.py\n+++ b/astropy/io/ascii/tests/test_rst.py\n@@ -69,6 +69,111 @@ def test_read_normal_names_include():\n     assert_equal(dat[0][1], 3)\n \n \n+def test_rst_with_header_rows():\n+    \"\"\"Round-trip a table with header_rows specified\"\"\"\n+    lines = [\n+        \"======= ======== ====\",\n+        \"   wave response ints\",\n+        \"     nm       ct     \",\n+        \"float64  float32 int8\",\n+        \"======= ======== ====\",\n+        \"  350.0      1.0    1\",\n+        \"  950.0      2.0    2\",\n+        \"======= ======== ====\",\n+    ]\n+    tbl = QTable.read(lines, format=\"ascii.rst\", header_rows=[\"name\", \"unit\", \"dtype\"])\n+    assert tbl[\"wave\"].unit == u.nm\n+    assert tbl[\"response\"].unit == u.ct\n+    assert tbl[\"wave\"].dtype == np.float64\n+    assert tbl[\"response\"].dtype == np.float32\n+    assert tbl[\"ints\"].dtype == np.int8\n+\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\", \"dtype\"])\n+    assert out.getvalue().splitlines() == lines\n+\n+\n+def test_rst_header_rows_basic():\n+    \"\"\"Test basic RST output with header_rows parameter\"\"\"\n+    from astropy.table import Table\n+    \n+    # Create a simple table\n+    tbl = Table({'col1': [1, 2], 'col2': [3, 4]})\n+    \n+    # Test that header_rows parameter is accepted without error\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\"])\n+    \n+    # Verify output contains expected structure\n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) > 0\n+    assert \"====\" in output_lines[0]  # RST table border\n+    assert \"col1\" in output_lines[1] or \"col2\" in output_lines[1]  # Column names\n+\n+\n+def test_rst_header_rows_with_units():\n+    \"\"\"Test RST output with header_rows including units\"\"\"\n+    # Create a table with units\n+    tbl = QTable({'wave': [350, 950]*u.nm, 'response': [0.7, 1.2]*u.count})\n+    \n+    # Test writing with header_rows\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\"])\n+    \n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) > 0\n+    \n+    # Should contain table structure\n+    assert \"====\" in output_lines[0]\n+    \n+    # Should contain column names and units in separate rows\n+    found_wave = False\n+    found_nm = False\n+    for line in output_lines:\n+        if \"wave\" in line:\n+            found_wave = True\n+        if \"nm\" in line:\n+            found_nm = True\n+    \n+    assert found_wave, \"Column name 'wave' not found in output\"\n+    assert found_nm, \"Unit 'nm' not found in output\"\n+\n+\n+def test_rst_header_rows_empty_list():\n+    \"\"\"Test RST output with empty header_rows list\"\"\"\n+    from astropy.table import Table\n+    \n+    tbl = Table({'a': [1, 2], 'b': [3, 4]})\n+    \n+    # Should work with empty header_rows\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[])\n+    \n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) > 0\n+    assert \"====\" in output_lines[0]\n+\n+\n+def test_rst_header_rows_multiple():\n+    \"\"\"Test RST output with multiple header rows\"\"\"\n+    # Create table with metadata that can generate multiple header rows\n+    tbl = QTable({\n+        'wavelength': [400, 500, 600]*u.nm, \n+        'flux': [1.0, 2.0, 3.0]*u.Jy\n+    })\n+    \n+    # Test with multiple header row types\n+    out = StringIO()\n+    tbl.write(out, format=\"ascii.rst\", header_rows=[\"name\", \"unit\"])\n+    \n+    output_lines = out.getvalue().splitlines()\n+    assert len(output_lines) >= 6  # At least borders + 2 header rows + data rows\n+    \n+    # Verify structure\n+    assert \"====\" in output_lines[0]\n+    assert \"====\" in output_lines[-1]\n+\n+\n def test_read_normal_exclude():\n     \"\"\"Nice, typical SimpleRST table with col name excluded\"\"\"\n     table = \"\"\"\n", "original_file_content": "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n\nfrom io import StringIO\n\nfrom astropy.io import ascii\n\nfrom .common import assert_almost_equal, assert_equal\n\n\ndef assert_equal_splitlines(arg1, arg2):\n    assert_equal(arg1.splitlines(), arg2.splitlines())\n\n\ndef test_read_normal():\n    \"\"\"Normal SimpleRST Table\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n======= =========\n   Col1      Col2\n======= =========\n   1.2    \"hello\"\n   2.4  's worlds\n======= =========\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col1\", \"Col2\"])\n    assert_almost_equal(dat[1][0], 2.4)\n    assert_equal(dat[0][1], '\"hello\"')\n    assert_equal(dat[1][1], \"'s worlds\")\n\n\ndef test_read_normal_names():\n    \"\"\"Normal SimpleRST Table with provided column names\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n======= =========\n   Col1      Col2\n======= =========\n   1.2    \"hello\"\n   2.4  's worlds\n======= =========\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST, names=(\"name1\", \"name2\"))\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"name1\", \"name2\"])\n    assert_almost_equal(dat[1][0], 2.4)\n\n\ndef test_read_normal_names_include():\n    \"\"\"Normal SimpleRST Table with provided column names\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n=======  ========== ======\n   Col1     Col2      Col3\n=======  ========== ======\n   1.2     \"hello\"       3\n   2.4    's worlds      7\n=======  ========== ======\n\"\"\"\n    reader = ascii.get_reader(\n        Reader=ascii.RST,\n        names=(\"name1\", \"name2\", \"name3\"),\n        include_names=(\"name1\", \"name3\"),\n    )\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"name1\", \"name3\"])\n    assert_almost_equal(dat[1][0], 2.4)\n    assert_equal(dat[0][1], 3)\n\n\ndef test_read_normal_exclude():\n    \"\"\"Nice, typical SimpleRST table with col name excluded\"\"\"\n    table = \"\"\"\n======= ==========\n  Col1     Col2\n======= ==========\n  1.2     \"hello\"\n  2.4    's worlds\n======= ==========\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST, exclude_names=(\"Col1\",))\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col2\"])\n    assert_equal(dat[1][0], \"'s worlds\")\n\n\ndef test_read_unbounded_right_column():\n    \"\"\"The right hand column should be allowed to overflow\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n===== ===== ====\n Col1  Col2 Col3\n===== ===== ====\n 1.2    2    Hello\n 2.4     4   Worlds\n===== ===== ====\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat[0][2], \"Hello\")\n    assert_equal(dat[1][2], \"Worlds\")\n\n\ndef test_read_unbounded_right_column_header():\n    \"\"\"The right hand column should be allowed to overflow\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n===== ===== ====\n Col1  Col2 Col3Long\n===== ===== ====\n 1.2    2    Hello\n 2.4     4   Worlds\n===== ===== ====\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames[-1], \"Col3Long\")\n\n\ndef test_read_right_indented_table():\n    \"\"\"We should be able to read right indented tables correctly\"\"\"\n    table = \"\"\"\n# comment (with blank line above)\n   ==== ==== ====\n   Col1 Col2 Col3\n   ==== ==== ====\n    3    3.4  foo\n    1    4.5  bar\n   ==== ==== ====\n\"\"\"\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col1\", \"Col2\", \"Col3\"])\n    assert_equal(dat[0][2], \"foo\")\n    assert_equal(dat[1][0], 1)\n\n\ndef test_trailing_spaces_in_row_definition():\n    \"\"\"Trailing spaces in the row definition column shouldn't matter\"\"\"\n    table = (\n        \"\\n\"\n        \"# comment (with blank line above)\\n\"\n        \"   ==== ==== ====    \\n\"\n        \"   Col1 Col2 Col3\\n\"\n        \"   ==== ==== ====  \\n\"\n        \"    3    3.4  foo\\n\"\n        \"    1    4.5  bar\\n\"\n        \"   ==== ==== ====  \\n\"\n    )\n    # make sure no one accidentally deletes the trailing whitespaces in the\n    # table.\n    assert len(table) == 151\n\n    reader = ascii.get_reader(Reader=ascii.RST)\n    dat = reader.read(table)\n    assert_equal(dat.colnames, [\"Col1\", \"Col2\", \"Col3\"])\n    assert_equal(dat[0][2], \"foo\")\n    assert_equal(dat[1][0], 1)\n\n\ntable = \"\"\"\\\n====== =========== ============ ===========\n  Col1    Col2        Col3        Col4\n====== =========== ============ ===========\n  1.2    \"hello\"      1           a\n  2.4   's worlds          2           2\n====== =========== ============ ===========\n\"\"\"\ndat = ascii.read(table, Reader=ascii.RST)\n\n\ndef test_write_normal():\n    \"\"\"Write a table as a normal SimpleRST Table\"\"\"\n    out = StringIO()\n    ascii.write(dat, out, Writer=ascii.RST)\n    assert_equal_splitlines(\n        out.getvalue(),\n        \"\"\"\\\n==== ========= ==== ====\nCol1      Col2 Col3 Col4\n==== ========= ==== ====\n 1.2   \"hello\"    1    a\n 2.4 's worlds    2    2\n==== ========= ==== ====\n\"\"\",\n    )"}
{"model_name_or_path": "agentless", "instance_id": "astropy__astropy-14309", "model_patch": "diff --git a/astropy/io/fits/tests/test_connect.py b/astropy/io/fits/tests/test_connect.py\nindex 00deafe..6a2e7c9 100644\n--- a/astropy/io/fits/tests/test_connect.py\n+++ b/astropy/io/fits/tests/test_connect.py\n@@ -74,6 +74,52 @@ class TestSingleTable:\n         t2 = Table.read(filename)\n         assert equal_data(t1, t2)\n \n+    def test_is_fits_gh_14305(self):\n+        \"\"\"Regression test for https://github.com/astropy/astropy/issues/14305\"\"\"\n+        assert not connect.is_fits(\"\", \"foo.bar\", None)\n+\n+    def test_is_fits_empty_args(self):\n+        \"\"\"Test is_fits with empty args - should not raise IndexError\"\"\"\n+        # Test with non-FITS extension and empty args\n+        assert not connect.is_fits(\"write\", \"test.ecsv\", None)\n+        assert not connect.is_fits(\"read\", \"test.csv\", None)\n+        assert not connect.is_fits(\"write\", \"test.txt\", None)\n+        \n+        # Test with FITS extension and empty args - should return True\n+        assert connect.is_fits(\"write\", \"test.fits\", None)\n+        assert connect.is_fits(\"read\", \"test.fit\", None)\n+        assert connect.is_fits(\"write\", \"test.fts\", None)\n+        assert connect.is_fits(\"read\", \"test.fits.gz\", None)\n+\n+    def test_is_fits_with_hdu_objects(self):\n+        \"\"\"Test is_fits with HDU objects in args\"\"\"\n+        # Create some HDU objects\n+        hdu_list = HDUList([PrimaryHDU()])\n+        table_hdu = BinTableHDU()\n+        \n+        # Test with HDU objects - should return True regardless of filename\n+        assert connect.is_fits(\"write\", \"test.ecsv\", None, hdu_list)\n+        assert connect.is_fits(\"write\", \"test.txt\", None, table_hdu)\n+        assert connect.is_fits(\"read\", \"foo.bar\", None, hdu_list)\n+\n+    def test_identify_format_regression_gh_14305(self):\n+        \"\"\"Test identify_format doesn't crash with empty args - regression test for issue #14305\"\"\"\n+        # This should not raise IndexError: tuple index out of range\n+        formats = identify_format(\"write\", Table, \"bububu.ecsv\", None, [], {})\n+        assert isinstance(formats, list)\n+        # Should not include 'fits' format for .ecsv file\n+        assert 'fits' not in formats\n+        \n+        # Test with other non-FITS extensions\n+        formats = identify_format(\"write\", Table, \"test.csv\", None, [], {})\n+        assert isinstance(formats, list)\n+        assert 'fits' not in formats\n+        \n+        # Test with FITS extension - should include 'fits' format\n+        formats = identify_format(\"write\", Table, \"test.fits\", None, [], {})\n+        assert isinstance(formats, list)\n+        assert 'fits' in formats\n+\n     def test_simple_meta(self, tmp_path):\n         filename = tmp_path / \"test_simple.fits\"\n         t1 = Table(self.data)\n", "raw_model_patch": "diff --git a/astropy/io/fits/tests/test_connect.py b/astropy/io/fits/tests/test_connect.py\nindex 00deafe..6a2e7c9 100644\n--- a/astropy/io/fits/tests/test_connect.py\n+++ b/astropy/io/fits/tests/test_connect.py\n@@ -74,6 +74,52 @@ class TestSingleTable:\n         t2 = Table.read(filename)\n         assert equal_data(t1, t2)\n \n+    def test_is_fits_gh_14305(self):\n+        \"\"\"Regression test for https://github.com/astropy/astropy/issues/14305\"\"\"\n+        assert not connect.is_fits(\"\", \"foo.bar\", None)\n+\n+    def test_is_fits_empty_args(self):\n+        \"\"\"Test is_fits with empty args - should not raise IndexError\"\"\"\n+        # Test with non-FITS extension and empty args\n+        assert not connect.is_fits(\"write\", \"test.ecsv\", None)\n+        assert not connect.is_fits(\"read\", \"test.csv\", None)\n+        assert not connect.is_fits(\"write\", \"test.txt\", None)\n+        \n+        # Test with FITS extension and empty args - should return True\n+        assert connect.is_fits(\"write\", \"test.fits\", None)\n+        assert connect.is_fits(\"read\", \"test.fit\", None)\n+        assert connect.is_fits(\"write\", \"test.fts\", None)\n+        assert connect.is_fits(\"read\", \"test.fits.gz\", None)\n+\n+    def test_is_fits_with_hdu_objects(self):\n+        \"\"\"Test is_fits with HDU objects in args\"\"\"\n+        # Create some HDU objects\n+        hdu_list = HDUList([PrimaryHDU()])\n+        table_hdu = BinTableHDU()\n+        \n+        # Test with HDU objects - should return True regardless of filename\n+        assert connect.is_fits(\"write\", \"test.ecsv\", None, hdu_list)\n+        assert connect.is_fits(\"write\", \"test.txt\", None, table_hdu)\n+        assert connect.is_fits(\"read\", \"foo.bar\", None, hdu_list)\n+\n+    def test_identify_format_regression_gh_14305(self):\n+        \"\"\"Test identify_format doesn't crash with empty args - regression test for issue #14305\"\"\"\n+        # This should not raise IndexError: tuple index out of range\n+        formats = identify_format(\"write\", Table, \"bububu.ecsv\", None, [], {})\n+        assert isinstance(formats, list)\n+        # Should not include 'fits' format for .ecsv file\n+        assert 'fits' not in formats\n+        \n+        # Test with other non-FITS extensions\n+        formats = identify_format(\"write\", Table, \"test.csv\", None, [], {})\n+        assert isinstance(formats, list)\n+        assert 'fits' not in formats\n+        \n+        # Test with FITS extension - should include 'fits' format\n+        formats = identify_format(\"write\", Table, \"test.fits\", None, [], {})\n+        assert isinstance(formats, list)\n+        assert 'fits' in formats\n+\n     def test_simple_meta(self, tmp_path):\n         filename = tmp_path / \"test_simple.fits\"\n         t1 = Table(self.data)\n", "original_file_content": "import gc\nimport warnings\n\nimport numpy as np\nimport pytest\nfrom numpy.testing import assert_allclose, assert_array_equal\n\nfrom astropy import units as u\nfrom astropy.io import fits\nfrom astropy.io.fits import BinTableHDU, HDUList, ImageHDU, PrimaryHDU, table_to_hdu\nfrom astropy.io.fits.column import (\n    _fortran_to_python_format,\n    _parse_tdisp_format,\n    python_to_tdisp,\n)\nfrom astropy.io.tests.mixin_columns import compare_attrs, mixin_cols, serialized_names\nfrom astropy.table import Column, QTable, Table\nfrom astropy.table.table_helpers import simple_table\nfrom astropy.time import Time\nfrom astropy.units import allclose as quantity_allclose\nfrom astropy.units.format.fits import UnitScaleError\nfrom astropy.units.quantity import QuantityInfo\nfrom astropy.utils.compat import NUMPY_LT_1_22\nfrom astropy.utils.data import get_pkg_data_filename\nfrom astropy.utils.exceptions import AstropyDeprecationWarning, AstropyUserWarning\nfrom astropy.utils.misc import _NOT_OVERWRITING_MSG_MATCH\n\n# FITS does not preserve precision, in_subfmt, and out_subfmt.\ntime_attrs = [\"value\", \"shape\", \"format\", \"scale\", \"location\"]\ncompare_attrs = {\n    name: (time_attrs if isinstance(col, Time) else compare_attrs[name])\n    for name, col in mixin_cols.items()\n}\n# FITS does not support multi-element location, array with object dtype,\n# or logarithmic quantities.\nunsupported_cols = {\n    name: col\n    for name, col in mixin_cols.items()\n    if (\n        isinstance(col, Time)\n        and col.location.shape != ()\n        or isinstance(col, np.ndarray)\n        and col.dtype.kind == \"O\"\n        or isinstance(col, u.LogQuantity)\n    )\n}\nmixin_cols = {\n    name: col for name, col in mixin_cols.items() if name not in unsupported_cols\n}\n\n\ndef equal_data(a, b):\n    return all(np.all(a[name] == b[name]) for name in a.dtype.names)\n\n\nclass TestSingleTable:\n    def setup_class(self):\n        self.data = np.array(\n            list(zip([1, 2, 3, 4], [\"a\", \"b\", \"c\", \"d\"], [2.3, 4.5, 6.7, 8.9])),\n            dtype=[(\"a\", int), (\"b\", \"U1\"), (\"c\", float)],\n        )\n\n    def test_simple(self, tmp_path):\n        filename = tmp_path / \"test_simple.fts\"\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n\n    def test_simple_pathlib(self, tmp_path):\n        filename = tmp_path / \"test_simple.fit\"\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n\n    def test_simple_meta(self, tmp_path):\n        filename = tmp_path / \"test_simple.fits\"\n        t1 = Table(self.data)\n        t1.meta[\"A\"] = 1\n        t1.meta[\"B\"] = 2.3\n        t1.meta[\"C\"] = \"spam\"\n        t1.meta[\"comments\"] = [\"this\", \"is\", \"a\", \"long\", \"comment\"]\n        t1.meta[\"HISTORY\"] = [\"first\", \"second\", \"third\"]\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n        for key in t1.meta:\n            if isinstance(t1.meta, list):\n                for i in range(len(t1.meta[key])):\n                    assert t1.meta[key][i] == t2.meta[key][i]\n            else:\n                assert t1.meta[key] == t2.meta[key]\n\n    def test_simple_meta_conflicting(self, tmp_path):\n        filename = tmp_path / \"test_simple.fits\"\n        t1 = Table(self.data)\n        t1.meta[\"ttype1\"] = \"spam\"\n        with pytest.warns(\n            AstropyUserWarning,\n            match=(\n                \"Meta-data keyword ttype1 \"\n                \"will be ignored since it conflicts with a FITS \"\n                \"reserved keyword\"\n            ),\n        ) as w:\n            t1.write(filename, overwrite=True)\n        assert len(w) == 1\n\n    def test_simple_noextension(self, tmp_path):\n        \"\"\"\n        Test that file type is recognized without extension\n        \"\"\"\n        filename = tmp_path / \"test_simple\"\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True, format=\"fits\")\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n\n    @pytest.mark.parametrize(\"table_type\", (Table, QTable))\n    def test_with_units(self, table_type, tmp_path):\n        filename = tmp_path / \"test_with_units.fits\"\n        t1 = table_type(self.data)\n        t1[\"a\"].unit = u.m\n        t1[\"c\"].unit = u.km / u.s\n        t1.write(filename, overwrite=True)\n        t2 = table_type.read(filename)\n        assert equal_data(t1, t2)\n        assert t2[\"a\"].unit == u.m\n        assert t2[\"c\"].unit == u.km / u.s\n\n    def test_with_custom_units_qtable(self, tmp_path):\n        # Test only for QTable - for Table's Column, new units are dropped\n        # (as is checked in test_write_drop_nonstandard_units).\n        filename = tmp_path / \"test_with_units.fits\"\n        unit = u.def_unit(\"bandpass_sol_lum\")\n        t = QTable()\n        t[\"l\"] = np.ones(5) * unit\n        with pytest.warns(AstropyUserWarning) as w:\n            t.write(filename, overwrite=True)\n        assert len(w) == 1\n        assert \"bandpass_sol_lum\" in str(w[0].message)\n        # Just reading back, the data is fine but the unit is not recognized.\n        with pytest.warns(\n            u.UnitsWarning, match=\"'bandpass_sol_lum' did not parse\"\n        ) as w:\n            t2 = QTable.read(filename)\n        assert len(w) == 1\n        assert isinstance(t2[\"l\"].unit, u.UnrecognizedUnit)\n        assert str(t2[\"l\"].unit) == \"bandpass_sol_lum\"\n        assert np.all(t2[\"l\"].value == t[\"l\"].value)\n\n        # But if we enable the unit, it should be recognized.\n        with u.add_enabled_units(unit):\n            t3 = QTable.read(filename)\n            assert t3[\"l\"].unit is unit\n            assert equal_data(t3, t)\n\n            # Regression check for #8897; write used to fail when a custom\n            # unit was enabled.\n            with pytest.warns(AstropyUserWarning):\n                t3.write(filename, overwrite=True)\n\n        # It should also be possible to read the file in using a unit alias,\n        # even to a unit that may not be the same.\n        with u.set_enabled_aliases({\"bandpass_sol_lum\": u.Lsun}):\n            t3 = QTable.read(filename)\n            assert t3[\"l\"].unit is u.Lsun\n\n    @pytest.mark.parametrize(\"table_type\", (Table, QTable))\n    def test_read_with_unit_aliases(self, table_type):\n        hdu = BinTableHDU(self.data)\n        hdu.columns[0].unit = \"Angstroms\"\n        hdu.columns[2].unit = \"ergs/(cm.s.Angstroms)\"\n        with u.set_enabled_aliases(dict(Angstroms=u.AA, ergs=u.erg)):\n            t = table_type.read(hdu)\n        assert t[\"a\"].unit == u.AA\n        assert t[\"c\"].unit == u.erg / (u.cm * u.s * u.AA)\n\n    @pytest.mark.parametrize(\"table_type\", (Table, QTable))\n    def test_with_format(self, table_type, tmp_path):\n        filename = tmp_path / \"test_with_format.fits\"\n        t1 = table_type(self.data)\n        t1[\"a\"].format = \"{:5d}\"\n        t1[\"b\"].format = \"{:>20}\"\n        t1[\"c\"].format = \"{:6.2f}\"\n        t1.write(filename, overwrite=True)\n        t2 = table_type.read(filename)\n        assert equal_data(t1, t2)\n        assert t2[\"a\"].format == \"{:5d}\"\n        assert t2[\"b\"].format == \"{:>20}\"\n        assert t2[\"c\"].format == \"{:6.2f}\"\n\n    def test_masked(self, tmp_path):\n        filename = tmp_path / \"test_masked.fits\"\n        t1 = Table(self.data, masked=True)\n        t1.mask[\"a\"] = [1, 0, 1, 0]\n        t1.mask[\"b\"] = [1, 0, 0, 1]\n        t1.mask[\"c\"] = [0, 1, 1, 0]\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert equal_data(t1, t2)\n        assert np.all(t1[\"a\"].mask == t2[\"a\"].mask)\n        assert np.all(t1[\"b\"].mask == t2[\"b\"].mask)\n        assert np.all(t1[\"c\"].mask == t2[\"c\"].mask)\n\n    @pytest.mark.parametrize(\"masked\", [True, False])\n    def test_masked_nan(self, masked, tmp_path):\n        \"\"\"Check that masked values by default are replaced by NaN.\n\n        This should work for any shape and be independent of whether the\n        Table is formally masked or not.\n\n        \"\"\"\n        filename = tmp_path / \"test_masked_nan.fits\"\n        a = np.ma.MaskedArray([5.25, 8.5, 3.75, 6.25], mask=[1, 0, 1, 0])\n        b = np.ma.MaskedArray([2.5, 4.5, 6.75, 8.875], mask=[1, 0, 0, 1], dtype=\"f4\")\n        c = np.ma.stack([a, b], axis=-1)\n        t1 = Table([a, b, c], names=[\"a\", \"b\", \"c\"], masked=masked)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert_array_equal(t2[\"a\"].data, [np.nan, 8.5, np.nan, 6.25])\n        assert_array_equal(t2[\"b\"].data, [np.nan, 4.5, 6.75, np.nan])\n        assert_array_equal(\n            t2[\"c\"].data, np.stack([t2[\"a\"].data, t2[\"b\"].data], axis=-1)\n        )\n        assert np.all(t1[\"a\"].mask == t2[\"a\"].mask)\n        assert np.all(t1[\"b\"].mask == t2[\"b\"].mask)\n        assert np.all(t1[\"c\"].mask == t2[\"c\"].mask)\n\n    def test_masked_serialize_data_mask(self, tmp_path):\n        filename = tmp_path / \"test_masked_nan.fits\"\n        a = np.ma.MaskedArray([5.25, 8.5, 3.75, 6.25], mask=[1, 0, 1, 0])\n        b = np.ma.MaskedArray([2.5, 4.5, 6.75, 8.875], mask=[1, 0, 0, 1])\n        c = np.ma.stack([a, b], axis=-1)\n        t1 = Table([a, b, c], names=[\"a\", \"b\", \"c\"])\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename)\n        assert_array_equal(t2[\"a\"].data, [5.25, 8.5, 3.75, 6.25])\n        assert_array_equal(t2[\"b\"].data, [2.5, 4.5, 6.75, 8.875])\n        assert_array_equal(\n            t2[\"c\"].data, np.stack([t2[\"a\"].data, t2[\"b\"].data], axis=-1)\n        )\n        assert np.all(t1[\"a\"].mask == t2[\"a\"].mask)\n        assert np.all(t1[\"b\"].mask == t2[\"b\"].mask)\n        assert np.all(t1[\"c\"].mask == t2[\"c\"].mask)\n\n    def test_read_from_fileobj(self, tmp_path):\n        filename = tmp_path / \"test_read_from_fileobj.fits\"\n        hdu = BinTableHDU(self.data)\n        hdu.writeto(filename, overwrite=True)\n        with open(filename, \"rb\") as f:\n            t = Table.read(f)\n        assert equal_data(t, self.data)\n\n    def test_read_with_nonstandard_units(self):\n        hdu = BinTableHDU(self.data)\n        hdu.columns[0].unit = \"RADIANS\"\n        hdu.columns[1].unit = \"spam\"\n        hdu.columns[2].unit = \"millieggs\"\n        with pytest.warns(u.UnitsWarning, match=\"did not parse as fits unit\"):\n            t = Table.read(hdu)\n        assert equal_data(t, self.data)\n\n    @pytest.mark.parametrize(\"table_type\", (Table, QTable))\n    def test_write_drop_nonstandard_units(self, table_type, tmp_path):\n        # While we are generous on input (see above), we are strict on\n        # output, dropping units not recognized by the fits standard.\n        filename = tmp_path / \"test_nonstandard_units.fits\"\n        spam = u.def_unit(\"spam\")\n        t = table_type()\n        t[\"a\"] = [1.0, 2.0, 3.0] * spam\n        with pytest.warns(AstropyUserWarning, match=\"spam\") as w:\n            t.write(filename)\n        assert len(w) == 1\n        if table_type is Table:\n            assert \"cannot be recovered in reading. \" in str(w[0].message)\n        else:\n            assert \"lost to non-astropy fits readers\" in str(w[0].message)\n\n        with fits.open(filename) as ff:\n            hdu = ff[1]\n            assert \"TUNIT1\" not in hdu.header\n\n    def test_memmap(self, tmp_path):\n        filename = tmp_path / \"test_simple.fts\"\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename, memmap=False)\n        t3 = Table.read(filename, memmap=True)\n        assert equal_data(t2, t3)\n        # To avoid issues with --open-files, we need to remove references to\n        # data that uses memory mapping and force the garbage collection\n        del t1, t2, t3\n        gc.collect()\n\n    @pytest.mark.parametrize(\"memmap\", (False, True))\n    def test_character_as_bytes(self, tmp_path, memmap):\n        filename = tmp_path / \"test_simple.fts\"\n        t1 = Table(self.data)\n        t1.write(filename, overwrite=True)\n        t2 = Table.read(filename, character_as_bytes=False, memmap=memmap)\n        t3 = Table.read(filename, character_as_bytes=True, memmap=memmap)\n        assert t2[\"b\"].dtype.kind == \"U\"\n        assert t3[\"b\"].dtype.kind == \"S\"\n        assert equal_data(t2, t3)\n        # To avoid issues with --open-files, we need to remove references to\n        # data that uses memory mapping and force the garbage collection\n        del t1, t2, t3\n        gc.collect()\n\n    def test_oned_single_element(self, tmp_path):\n        filename = tmp_path / \"test_oned_single_element.fits\"\n        table = Table({\"x\": [[1], [2]]})\n        table.write(filename, overwrite=True)\n\n        read = Table.read(filename)\n        assert read[\"x\"].shape == (2, 1)\n        assert len(read[\"x\"][0]) == 1\n\n    def test_write_append(self, tmp_path):\n        t = Table(self.data)\n        hdu = table_to_hdu(t)\n\n        def check_equal(filename, expected, start_from=1):\n            with fits.open(filename) as hdu_list:\n                assert len(hdu_list) == expected\n                for hdu_table in hdu_list[start_from:]:\n                    assert hdu_table.header == hdu.header\n                    assert np.all(hdu_table.data == hdu.data)\n\n        filename = tmp_path / \"test_write_append.fits\"\n        t.write(filename, append=True)\n        t.write(filename, append=True)\n        check_equal(filename, 3)\n\n        # Check the overwrite works correctly.\n        t.write(filename, append=True, overwrite=True)\n        t.write(filename, append=True)\n        check_equal(filename, 3)\n\n        # Normal write, check it's not appending.\n        t.write(filename, overwrite=True)\n        t.write(filename, overwrite=True)\n        check_equal(filename, 2)\n\n        # Now write followed by append, with different shaped tables.\n        t2 = Table(np.array([1, 2]))\n        t2.write(filename, overwrite=True)\n        t.write(filename, append=True)\n        check_equal(filename, 3, start_from=2)\n        assert equal_data(t2, Table.read(filename, hdu=1))\n\n    def test_write_overwrite(self, tmp_path):\n        t = Table(self.data)\n        filename = tmp_path / \"test_write_overwrite.fits\"\n        t.write(filename)\n        with pytest.raises(OSError, match=_NOT_OVERWRITING_MSG_MATCH):\n            t.write(filename)\n        t.write(filename, overwrite=True)\n\n    def test_mask_nans_on_read(self, tmp_path):\n        filename = tmp_path / \"test_inexact_format_parse_on_read.fits\"\n        c1 = fits.Column(name=\"a\", array=np.array([1, 2, np.nan]), format=\"E\")\n        table_hdu = fits.TableHDU.from_columns([c1])\n        table_hdu.writeto(filename)\n\n        tab = Table.read(filename)\n        assert any(tab.mask)\n        assert tab.mask[2]\n\n        tab = Table.read(filename, mask_invalid=False)\n        assert tab.mask is None\n\n        # using memmap also deactivate the masking\n        tab = Table.read(filename, memmap=True)\n        assert tab.mask is None\n\n    def test_mask_null_on_read(self, tmp_path):\n        filename = tmp_path / \"test_null_format_parse_on_read.fits\"\n        col = fits.Column(\n            name=\"a\",\n            array=np.array([1, 2, 99, 60000], dtype=\"u2\"),\n            format=\"I\",\n            null=99,\n            bzero=32768,\n        )\n        bin_table_hdu = fits.BinTableHDU.from_columns([col])\n        bin_table_hdu.writeto(filename, overwrite=True)\n\n        tab = Table.read(filename)\n        assert any(tab.mask)\n        assert tab.mask[2]\n\n    def test_mask_str_on_read(self, tmp_path):\n        filename = tmp_path / \"test_null_format_parse_on_read.fits\"\n        col = fits.Column(\n            name=\"a\", array=np.array([b\"foo\", b\"bar\", b\"\"], dtype=\"|S3\"), format=\"A3\"\n        )\n        bin_table_hdu = fits.BinTableHDU.from_columns([col])\n        bin_table_hdu.writeto(filename, overwrite=True)\n\n        tab = Table.read(filename)\n        assert any(tab.mask)\n        assert tab.mask[2]\n\n        tab = Table.read(filename, mask_invalid=False)\n        assert tab.mask is None\n\n\nclass TestMultipleHDU:\n    def setup_class(self):\n        self.data1 = np.array(\n            list(zip([1, 2, 3, 4], [\"a\", \"b\", \"c\", \"d\"], [2.3, 4.5, 6.7, 8.9])),\n            dtype=[(\"a\", int), (\"b\", \"U1\"), (\"c\", float)],\n        )\n        self.data2 = np.array(\n            list(zip([1.4, 2.3, 3.2, 4.7], [2.3, 4.5, 6.7, 8.9])),\n            dtype=[(\"p\", float), (\"q\", float)],\n        )\n        self.data3 = np.array(\n            list(zip([1, 2, 3, 4], [2.3, 4.5, 6.7, 8.9])),\n            dtype=[(\"A\", int), (\"B\", float)],\n        )\n        hdu0 = PrimaryHDU()\n        hdu1 = BinTableHDU(self.data1, name=\"first\")\n        hdu2 = BinTableHDU(self.data2, name=\"second\")\n        hdu3 = ImageHDU(np.ones((3, 3)), name=\"third\")\n        hdu4 = BinTableHDU(self.data3)\n\n        self.hdus = HDUList([hdu0, hdu1, hdu2, hdu3, hdu4])\n        self.hdusb = HDUList([hdu0, hdu3, hdu2, hdu1])\n        self.hdus3 = HDUList([hdu0, hdu3, hdu2])\n        self.hdus2 = HDUList([hdu0, hdu1, hdu3])\n        self.hdus1 = HDUList([hdu0, hdu1])\n\n    def teardown_class(self):\n        del self.hdus\n\n    def setup_method(self, method):\n        warnings.filterwarnings(\"always\")\n\n    def test_read(self, tmp_path):\n        filename = tmp_path / \"test_read.fits\"\n        self.hdus.writeto(filename)\n        with pytest.warns(\n            AstropyUserWarning,\n            match=r\"hdu= was not specified but multiple tables \"\n            r\"are present, reading in first available \"\n            r\"table \\(hdu=1\\)\",\n        ):\n            t = Table.read(filename)\n        assert equal_data(t, self.data1)\n\n        filename = tmp_path / \"test_read_2.fits\"\n        self.hdusb.writeto(filename)\n        with pytest.warns(\n            AstropyUserWarning,\n            match=r\"hdu= was not specified but multiple tables \"\n            r\"are present, reading in first available \"\n            r\"table \\(hdu=2\\)\",\n        ):\n            t3 = Table.read(filename)\n        assert equal_data(t3, self.data2)\n\n    def test_read_with_hdu_0(self, tmp_path):\n        filename = tmp_path / \"test_read_with_hdu_0.fits\"\n        self.hdus.writeto(filename)\n        with pytest.raises(ValueError) as exc:\n            Table.read(filename, hdu=0)\n        assert exc.value.args[0] == \"No table found in hdu=0\"\n\n    @pytest.mark.parametrize(\"hdu\", [1, \"first\"])\n    def test_read_with_hdu_1(self, tmp_path, hdu):\n        filename = tmp_path / \"test_read_with_hdu_1.fits\"\n        self.hdus.writeto(filename)\n        t = Table.read(filename, hdu=hdu)\n        assert equal_data(t, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [2, \"second\"])\n    def test_read_with_hdu_2(self, tmp_path, hdu):\n        filename = tmp_path / \"test_read_with_hdu_2.fits\"\n        self.hdus.writeto(filename)\n        t = Table.read(filename, hdu=hdu)\n        assert equal_data(t, self.data2)\n\n    @pytest.mark.parametrize(\"hdu\", [3, \"third\"])\n    def test_read_with_hdu_3(self, tmp_path, hdu):\n        filename = tmp_path / \"test_read_with_hdu_3.fits\"\n        self.hdus.writeto(filename)\n        with pytest.raises(ValueError, match=\"No table found in hdu=3\"):\n            Table.read(filename, hdu=hdu)\n\n    def test_read_with_hdu_4(self, tmp_path):\n        filename = tmp_path / \"test_read_with_hdu_4.fits\"\n        self.hdus.writeto(filename)\n        t = Table.read(filename, hdu=4)\n        assert equal_data(t, self.data3)\n\n    @pytest.mark.parametrize(\"hdu\", [2, 3, \"1\", \"second\", \"\"])\n    def test_read_with_hdu_missing(self, tmp_path, hdu):\n        filename = tmp_path / \"test_warn_with_hdu_1.fits\"\n        self.hdus1.writeto(filename)\n        with pytest.warns(\n            AstropyDeprecationWarning,\n            match=rf\"Specified hdu={hdu} not found, \"\n            r\"reading in first available table \\(hdu=1\\)\",\n        ):\n            t1 = Table.read(filename, hdu=hdu)\n        assert equal_data(t1, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [0, 2, \"third\"])\n    def test_read_with_hdu_warning(self, tmp_path, hdu):\n        filename = tmp_path / \"test_warn_with_hdu_2.fits\"\n        self.hdus2.writeto(filename)\n        with pytest.warns(\n            AstropyDeprecationWarning,\n            match=rf\"No table found in specified hdu={hdu}, \"\n            r\"reading in first available table \\(hdu=1\\)\",\n        ):\n            t2 = Table.read(filename, hdu=hdu)\n        assert equal_data(t2, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [0, 1, \"third\"])\n    def test_read_in_last_hdu(self, tmp_path, hdu):\n        filename = tmp_path / \"test_warn_with_hdu_3.fits\"\n        self.hdus3.writeto(filename)\n        with pytest.warns(\n            AstropyDeprecationWarning,\n            match=rf\"No table found in specified hdu={hdu}, \"\n            r\"reading in first available table \\(hdu=2\\)\",\n        ):\n            t3 = Table.read(filename, hdu=hdu)\n        assert equal_data(t3, self.data2)\n\n    def test_read_from_hdulist(self):\n        with pytest.warns(\n            AstropyUserWarning,\n            match=r\"hdu= was not specified but multiple tables \"\n            r\"are present, reading in first available \"\n            r\"table \\(hdu=1\\)\",\n        ):\n            t = Table.read(self.hdus)\n        assert equal_data(t, self.data1)\n\n        with pytest.warns(\n            AstropyUserWarning,\n            match=r\"hdu= was not specified but multiple tables \"\n            r\"are present, reading in first available \"\n            r\"table \\(hdu=2\\)\",\n        ):\n            t3 = Table.read(self.hdusb)\n        assert equal_data(t3, self.data2)\n\n    def test_read_from_hdulist_with_hdu_0(self):\n        with pytest.raises(ValueError) as exc:\n            Table.read(self.hdus, hdu=0)\n        assert exc.value.args[0] == \"No table found in hdu=0\"\n\n    @pytest.mark.parametrize(\"hdu\", [1, \"first\", None])\n    def test_read_from_hdulist_with_single_table(self, hdu):\n        t = Table.read(self.hdus1, hdu=hdu)\n        assert equal_data(t, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [1, \"first\"])\n    def test_read_from_hdulist_with_hdu_1(self, hdu):\n        t = Table.read(self.hdus, hdu=hdu)\n        assert equal_data(t, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [2, \"second\"])\n    def test_read_from_hdulist_with_hdu_2(self, hdu):\n        t = Table.read(self.hdus, hdu=hdu)\n        assert equal_data(t, self.data2)\n\n    @pytest.mark.parametrize(\"hdu\", [3, \"third\"])\n    def test_read_from_hdulist_with_hdu_3(self, hdu):\n        with pytest.raises(ValueError, match=\"No table found in hdu=3\"):\n            Table.read(self.hdus, hdu=hdu)\n\n    @pytest.mark.parametrize(\"hdu\", [0, 2, \"third\"])\n    def test_read_from_hdulist_with_hdu_warning(self, hdu):\n        with pytest.warns(\n            AstropyDeprecationWarning,\n            match=rf\"No table found in specified hdu={hdu}, \"\n            r\"reading in first available table \\(hdu=1\\)\",\n        ):\n            t2 = Table.read(self.hdus2, hdu=hdu)\n        assert equal_data(t2, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [2, 3, \"1\", \"second\", \"\"])\n    def test_read_from_hdulist_with_hdu_missing(self, hdu):\n        with pytest.warns(\n            AstropyDeprecationWarning,\n            match=rf\"Specified hdu={hdu} not found, \"\n            r\"reading in first available table \\(hdu=1\\)\",\n        ):\n            t1 = Table.read(self.hdus1, hdu=hdu)\n        assert equal_data(t1, self.data1)\n\n    @pytest.mark.parametrize(\"hdu\", [0, 1, \"third\"])\n    def test_read_from_hdulist_in_last_hdu(self, hdu):\n        with pytest.warns(\n            AstropyDeprecationWarning,\n            match=rf\"No table found in specified hdu={hdu}, \"\n            r\"reading in first available table \\(hdu=2\\)\",\n        ):\n            t3 = Table.read(self.hdus3, hdu=hdu)\n        assert equal_data(t3, self.data2)\n\n    @pytest.mark.parametrize(\"hdu\", [None, 1, \"first\"])\n    def test_read_from_single_hdu(self, hdu):\n        t = Table.read(self.hdus[1])\n        assert equal_data(t, self.data1)\n\n\ndef test_masking_regression_1795():\n    \"\"\"\n    Regression test for #1795 - this bug originally caused columns where TNULL\n    was not defined to have their first element masked.\n    \"\"\"\n    t = Table.read(get_pkg_data_filename(\"data/tb.fits\"))\n    assert np.all(t[\"c1\"].mask == np.array([False, False]))\n    assert not hasattr(t[\"c2\"], \"mask\")\n    assert not hasattr(t[\"c3\"], \"mask\")\n    assert not hasattr(t[\"c4\"], \"mask\")\n    assert np.all(t[\"c1\"].data == np.array([1, 2]))\n    assert np.all(t[\"c2\"].data == np.array([b\"abc\", b\"xy \"]))\n    assert_allclose(t[\"c3\"].data, np.array([3.70000007153, 6.6999997139]))\n    assert np.all(t[\"c4\"].data == np.array([False, True]))\n\n\ndef test_scale_error():\n    a = [1, 4, 5]\n    b = [2.0, 5.0, 8.2]\n    c = [\"x\", \"y\", \"z\"]\n    t = Table([a, b, c], names=(\"a\", \"b\", \"c\"), meta={\"name\": \"first table\"})\n    t[\"a\"].unit = \"1.2\"\n    with pytest.raises(\n        UnitScaleError,\n        match=r\"The column 'a' could not be \"\n        r\"stored in FITS format because it has a scale '\\(1\\.2\\)'\"\n        r\" that is not recognized by the FITS standard\\. Either \"\n        r\"scale the data or change the units\\.\",\n    ):\n        t.write(\"t.fits\", format=\"fits\", overwrite=True)\n\n\n@pytest.mark.parametrize(\n    \"tdisp_str, format_return\",\n    [\n        (\"EN10.5\", (\"EN\", \"10\", \"5\", None)),\n        (\"F6.2\", (\"F\", \"6\", \"2\", None)),\n        (\"B5.10\", (\"B\", \"5\", \"10\", None)),\n        (\"E10.5E3\", (\"E\", \"10\", \"5\", \"3\")),\n        (\"A21\", (\"A\", \"21\", None, None)),\n    ],\n)\ndef test_parse_tdisp_format(tdisp_str, format_return):\n    assert _parse_tdisp_format(tdisp_str) == format_return\n\n\n@pytest.mark.parametrize(\n    \"tdisp_str, format_str_return\",\n    [\n        (\"G15.4E2\", \"{:15.4g}\"),\n        (\"Z5.10\", \"{:5x}\"),\n        (\"I6.5\", \"{:6d}\"),\n        (\"L8\", \"{:>8}\"),\n        (\"E20.7\", \"{:20.7e}\"),\n    ],\n)\ndef test_fortran_to_python_format(tdisp_str, format_str_return):\n    assert _fortran_to_python_format(tdisp_str) == format_str_return\n\n\n@pytest.mark.parametrize(\n    \"fmt_str, tdisp_str\",\n    [\n        (\"{:3d}\", \"I3\"),\n        (\"3d\", \"I3\"),\n        (\"7.3f\", \"F7.3\"),\n        (\"{:>4}\", \"A4\"),\n        (\"{:7.4f}\", \"F7.4\"),\n        (\"%5.3g\", \"G5.3\"),\n        (\"%10s\", \"A10\"),\n        (\"%.4f\", \"F13.4\"),\n    ],\n)\ndef test_python_to_tdisp(fmt_str, tdisp_str):\n    assert python_to_tdisp(fmt_str) == tdisp_str\n\n\ndef test_logical_python_to_tdisp():\n    assert python_to_tdisp(\"{:>7}\", logical_dtype=True) == \"L7\"\n\n\ndef test_bool_column(tmp_path):\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/1953\n\n    Ensures that Table columns of bools are properly written to a FITS table.\n    \"\"\"\n\n    arr = np.ones(5, dtype=bool)\n    arr[::2] == np.False_\n\n    t = Table([arr])\n    t.write(tmp_path / \"test.fits\", overwrite=True)\n\n    with fits.open(tmp_path / \"test.fits\") as hdul:\n        assert hdul[1].data[\"col0\"].dtype == np.dtype(\"bool\")\n        assert np.all(hdul[1].data[\"col0\"] == arr)\n\n\ndef test_unicode_column(tmp_path):\n    \"\"\"\n    Test that a column of unicode strings is still written as one\n    byte-per-character in the FITS table (so long as the column can be ASCII\n    encoded).\n\n    Regression test for one of the issues fixed in\n    https://github.com/astropy/astropy/pull/4228\n    \"\"\"\n\n    t = Table([np.array([\"a\", \"b\", \"cd\"])])\n    t.write(tmp_path / \"test.fits\", overwrite=True)\n\n    with fits.open(tmp_path / \"test.fits\") as hdul:\n        assert np.all(hdul[1].data[\"col0\"] == [\"a\", \"b\", \"cd\"])\n        assert hdul[1].header[\"TFORM1\"] == \"2A\"\n\n    t2 = Table([np.array([\"\\N{SNOWMAN}\"])])\n\n    with pytest.raises(UnicodeEncodeError):\n        t2.write(tmp_path / \"test.fits\", overwrite=True)\n\n\ndef test_unit_warnings_read_write(tmp_path):\n    filename = tmp_path / \"test_unit.fits\"\n    t1 = Table([[1, 2], [3, 4]], names=[\"a\", \"b\"])\n    t1[\"a\"].unit = \"m/s\"\n    t1[\"b\"].unit = \"not-a-unit\"\n\n    with pytest.warns(\n        u.UnitsWarning, match=\"'not-a-unit' did not parse as fits unit\"\n    ) as w:\n        t1.write(filename, overwrite=True)\n    assert len(w) == 1\n\n    with pytest.warns(\n        u.UnitsWarning, match=\"'not-a-unit' did not parse as fits unit\"\n    ) as w:\n        Table.read(filename, hdu=1)\n\n\ndef test_convert_comment_convention():\n    \"\"\"\n    Regression test for https://github.com/astropy/astropy/issues/6079\n    \"\"\"\n    filename = get_pkg_data_filename(\"data/stddata.fits\")\n    with pytest.warns(\n        AstropyUserWarning,\n        match=r\"hdu= was not specified but \" r\"multiple tables are present\",\n    ):\n        t = Table.read(filename)\n\n    assert t.meta[\"comments\"] == [\n        \"\",\n        \" *** End of mandatory fields ***\",\n        \"\",\n        \"\",\n        \" *** Column names ***\",\n        \"\",\n        \"\",\n        \" *** Column formats ***\",\n        \"\",\n    ]\n\n\ndef assert_objects_equal(obj1, obj2, attrs, compare_class=True):\n    if compare_class:\n        assert obj1.__class__ is obj2.__class__\n\n    info_attrs = [\n        \"info.name\",\n        \"info.format\",\n        \"info.unit\",\n        \"info.description\",\n        \"info.meta\",\n        \"info.dtype\",\n    ]\n    for attr in attrs + info_attrs:\n        a1 = obj1\n        a2 = obj2\n        for subattr in attr.split(\".\"):\n            try:\n                a1 = getattr(a1, subattr)\n                a2 = getattr(a2, subattr)\n            except AttributeError:\n                a1 = a1[subattr]\n                a2 = a2[subattr]\n\n        # Mixin info.meta can None instead of empty OrderedDict(), #6720 would\n        # fix this.\n        if attr == \"info.meta\":\n            if a1 is None:\n                a1 = {}\n            if a2 is None:\n                a2 = {}\n\n        if isinstance(a1, np.ndarray) and a1.dtype.kind == \"f\":\n            assert quantity_allclose(a1, a2, rtol=1e-15)\n        elif isinstance(a1, np.dtype):\n            # FITS does not perfectly preserve dtype: byte order can change, and\n            # unicode gets stored as bytes.  So, we just check safe casting, to\n            # ensure we do not, e.g., accidentally change integer to float, etc.\n            if NUMPY_LT_1_22 and a1.names:\n                # For old numpy, can_cast does not deal well with structured dtype.\n                assert a1.names == a2.names\n            else:\n                assert np.can_cast(a2, a1, casting=\"safe\")\n        else:\n            assert np.all(a1 == a2)\n\n\ndef test_fits_mixins_qtable_to_table(tmp_path):\n    \"\"\"Test writing as QTable and reading as Table.  Ensure correct classes\n    come out.\n    \"\"\"\n    filename = tmp_path / \"test_simple.fits\"\n\n    names = sorted(mixin_cols)\n\n    t = QTable([mixin_cols[name] for name in names], names=names)\n    t.write(filename, format=\"fits\")\n    t2 = Table.read(filename, format=\"fits\", astropy_native=True)\n\n    assert t.colnames == t2.colnames\n\n    for name, col in t.columns.items():\n        col2 = t2[name]\n\n        # Special-case Time, which does not yet support round-tripping\n        # the format.\n        if isinstance(col2, Time):\n            col2.format = col.format\n\n        attrs = compare_attrs[name]\n        compare_class = True\n\n        if isinstance(col.info, QuantityInfo):\n            # Downgrade Quantity to Column + unit\n            assert type(col2) is Column\n            # Class-specific attributes like `value` or `wrap_angle` are lost.\n            attrs = [\"unit\"]\n            compare_class = False\n            # Compare data values here (assert_objects_equal doesn't know how in this case)\n            assert np.all(col.value == col2)\n\n        assert_objects_equal(col, col2, attrs, compare_class)\n\n\n@pytest.mark.parametrize(\"table_cls\", (Table, QTable))\ndef test_fits_mixins_as_one(table_cls, tmp_path):\n    \"\"\"Test write/read all cols at once and validate intermediate column names\"\"\"\n    filename = tmp_path / \"test_simple.fits\"\n    names = sorted(mixin_cols)\n    # FITS stores times directly, so we just get the column back.\n    all_serialized_names = []\n    for name in sorted(mixin_cols):\n        all_serialized_names.extend(\n            [name] if isinstance(mixin_cols[name], Time) else serialized_names[name]\n        )\n    t = table_cls([mixin_cols[name] for name in names], names=names)\n    t.meta[\"C\"] = \"spam\"\n    t.meta[\"comments\"] = [\"this\", \"is\", \"a\", \"comment\"]\n    t.meta[\"history\"] = [\"first\", \"second\", \"third\"]\n\n    t.write(filename, format=\"fits\")\n\n    t2 = table_cls.read(filename, format=\"fits\", astropy_native=True)\n    assert t2.meta[\"C\"] == \"spam\"\n    assert t2.meta[\"comments\"] == [\"this\", \"is\", \"a\", \"comment\"]\n    assert t2.meta[\"HISTORY\"] == [\"first\", \"second\", \"third\"]\n\n    assert t.colnames == t2.colnames\n\n    # Read directly via fits and confirm column names\n    with fits.open(filename) as hdus:\n        assert hdus[1].columns.names == all_serialized_names\n\n\n@pytest.mark.parametrize(\"name_col\", list(mixin_cols.items()))\n@pytest.mark.parametrize(\"table_cls\", (Table, QTable))\ndef test_fits_mixins_per_column(table_cls, name_col, tmp_path):\n    \"\"\"Test write/read one col at a time and do detailed validation\"\"\"\n    filename = tmp_path / \"test_simple.fits\"\n    name, col = name_col\n\n    c = [1.0, 2.0]\n    t = table_cls([c, col, c], names=[\"c1\", name, \"c2\"])\n    t[name].info.description = \"my \\n\\n\\n description\"\n    t[name].info.meta = {\"list\": list(range(50)), \"dict\": {\"a\": \"b\" * 200}}\n\n    if not t.has_mixin_columns:\n        pytest.skip(\"column is not a mixin (e.g. Quantity subclass in Table)\")\n\n    t.write(filename, format=\"fits\")\n    t2 = table_cls.read(filename, format=\"fits\", astropy_native=True)\n    if isinstance(col, Time):\n        # FITS Time does not preserve format\n        t2[name].format = col.format\n\n    assert t.colnames == t2.colnames\n\n    for colname in t.colnames:\n        compare = [\"data\"] if colname in (\"c1\", \"c2\") else compare_attrs[colname]\n        assert_objects_equal(t[colname], t2[colname], compare)\n\n    # Special case to make sure Column type doesn't leak into Time class data\n    if name.startswith(\"tm\"):\n        assert t2[name]._time.jd1.__class__ is np.ndarray\n        assert t2[name]._time.jd2.__class__ is np.ndarray\n\n\n@pytest.mark.parametrize(\"name_col\", unsupported_cols.items())\n@pytest.mark.xfail(reason=\"column type unsupported\")\ndef test_fits_unsupported_mixin(self, name_col, tmp_path):\n    # Check that we actually fail in writing unsupported columns defined\n    # on top.\n    filename = tmp_path / \"test_simple.fits\"\n    name, col = name_col\n    Table([col], names=[name]).write(filename, format=\"fits\")\n\n\ndef test_info_attributes_with_no_mixins(tmp_path):\n    \"\"\"Even if there are no mixin columns, if there is metadata that would be lost it still\n    gets serialized\n    \"\"\"\n    filename = tmp_path / \"test.fits\"\n    t = Table([[1.0, 2.0]])\n    t[\"col0\"].description = \"hello\" * 40\n    t[\"col0\"].format = \"{:8.4f}\"\n    t[\"col0\"].meta[\"a\"] = {\"b\": \"c\"}\n    t.write(filename, overwrite=True)\n\n    t2 = Table.read(filename)\n    assert t2[\"col0\"].description == \"hello\" * 40\n    assert t2[\"col0\"].format == \"{:8.4f}\"\n    assert t2[\"col0\"].meta[\"a\"] == {\"b\": \"c\"}\n\n\n@pytest.mark.parametrize(\"method\", [\"set_cols\", \"names\", \"class\"])\ndef test_round_trip_masked_table_serialize_mask(tmp_path, method):\n    \"\"\"\n    Same as previous test but set the serialize_method to 'data_mask' so mask is\n    written out and the behavior is all correct.\n    \"\"\"\n    filename = tmp_path / \"test.fits\"\n\n    t = simple_table(masked=True)  # int, float, and str cols with one masked element\n\n    # MaskedColumn but no masked elements.  See table the MaskedColumnInfo class\n    # _represent_as_dict() method for info about we test a column with no masked elements.\n    t[\"d\"] = [1, 2, 3]\n\n    if method == \"set_cols\":\n        for col in t.itercols():\n            col.info.serialize_method[\"fits\"] = \"data_mask\"\n        t.write(filename)\n    elif method == \"names\":\n        t.write(\n            filename,\n            serialize_method={\n                \"a\": \"data_mask\",\n                \"b\": \"data_mask\",\n                \"c\": \"data_mask\",\n                \"d\": \"data_mask\",\n            },\n        )\n    elif method == \"class\":\n        t.write(filename, serialize_method=\"data_mask\")\n\n    t2 = Table.read(filename)\n    assert t2.masked is False\n    assert t2.colnames == t.colnames\n    for name in t2.colnames:\n        assert np.all(t2[name].mask == t[name].mask)\n        assert np.all(t2[name] == t[name])\n\n        # Data under the mask round-trips also (unmask data to show this).\n        t[name].mask = False\n        t2[name].mask = False\n        assert np.all(t2[name] == t[name])\n\n\ndef test_meta_not_modified(tmp_path):\n    filename = tmp_path / \"test.fits\"\n    t = Table(data=[Column([1, 2], \"a\", description=\"spam\")])\n    t.meta[\"comments\"] = [\"a\", \"b\"]\n    assert len(t.meta) == 1\n    t.write(filename)\n    assert len(t.meta) == 1\n    assert t.meta[\"comments\"] == [\"a\", \"b\"]"}
